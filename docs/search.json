[
  {
    "objectID": "r_basics.html#what-is-r",
    "href": "r_basics.html#what-is-r",
    "title": "R basics",
    "section": "1 What is R?",
    "text": "1 What is R?\n\nA free Domain-Specific-Language (DSL) for statistics and data analysis\nA collection of over 19514 (may-12-2023) libraries\nA large and active community across industry and academia\nA way to talk “directly” to your computer\n\nHistorically:\n\nBased on the S Programming Language\nAround 20 years old (Lineage dates from 1975 - almost 40 years ago)"
  },
  {
    "objectID": "r_basics.html#rstudio",
    "href": "r_basics.html#rstudio",
    "title": "R basics",
    "section": "2 Rstudio",
    "text": "2 Rstudio\nIntegrated development environment (IDE) for R. Includes:\n\nA console\nSyntax-highlighting editor that supports direct code execution\nTools for plotting, history, debugging and workspace management"
  },
  {
    "objectID": "r_basics.html#elements-of-the-r-language",
    "href": "r_basics.html#elements-of-the-r-language",
    "title": "R basics",
    "section": "3 Elements of the R language",
    "text": "3 Elements of the R language\n\nVectors\nLists\nMatrices\nData Frames\nFunctions (including operators)\nAttributes\nTables\nArrays\nEnvironments\n\nData structure\nThe basic data structure in R is the vector. There are two basic types of vectors: atomic vectors and lists.\nThey have three common properties:\n\nType, typeof() (~ class/mode)\nLength, length() (number of elements)\nAttributes, attributes() (metadata)\n\nThey differ in the types of their elements: all elements of an atomic vector must be the same type, whereas the elements of a list can have different types.\n\n\n\n\n\n\n\nHomogeneous\nHeterogeneous\n\n\n\n\n1d\nAtomic vector\nList\n\n\n2d\nMatrix\nData frame\n\n\nnd\nArray\n\n\n\n\n\n\n\n \nR has no 0-dimensional elements (scalars). Individual numbers or strings are actually vectors of length one.\nAtomic vectors\nTypes of atomic vectors:\n\nLogical (boolean)\nInteger\nNumeric (double)\nCharacter\n\nVectors are built using c():\n\n\nCode\n\nx <- 1\nx1 <- c(1)\n\nall.equal(x, x1)\n## [1] TRUE\n\nclass(x)\n## [1] \"numeric\"\n\ny <- \"something\"\n\nclass(y)\n## [1] \"character\"\n\nw <- 1L\n\nclass(w)\n## [1] \"integer\"\n \nz <- TRUE\n\nclass(z)\n## [1] \"logical\"\n\nq <- factor(1)\n\nclass(q)\n## [1] \"factor\"\n\n\n \nVectors can only contain entries of the same type. Different types will be coerced to the most flexible type:\n\n\nCode\n\nv <- c(10, 11, 12, 13)\n\nclass(v)\n## [1] \"numeric\"\n\nis.integer(v)\n## [1] FALSE\n\ny <- c(\"Amazona\", \"Ara\", \"Eupsittula\", \"Myiopsitta\")\n\nclass(y)\n## [1] \"character\"\n\nis.integer(y)\n## [1] FALSE\n\nx <- c(1,2,3, \"Myiopsitta\")\n\nx\n## [1] \"1\"          \"2\"          \"3\"          \"Myiopsitta\"\n\nclass(x)\n## [1] \"character\"\n\n\n \nMissing values are specified with NA, which is a logical vector of length 1. NA will always be coerced to the correct type if used inside c():\n\n\nCode\n\nv <- c(10, 11, 12, 13, NA)\n\nclass(v)\n## [1] \"numeric\"\n\nv <- c(letters[1:3], NA)\n\nclass(v)\n## [1] \"character\"\n\n\n \nLists\nCan contain objects of different classes and sizes. Lists are built using list():\n\n\nCode\nl <- list(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), \n          size = c(1, 2, 3, 4, 5), \n          observed = c(FALSE, TRUE, FALSE, FALSE, FALSE))\n\nl\n\n\n$ID\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n$size\n[1] 1 2 3 4 5\n\n$observed\n[1] FALSE  TRUE FALSE FALSE FALSE\n\n\nCode\nclass(l)\n\n\n[1] \"list\"\n\n\nCode\nstr(l)\n\n\nList of 3\n $ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n $ size    : num [1:5] 1 2 3 4 5\n $ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n\n\n… and dimensions:\n\n\nCode\nl <- list(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), \n          size = c(1, 2, 3, 4, 5, 6), \n          observed = c(FALSE, TRUE, FALSE, FALSE, FALSE), \n          l)\n\nstr(l)\n\n\nList of 4\n $ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n $ size    : num [1:6] 1 2 3 4 5 6\n $ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n $         :List of 3\n  ..$ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ size    : num [1:5] 1 2 3 4 5\n  ..$ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n\n\nCode\nl2 <- list(l, l)\n\nstr(l2)\n\n\nList of 2\n $ :List of 4\n  ..$ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ size    : num [1:6] 1 2 3 4 5 6\n  ..$ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n  ..$         :List of 3\n  .. ..$ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  .. ..$ size    : num [1:5] 1 2 3 4 5\n  .. ..$ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n $ :List of 4\n  ..$ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  ..$ size    : num [1:6] 1 2 3 4 5 6\n  ..$ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n  ..$         :List of 3\n  .. ..$ ID      : chr [1:5] \"a\" \"b\" \"c\" \"d\" ...\n  .. ..$ size    : num [1:5] 1 2 3 4 5\n  .. ..$ observed: logi [1:5] FALSE TRUE FALSE FALSE FALSE\n\n\n \nAttributes\nObjects can have attributes. Attributes allow to store metadata about the object. Attributes are kind of named lists. Attributes can be accessed individually with attr() or all at once (as a list) with attributes():\n\n\nCode\ny <- 1:10\n\nmean(y)\n\n\n[1] 5.5\n\n\nCode\nattr(y, \"my_attribute\") <- \"This is an attribute\"\n\n\nattr(y, \"my_attribute\")\n\n\n[1] \"This is an attribute\"\n\n\nCode\nstr(y)\n\n\n int [1:10] 1 2 3 4 5 6 7 8 9 10\n - attr(*, \"my_attribute\")= chr \"This is an attribute\"\n\n\n \nMost attributes are lost when modifying a vector:\n\n\nCode\nattributes(y[1])\n\n\nNULL\n\n\n \nThe only attributes not lost are the three most important:\n\nNames, a character vector giving each element a name, described in names\nDimensions\nClass\n\n\n\n\nCode\nw <- structure(c(a =1, b = 2), my_attribute = \"This is not an apple\")\n\nattributes(w)\n\n\n$names\n[1] \"a\" \"b\"\n\n$my_attribute\n[1] \"This is not an apple\"\n\n\nCode\nattributes(w[1])\n\n\n$names\n[1] \"a\"\n\n\nCode\nclass(w[1])\n\n\n[1] \"numeric\"\n\n\n \nFactors\nAttributes are used to define factors. A factor is a vector that can contain only predefined values, and is used to store categorical data.\nFactors are built on top of integer vectors using two attributes:\n\nclass “factor”: makes them behave differently from regular integer vectors\nlevels: defines the set of allowed values\n\n\n\nCode\nx <- factor(c(\"a\", \"b\", \"b\", \"a\"))\nx\n\n\n[1] a b b a\nLevels: a b\n\n\nCode\nlevels(x)\n\n\n[1] \"a\" \"b\"\n\n\nCode\nstr(x)\n\n\n Factor w/ 2 levels \"a\",\"b\": 1 2 2 1\n\n\n \nFactors look like character vectors but they are actually integers:\n\n\nCode\nx <- factor(c(\"a\", \"b\", \"b\", \"a\"))\n\nc(x)\n\n\n[1] a b b a\nLevels: a b\n\n\n \nMatrices\nAll entries are of the same type:\n\n\nCode\nm <- matrix(c(1, 2, 3, 11, 12, 13), nrow = 2)\n\ndim(m)\n\n\n[1] 2 3\n\n\nCode\nm\n\n\n     [,1] [,2] [,3]\n[1,]    1    3   12\n[2,]    2   11   13\n\n\nCode\nclass(m)\n\n\n[1] \"matrix\" \"array\" \n\n\nCode\nm <- matrix(c(1, 2, 3, 11, 12,\"13\"), nrow = 2)\nm\n\n\n     [,1] [,2] [,3]\n[1,] \"1\"  \"3\"  \"12\"\n[2,] \"2\"  \"11\" \"13\"\n\n\n \nData frames\nSpecial case of lists. Can contain entries of different types:\n\n\nCode\nm <- data.frame(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), \n                size = c(1, 2, 3, 4, 5), \n                observed = c(FALSE, TRUE, FALSE, FALSE, FALSE))\n\ndim(m)\n\n\n[1] 5 3\n\n\nCode\nm\n\n\n\n\n\n\nID\nsize\nobserved\n\n\n\n\na\n1\nFALSE\n\n\nb\n2\nTRUE\n\n\nc\n3\nFALSE\n\n\nd\n4\nFALSE\n\n\ne\n5\nFALSE\n\n\n\n\n\n\nCode\nclass(m)\n\n\n[1] \"data.frame\"\n\n\nCode\nis.data.frame(m)\n\n\n[1] TRUE\n\n\nCode\nis.list(m)\n\n\n[1] TRUE\n\n\nCode\nstr(m)\n\n\n'data.frame':   5 obs. of  3 variables:\n $ ID      : chr  \"a\" \"b\" \"c\" \"d\" ...\n $ size    : num  1 2 3 4 5\n $ observed: logi  FALSE TRUE FALSE FALSE FALSE\n\n\n \nBut vectors should have the same length:\n\n\nCode\nm <- data.frame(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), \n                size = c(1, 2, 3, 4, 5, 6), \n                observed = c(FALSE, TRUE, FALSE, FALSE, FALSE))\n\n\nError in data.frame(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), size = c(1, 2, 3, : arguments imply differing number of rows: 5, 6"
  },
  {
    "objectID": "r_basics.html#data-subsetting",
    "href": "r_basics.html#data-subsetting",
    "title": "R basics",
    "section": "4 Data subsetting",
    "text": "4 Data subsetting\nIndexing\nElements within objects can be called by indexing. To subset a vector simply call the object position using square brackets:\n\n\nCode\nx <- c(1, 3, 4, 10, 15, 20, 50, 1, 6)\n\nx[1]\n\n\n[1] 1\n\n\nCode\nx[2]\n\n\n[1] 3\n\n\nCode\nx[2:3]\n\n\n[1] 3 4\n\n\nCode\nx[c(1,3)]\n\n\n[1] 1 4\n\n\n \nElements can be removed in the same way:\n\n\nCode\nx[-1]\n\n\n[1]  3  4 10 15 20 50  1  6\n\n\nCode\nx[-c(1,3)]\n\n\n[1]  3 10 15 20 50  1  6\n\n\n \nMatrices and data frames required 2 indices [row, column]:\n\n\nCode\nm <- matrix(c(1, 2, 3, 11, 12, 13), nrow = 2)\n\nm[1, ]\n\n\n[1]  1  3 12\n\n\nCode\nm[, 1]\n\n\n[1] 1 2\n\n\nCode\nm[1, 1]\n\n\n[1] 1\n\n\nCode\nm[-1, ]\n\n\n[1]  2 11 13\n\n\nCode\nm[, -1]\n\n\n     [,1] [,2]\n[1,]    3   12\n[2,]   11   13\n\n\nCode\nm[-1, -1]\n\n\n[1] 11 13\n\n\nCode\ndf <- data.frame(family = c(\"Psittacidae\", \"Trochilidae\", \n                            \"Psittacidae\"), \n  genus = c(\"Amazona\", \"Phaethornis\", \"Ara\"), \n    species = c(\"aestiva\", \"philippii\", \"ararauna\"))\n\ndf\n\n\n\n\n\n\nfamily\ngenus\nspecies\n\n\n\n\nPsittacidae\nAmazona\naestiva\n\n\nTrochilidae\nPhaethornis\nphilippii\n\n\nPsittacidae\nAra\nararauna\n\n\n\n\n\n\nCode\ndf[1, ]\n\n\n\n\n\n\nfamily\ngenus\nspecies\n\n\n\n\nPsittacidae\nAmazona\naestiva\n\n\n\n\n\n\nCode\ndf[, 1]\n\n\n[1] \"Psittacidae\" \"Trochilidae\" \"Psittacidae\"\n\n\nCode\ndf[1, 1]\n\n\n[1] \"Psittacidae\"\n\n\nCode\ndf[-1, ]\n\n\n\n\n\n\n\nfamily\ngenus\nspecies\n\n\n\n\n2\nTrochilidae\nPhaethornis\nphilippii\n\n\n3\nPsittacidae\nAra\nararauna\n\n\n\n\n\n\nCode\ndf[, -1]\n\n\n\n\n\n\ngenus\nspecies\n\n\n\n\nAmazona\naestiva\n\n\nPhaethornis\nphilippii\n\n\nAra\nararauna\n\n\n\n\n\n\nCode\ndf[-1, -1]\n\n\n\n\n\n\n\ngenus\nspecies\n\n\n\n\n2\nPhaethornis\nphilippii\n\n\n3\nAra\nararauna\n\n\n\n\n\n\nCode\ndf[,\"family\"]\n\n\n[1] \"Psittacidae\" \"Trochilidae\" \"Psittacidae\"\n\n\nCode\ndf[,c(\"family\", \"genus\")]\n\n\n\n\n\n\nfamily\ngenus\n\n\n\n\nPsittacidae\nAmazona\n\n\nTrochilidae\nPhaethornis\n\n\nPsittacidae\nAra\n\n\n\n\n\n\n \nLists require 1 index within double square brackets [[index]]:\n\n\nCode\nl <- list(ID = c(\"a\", \"b\", \"c\", \"d\", \"e\"), size = c(1, 2, 3, 4, 5), observed = c(FALSE, TRUE, FALSE, FALSE, FALSE))\n\nl[[1]]\n\n\n[1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n\nCode\nl[[3]]\n\n\n[1] FALSE  TRUE FALSE FALSE FALSE\n\n\n \nElements within lists can also be subset in the same string of code:\n\n\nCode\nl[[1]][1:2]\n\n\n[1] \"a\" \"b\"\n\n\nCode\nl[[3]][2]\n\n\n[1] TRUE\n\n\n \nExploring objects\n\n\nCode\nstr(df)\n\n\n'data.frame':   3 obs. of  3 variables:\n $ family : chr  \"Psittacidae\" \"Trochilidae\" \"Psittacidae\"\n $ genus  : chr  \"Amazona\" \"Phaethornis\" \"Ara\"\n $ species: chr  \"aestiva\" \"philippii\" \"ararauna\"\n\n\nCode\nnames(df)\n\n\n[1] \"family\"  \"genus\"   \"species\"\n\n\nCode\ndim(df)\n\n\n[1] 3 3\n\n\nCode\nnrow(df)\n\n\n[1] 3\n\n\nCode\nncol(df)\n\n\n[1] 3\n\n\nCode\nhead(df)\n\n\n\n\n\n\nfamily\ngenus\nspecies\n\n\n\n\nPsittacidae\nAmazona\naestiva\n\n\nTrochilidae\nPhaethornis\nphilippii\n\n\nPsittacidae\nAra\nararauna\n\n\n\n\n\n\nCode\ntail(df)\n\n\n\n\n\n\nfamily\ngenus\nspecies\n\n\n\n\nPsittacidae\nAmazona\naestiva\n\n\nTrochilidae\nPhaethornis\nphilippii\n\n\nPsittacidae\nAra\nararauna\n\n\n\n\n\n\nCode\ntable(df$genus)\n\n\n\n    Amazona         Ara Phaethornis \n          1           1           1 \n\n\nCode\ntypeof(df)\n\n\n[1] \"list\"\n\n\n\n\nCode\nView(df)\n\n\n \n\nExercise\n \n\nUsing the example data iris to create a data subset with only the observations of the species ‘setosa’\nNow create a data subset containing the observations of both ‘setosa’ and ‘versicolor’\nAlso with iris create a data subset with the observations for which iris$Sepal.length is higher than 6\nHow many observations have a sepal length higher than 6?"
  },
  {
    "objectID": "r_basics.html#functions",
    "href": "r_basics.html#functions",
    "title": "R basics",
    "section": "5 Functions",
    "text": "5 Functions\nAll functions are created by the function function() and follow the same structure:\n\n* Modified from Grolemund 2014  \nR comes with many functions that you can use to do sophisticated tasks:\n\n\nCode\n# built in functions\nbi <- builtins()\n\nlength(bi)\n\n\n[1] 1375\n\n\nCode\nsample(bi, 10)\n\n\n [1] \"call\"                  \"as.matrix.noquote\"     \"R.Version\"            \n [4] \"readRenviron\"          \"split.POSIXct\"         \"weekdays\"             \n [7] \"anyNA.numeric_version\" \"mem.maxNSize\"          \"topenv\"               \n[10] \"open.srcfilealias\"    \n\n\n \nOperators are functions:\n\n\nCode\n1 + 1\n\n\n[1] 2\n\n\nCode\n'+'(1, 1)\n\n\n[1] 2\n\n\nCode\n2 * 3\n\n\n[1] 6\n\n\nCode\n'*'(2, 3)\n\n\n[1] 6\n\n\n \nMost commonly used R operators\nArithmetic operators:\n\n\n                                 Operator       Description        \nc.......addition..               \"+\"            \"addition\"         \nc.......subtraction..            \"-\"            \"subtraction\"      \nc.......multiplication..         \"*\"            \"multiplication\"   \nc.......division..               \"/\"            \"division\"         \nc....or.......exponent..         \"^ or **\"      \"exponent\"         \nc..x....y....modulus..x.mod.y... \"x %% y\"       \"modulus (x mod y)\"\nc..x.....y....integer.division.. \"x %/% y\"      \"integer division\" \n\n\n\n\nCode\n1 - 2\n\n\n[1] -1\n\n\nCode\n1 + 2\n\n\n[1] 3\n\n\nCode\n2 ^ 2\n\n\n[1] 4\n\n\n \nLogical operators:\n\n\n                                    Operator    Description               \nc.......less.than..                 \"<\"         \"less than\"               \nc........less.than.or.equal.to..    \"<=\"        \"less than or equal to\"   \nc.......greater.than..              \">\"         \"greater than\"            \nc........greater.than.or.equal.to.. \">=\"        \"greater than or equal to\"\nc........exactly.equal.to..         \"==\"        \"exactly equal to\"        \nc........not.equal.to..             \"!=\"        \"not equal to\"            \nc...x....Not.x..                    \"!x\"        \"Not x\"                   \nc..x...y.....tx.OR.y..              \"x | y\"     \"\\tx OR y\"                \nc..x...y....x.AND.y..               \"x & y\"     \"x AND y\"                 \nc..x..in..y....match..              \"x %in% y\"  \"match\"                   \n\n\n\n\nCode\n1 < 2 \n\n\n[1] TRUE\n\n\nCode\n1 > 2 \n\n\n[1] FALSE\n\n\nCode\n1 <= 2 \n\n\n[1] TRUE\n\n\nCode\n1 == 2\n\n\n[1] FALSE\n\n\nCode\n1 != 2\n\n\n[1] TRUE\n\n\nCode\n1 > 2 \n\n\n[1] FALSE\n\n\nCode\n5 %in% 1:6\n\n\n[1] TRUE\n\n\nCode\n5 %in% 1:4\n\n\n[1] FALSE\n\n\n \nMost functions are vectorized:\n\n\nCode\n1:6 * 1:6\n\n\n\n* Modified from Grolemund & Wickham 2017\n \n\n\n[1]  1  4  9 16 25 36\n\n\n\n\nCode\n1:6 - 1:6\n\n\n[1] 0 0 0 0 0 0\n\n\nR recycles vectors of unequal length:\n\n\nCode\n1:6 * 1:5\n\n\n\n* Modified from Grolemund & Wickham 2017\n \n\n\nWarning in 1:6 * 1:5: longitud de objeto mayor no es múltiplo de la longitud de\nuno menor\n\n\n[1]  1  4  9 16 25  6\n\n\n\n\nCode\n1:6 + 1:5\n\n\nWarning in 1:6 + 1:5: longitud de objeto mayor no es múltiplo de la longitud de\nuno menor\n\n\n[1]  2  4  6  8 10  7"
  },
  {
    "objectID": "r_basics.html#style-matters",
    "href": "r_basics.html#style-matters",
    "title": "R basics",
    "section": "6 Style matters",
    "text": "6 Style matters\nBased on google’s R Style Guide\nFile names\nFile names should end in .R and, of course, be meaningful:\n\nGOOD: predict_ad_revenue.R\nBAD: foo.R\n\nObject names\nVariables and functions:\n\nLowercase\nUse an underscore (_) (HW style)\nGenerally, nouns for variables and verbs for functions\nStrive for names that are concise and meaningful (not always easy)\nAvoid using names of existing functions of variables\n\n\n\nCode\n  - GOOD: day_one: day_1, mean.day(),\n  \n  - BAD: dayOne, day1, firstDay_of.month, mean <- function(x) sum(x), c <- 10\n\n\n \nSyntax\nSpacing:\n\nUse spaces around operators and for argument within a function\nAlways put a space after a comma, and never before (just like in regular English)\nPlace a space before left parenthesis, except in a function call\n\n\n\nCode\n  - GOOD: \n          a <- rnorm(n = 10, sd = 10, mean = 1)\n          tab.prior <- table(df[df$days.from.opt < 0, \"campaign.id\"])\n          total <- sum(x[, 1])\n          total <- sum(x[1, ])\n          if (debug)\n          mean(1:10)\n          \n  - BAD: \n         a<-rnorm(n=10,sd=10,mean=1)\n         tab.prior <- table(df[df$days.from.opt<0, \"campaign.id\"])  # Needs spaces around '<'\n         tab.prior <- table(df[df$days.from.opt < 0,\"campaign.id\"])  # Needs a space after the comma\n         tab.prior<- table(df[df$days.from.opt < 0, \"campaign.id\"])  # Needs a space before <-\n         tab.prior<-table(df[df$days.from.opt < 0, \"campaign.id\"])  # Needs spaces around <-\n         total <- sum(x[,1])  # Needs a space after the comma\n         total <- sum(x[ ,1])  # Needs a space after the comma, not before  \n         if(debug) # Needs a space before parenthesis\n         mean (1:10) # ) # Extra space before parenthesis\n\n\n \nCurly braces:\n\nAn opening curly brace should never go on its own line\nClosing curly brace should always go on its own line\nYou may omit curly braces when a block consists of a single statement\n\n\n\nCode\n  - GOOD:\n              if (is.null(ylim)) {\n              ylim <- c(0, 0.06)\n            }\n                      \n            if (is.null(ylim))\n              ylim <- c(0, 0.06)\n          \n  - BAD:\n            \n         if (is.null(ylim)) ylim <- c(0, 0.06)\n                    \n         if (is.null(ylim)) {ylim <- c(0, 0.06)} \n\n         if (is.null(ylim)) {\n           ylim <- c(0, 0.06)\n           } \n\n\n \nAssigments:\n\nUse <-, not =\n\n\n\nCode\n  - GOOD:\n         x <- 5 \n          \n  - BAD:\n         x = 5\n\n\n \nCommenting guidelines:\n\nComment your code\nEntire commented lines should begin with # and one space\nShort comments can be placed after code preceded by two spaces, #, and then one space\n\n\n\nCode\n# Create histogram of frequency of campaigns by pct budget spent.\nhist(df$pct.spent,\n     breaks = \"scott\",  # method for choosing number of buckets\n     main   = \"Histogram: fraction budget spent by campaignid\",\n     xlab   = \"Fraction of budget spent\",\n     ylab   = \"Frequency (count of campaignids)\")\n\n\n \nGeneral Layout and Ordering (google style):\n\nCopyright statement comment (?)\nAuthor comment\nFile description comment, including purpose of program, inputs, and outputs\nsource() and library() statements\nFunction definitions\nExecuted statements, if applicable (e.g., print, plot)"
  },
  {
    "objectID": "r_basics.html#r-documentation",
    "href": "r_basics.html#r-documentation",
    "title": "R basics",
    "section": "7 R documentation",
    "text": "7 R documentation\nMost R resources are extremely well documented. So the first source for help you should go to when writting R code is the R documention itself. All packages are documented in the same standard way. Getting familiar with the format can simplify things a lot.\nPackage documentation\n\n \nReference manuals\nReference manuals are collections of the documentation for all functions in a package (only 1 per package):\n\ndynaSpec manual\nbaRulho manual\n\n \nFunction documentation\nAll functions (default or from loaded packages) must have a documentation that follows a standard format:\n\n\nCode\n?mean\n\nhelp(\"mean\")\n\n\n  \nThis documentation can also be shown in Rstudio by pressing F1 when the cursor is on the function name\n \nIf you don’t recall the function name try apropos():\n\n\nCode\napropos(\"mean\")\n\n\n [1] \".colMeans\"     \".rowMeans\"     \"colMeans\"      \"kmeans\"       \n [5] \"mean\"          \"mean.Date\"     \"mean.default\"  \"mean.difftime\"\n [9] \"mean.POSIXct\"  \"mean.POSIXlt\"  \"rowMeans\"      \"weighted.mean\"\n\n\n \nVignettes\nVignettes are illustrative documents or study cases detailing the use of a package (optional, can be several per package).\nVignettes can be called directly from R:\n\n\nCode\nvgn <- browseVignettes() \n\n\n\n\nCode\nvignette()\n\n\nThey should also be listed in the package CRAN page.\n \nDemonstrations\nPackages may also include extended code demonstrations (‘demos’). To list demos in a package run demo(\"package name\"):\n\n\nCode\ndemo(package=\"stats\")\n\n# call demo directly\ndemo(\"nlm\")\n\n\n \n\nExercise\n \n\nWhat does the function cut() do?\nWhat is the breaks argument in cut() used for?\nRun the first 4 lines of code in the examples supplied in the cut() documentation\nHow many vignettes does the package warbleR has?"
  },
  {
    "objectID": "r_basics.html#references",
    "href": "r_basics.html#references",
    "title": "R basics",
    "section": "8 References",
    "text": "8 References\n\nAdvanced R, H Wickham\nGoogle’s R Style Guide\n\nHands-On Programming with R (Grolemund, 2014)"
  },
  {
    "objectID": "spectrograms.html",
    "href": "spectrograms.html",
    "title": "Building spectrograms",
    "section": "",
    "text": "The spectrogram is a fundamental tool in the study of acoustic communication in vertebrates. They are basically a visual representation of the sound where the variation in energy (or power spectral density) is shown on both the frequency and the time domains. Spectrograms allow us to visually explore acoustic variation in our study systems, which makes it easy to distinguish structural differences at small temporal/spectral scales that our ears cannot detect.\nWe will use the seewave package and its sample data:"
  },
  {
    "objectID": "spectrograms.html#fourier-transformation",
    "href": "spectrograms.html#fourier-transformation",
    "title": "Building spectrograms",
    "section": "1 Fourier transformation",
    "text": "1 Fourier transformation\nIn order to understand the information contained in a spectrogram it is necessary to understand, at least briefly, the Fourier transformation. In simple words, this is a mathematical transformation that detects the periodicity in time series, identifying the different frequencies that compose them and their relative energy. Therefore it is said that it transforms the signals from the time domain to the frequency domain.\nTo better understand how it works, we can simulate time series composed of pre-defined frequencies. In this example we simulate 3 frequencies and join them in a single time series:\n\n\nCode\n# freq\nf <- 11025\n\n# time sequence\nt <- seq(1/f, 1, length.out = f)\n\n# period\npr <- 1/440\nw0 <- 2 * pi/pr\n\n# frec 1\nh1 <- 5 * cos(w0 * t)\n\nplot(h1[1:75], type = \"l\", col = \"blue\", xlab = \"Time (samples)\", ylab = \"Amplitude (no units)\")\n\n\n\n\n\nCode\n# frec 2\nh2 <- 10 * cos(2 * w0 * t)\n\nplot(h2[1:75], type = \"l\", col = \"blue\", xlab = \"Time (samples)\", ylab = \"Amplitude (no units)\")\n\n\n\n\n\nCode\n# frec 3\nh3 <- 15 * sin(3 * w0 * t)\n\nplot(h3[1:75], type = \"l\", col = \"blue\", xlab = \"Time (samples)\", ylab = \"Amplitude (no units)\")\n\n\n\n\n\nThis is what the union of the three frequencies looks like:\n\n\nCode\nH0 <- 0.5 + h1 + h2 + h3\n\nplot(H0[1:75], type = \"l\", col = \"blue\", xlab = \"Time (samples)\", ylab = \"Amplitude (no units)\")\n\n\n\n\n\nNow we can apply the Fourier transform to this time series and graph the frequencies detected using a periodogram:\n\n\nCode\nfspc <- Mod(fft(H0))\n\nplot(fspc, type = \"h\", col = \"blue\", xlab = \"Frecuency (Hz)\", ylab = \"Amplitude (no units)\")\n\nabline(v = f/2, lty = 2)\n\ntext(x = (f/2) + 1650, y = 8000, \"Nyquist Frequency\")\n\n\n\n\n\nWe can make zoom in to frequencies below the Nyquist frequency:\n\n\nCode\nplot(fspc[1:(length(fspc)/2)], type = \"h\", col = \"blue\", xlab = \"Frecuency (Hz)\",\n    ylab = \"Amplitude (no units)\")\n\n\n\n\n\nThis diagram (taken from Sueur 2018) summarizes the process we just simulated:\n\n\n\n\n\n\n\n\n\nTomado de Sueur 2018\nThe periodogram next to the spectrogram of these simulated sounds looks like this:"
  },
  {
    "objectID": "spectrograms.html#from-the-fourier-transformation-to-the-spectrogram",
    "href": "spectrograms.html#from-the-fourier-transformation-to-the-spectrogram",
    "title": "Building spectrograms",
    "section": "2 From the Fourier transformation to the spectrogram",
    "text": "2 From the Fourier transformation to the spectrogram\nThe spectrograms are constructed of the spectral decomposition of discrete time segments of amplitude values. Each segment (or window) of time is a column of spectral density values in a frequency range. Take for example this simple modulated sound, which goes up and down in frequency:\n\n\n\n\n\n \nIf we divide the sound into 10 segments and make periodograms for each of them we can see this pattern in the frequencies:\n\n\n\n\n\n\n\nThis animation shows in a very simple way the logic behind the spectrograms: if we calculate Fourier transforms for short segments of time through a sound (e.g. amplitude changes in time) and concatenate them, we can visualize the variation in frequencies over time."
  },
  {
    "objectID": "spectrograms.html#overlap",
    "href": "spectrograms.html#overlap",
    "title": "Building spectrograms",
    "section": "3 Overlap",
    "text": "3 Overlap\nWhen frequency spectra are combined to produce a spectrogram, the frequency and amplitude modulations are not gradual:\n\n\n\n\n\n \nThere are several “tricks” to smooth out the contours of signals with high modulation in a spectrogram, although the main and most common is window overlap. The overlap recycles a percentage of the amplitude samples of a window to calculate the next window. For example, the sound used as an example, with a window size of 512 points divides the sound into 15 segments:\n\n\n\n\n\nA 50% overlap generates windows that share 50% of the amplitude values with the adjacent windows. This has the visual effect of making modulations much more gradual:\n\n\n\n\n\nWhich increases (in some way artificially) the number of time windows, without changing the resolution in frequency. In this example, the number of time windows is doubled:\n\n\n\n\n\nTherefore, the greater the overlap the greater the smoothing of the contours of the sounds:\n\n\n\n\nThis increases the number of windows as a function of the overlap for this particular sound:\n\n\n\n\n\n \nThis increase in spectrogram sharpness does not come without a cost. The longer the time windows, the greater the number of Fourier transformations to compute, and therefore, the greater the duration of the process. This graphic shows the increase in duration as a function of the number of windows on my computer:\n\n\n\n\n\n\n\n\n \nIt is necessary to take this cost into account when producing spectrograms of long sound files (> 1 min)."
  },
  {
    "objectID": "spectrograms.html#limitations",
    "href": "spectrograms.html#limitations",
    "title": "Building spectrograms",
    "section": "4 Limitations",
    "text": "4 Limitations\nHowever, there is a trade-off between the resolution between the 2 domains: the higher the frequency resolution, the lower the resolution in time. The following animation shows, for the sound of the previous example, how the resolution in frequency decreases as the resolution in time increases:\n\n\n\n\n \nThis is the relationship between frequency resolution and time resolution for the example signal:"
  },
  {
    "objectID": "spectrograms.html#creating-spectrograms-in-r",
    "href": "spectrograms.html#creating-spectrograms-in-r",
    "title": "Building spectrograms",
    "section": "5 Creating spectrograms in R",
    "text": "5 Creating spectrograms in R\nThere are several R packages with functions that produce spectrograms in the graphical device. This chart (taken from Sueur 2018) summarizes the functions and their arguments: \n \nWe will focus on making spectrograms using the spectro () function of seewave:\n\n\nCode\ntico2 <- cutw(tico, from = 0.55, to = 0.9, output = \"Wave\")\n\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = FALSE)\n\n\n\n\n\n \n\nExercise\n\nHow can I increase the overlap between time windows?\nHow much longer it takes to create a 99%-overlap spectrogram compare to a 5%-overlap spectrogram?\nWhat does the argument ‘collevels’ do? Increase the range and look at the spectrogram.\nWhat do the ‘flim’ and ‘tlim’ arguments determine?\nRun the examples that come in the spectro() function documentation\n\n\n \nAlmost all components of a spectrogram in seewave can be modified. We can add scales:\n\n\nCode\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = TRUE)\n\n\n\n\n\nChange the color palette:\n\n\nCode\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = TRUE, palette = reverse.cm.colors)\n\n\n\n\n\n\n\nCode\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = TRUE, palette = reverse.gray.colors.1)\n\n\n\n\n\nRemove the vertical lines:\n\n\nCode\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = TRUE, palette = reverse.gray.colors.1, grid = FALSE)\n\n\n\n\n\nAdd oscillograms (waveforms):\n\n\nCode\nspectro(tico2, f = 22050, wl = 512, ovlp = 90, collevels = seq(-40, 0, 0.5), flim = c(2,\n    6), scale = TRUE, palette = reverse.gray.colors.1, grid = FALSE, osc = TRUE)\n\n\n\n\n\n \n\nExercise\n\nChange the color of the oscillogram to red\nThese are some of the color palettes that fit well the gradients in spectrograms:  \n\n\nFrom Sueur 2018\n \nUse at least 3 palettes to generate the “tico2” spectrogram\n \n\nChange the relative height of the oscillogram so that it corresponds to 1/3 of the height of the spectrogram\nChange the relative width of the amplitude scale so that it corresponds to 1/8 of the spectrogram width\nWhat does the “zp” argument do? (hint: try zp = 100 and notice the effect on the spectrogram)\nWhich value of “wl” (window size) generates smoother spectrograms for the example “orni” object?\nThe package viridis provides some color palettes that are better perceived by people with forms of color blindness and/or color vision deficiency. Install the package and try some of the color palettes available (try ?viridis)"
  },
  {
    "objectID": "spectrograms.html#dynamic-spectrograms",
    "href": "spectrograms.html#dynamic-spectrograms",
    "title": "Building spectrograms",
    "section": "6 Dynamic spectrograms",
    "text": "6 Dynamic spectrograms\nThe package dynaSpec allows to create static and dynamic visualizations of sounds, ready for publication or presentation. These dynamic spectrograms are produced natively with base graphics, and are save as an .mp4 video in the working directory:\n\n\nCode\nngh_wren <- read_sound_file(\"https://www.xeno-canto.org/518334/download\")\n\ncustom_pal <- colorRampPalette(c(\"#2d2d86\", \"#2d2d86\", reverse.terrain.colors(10)[5:10]))\n\nlibrary(dynaSpec)\n\nscrolling_spectro(wave = ngh_wren, wl = 600, t.display = 3, ovlp = 95, pal = custom_pal,\n    grid = FALSE, flim = c(2, 8), width = 700, height = 250, res = 100, collevels = seq(-40,\n        0, 5), file.name = \"../nightingale_wren.mp4\", colbg = \"#2d2d86\", lcol = \"#FFFFFFE6\")"
  },
  {
    "objectID": "spectrograms.html#references",
    "href": "spectrograms.html#references",
    "title": "Building spectrograms",
    "section": "7 References",
    "text": "7 References\n\nAraya-Salas, Marcelo and Wilkins, Matthew R. (2020), dynaSpec: dynamic spectrogram visualizations in R. R package version 1.0.0.\nSueur J, Aubin T, Simonis C. 2008. Equipment review: seewave, a free modular tool for sound analysis and synthesis. Bioacoustics 18(2):213–226.\nSueur, J. (2018). Sound Analysis and Synthesis with R.\n\n\n \nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] seewave_2.2.0 knitr_1.42   \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     MASS_7.3-58.2     jsonlite_1.8.4    signal_0.7-7     \n [5] formatR_1.12      evaluate_0.21     rlang_1.1.1       cli_3.6.1        \n [9] rstudioapi_0.14   rmarkdown_2.21    tools_4.2.2       tuneR_1.4.4      \n[13] htmlwidgets_1.5.4 xfun_0.39         yaml_2.3.7        fastmap_1.1.1    \n[17] compiler_4.2.2    monitoR_1.0.7     htmltools_0.5.5"
  },
  {
    "objectID": "course_prep.html",
    "href": "course_prep.html",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "",
    "text": "Install or update R on the computer you will use during the course (https://cran.r-project.org). I assume that you already have it installed, but try to update it if you have a R version < 4.0.0. You can find which R version you have by running this in the R console:\n\n\n\nCode\nversion$version.string\n\n\n\nInstall or update the RStudio interface (https://www.rstudio.com/products/rstudio/download/, choose the free version). Optional but advised.\nMake a directory called “BIR_OTS_2023”, this will be your working directory for the course.\nOpen RStudio and select the tab “Tools” then “Global Options” (last option). Select the “Code” option, then select the box for “Soft-wrap R source files”.\nAlso in Rstudio: Select the “Pane Layout” option and move “Source” to the top left pane and “Console” to the top right pane. For those of you unfamiliar with RStudio, the source is your script, where you save code in a physical file (usually .R script) and the console prints the output of the code you run from the source. You can write code in the console, but it will not be saved in a physical file. This layout allocates more screen space to the most useful panes. Hit “Apply” and “Ok”.\nAlso in Rstudio: Go back up to the “File” tab and select “New Project”, then select the “BIR_OTS_2023” directory.\nNow in the R console in Rstudio: Run the following code to install the latest developmental versions (from github) of warbleR, Rraven, PhenotypeSpace, ohun, baRulho and dynaSpec (remove the packages first if you have them installed already).\n\n\n\nCode\n# package to install other packages from github\ninstall.packages(\"remotes\") \n\n# install from github\nremotes::install_github(\"maRce10/warbleR\")\nremotes::install_github(\"maRce10/Rraven\")\nremotes::install_github(\"maRce10/ohun\")\nremotes::install_github(\"spatstat/spatstat.core\") \nremotes::install_github(\"maRce10/PhenotypeSpace\")\nremotes::install_github(\"maRce10/baRulho\")\nremotes::install_github(\"maRce10/dynaSpec\")\n\n# install from CRAN\ninstall.packages(\"pracma\")\ninstall.packages(\"Sim.DiffProc\")\ninstall.packages(\"bioacoustics\")\ninstall.packages(\"phonTools\")\ninstall.packages(\"soundgen\")\n\n\n\nif you have any issue installing ‘bioacoustics’ take a look at this fix: https://stackoverflow.com/questions/53092646/unable-to-install-warbler-package-using-mac-os\n\n\nwarbleR depends heavily on the R package seewave. Seewave may require some extra steps to get installed. Take a look at seewave’s website for further help: http://rug.mnhn.fr/seewave (and then go to “installation” and scroll down)\nInstall Raven lite (scroll down to “Raven Lite 2.0” and click on “Order Free Raven Lite 2.0 License”):\n\nhttp://ravensoundsoftware.com/raven-pricing/\n\nInstall ffmpeg (only needed for dynaSpec package, not critical):\n\nhttps://ffmpeg.org/download.html\ntake a look at this link if you have issues installing ffmpeg on windows:\nhttps://github.com/maRce10/dynaSpec/issues/3\n\nInstall Audacity (not critical, you can use Adobe Audition instead):\n\nhttps://www.audacityteam.org/download/\n\nInstall SOX. It can be downloaded from here (not critical but could be useful): http://sox.sourceforge.net (Not critical)\nInstall FLAC. It can be downloaded from here (also not critical): https://xiph.org/flac/download.html (Not critical)\nNote that you can also run the code using google colab. Take a look at this notebook: https://colab.research.google.com/\n\n \n\nA few tips to make sure you will take full advantage of the course:\n \n\nSet aside a physical space, hopefully as isolated as possible from external stimuli\nUse headphones/earphones to avoid any interference from echoes or external noises\nIdeally, read the materials ahead of time (I know! it’s time comsuming)\nMake sure you have anything you need before the start of the class\nBe ready a few minutes before the start of the class\nTry to focus as much as possible in the course, close other programs or unnecessary internet browser tabs (i.e. instagram, twitter, etc). This will also make the computer more efficient (less likely to get slow)\nComment your code"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "",
    "text": "Bioacoustic Analysis in R\n\n\nOrganization for Tropical Studies\n\n\n\nMarcelo Araya-Salas, PhD\n\n\n\nMay 15 - 19, 2023\n\n\n\n\n \nThe study of animal acoustic signals is a central tool for many fields in behavior, ecology, evolution and biodiversity monitoring. The accessibility of recording equipment and growing availability of open-access acoustic libraries provide an unprecedented opportunity to study animal acoustic signals at large temporal, geographic and taxonomic scales. However, the diversity of analytical methods and the multidimensionality of these signals posts significant challenges to conduct analyses that can quantify biologically meaningful variation. The recent development of acoustic analysis tools in the R programming environment provides a powerful means for overcoming these challenges, facilitating the gathering and organization of large acoustic data sets and the use of more elaborated analyses that better fit the studied acoustic signals and associated biological questions. The course will introduce students on the basic concepts in animal acoustic signal research as well as hands-on experience on analytical tools in R.\n\nObjetive\nTraining biological science students and researchers in the detection and analysis of animal sounds in R. Specifically, it seeks to familiarize participants with computational tools in the R environment aiming at curating, detecting and analyzing animal acoustic signals, with an especial focus on quantifying fine-scale structural variation. The course will introduce the most relevant acoustics concepts to allow a detailed understanding of the metrics used for characterize acoustic signals. It will also guide participants through a variety of R packages for bioacoustics analysis, including seewave, tuneR, warbleR and baRulho."
  },
  {
    "objectID": "introduction.html#section",
    "href": "introduction.html#section",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "",
    "text": "Why animal sounds and why R?\n\n \n\nMarcelo Araya-Salas PhD\n\n\nNeuroscience Research Center\n\n\nUniversity of Costa Rica"
  },
  {
    "objectID": "introduction.html#animal-acoustic-signals",
    "href": "introduction.html#animal-acoustic-signals",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Animal acoustic signals",
    "text": "Animal acoustic signals"
  },
  {
    "objectID": "introduction.html#animal-acoustic-signals-1",
    "href": "introduction.html#animal-acoustic-signals-1",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Animal acoustic signals",
    "text": "Animal acoustic signals"
  },
  {
    "objectID": "introduction.html#common-research-questions",
    "href": "introduction.html#common-research-questions",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Common research questions",
    "text": "Common research questions\n\nHow animal acoustic signals vary in space and time? why?\nWhat is their function?\nWhat socio-ecological factors favor the evolution of specific features?\nHow the transmission properties of the environment have shaped signal structure?"
  },
  {
    "objectID": "introduction.html#acoustic-analysis-workflow",
    "href": "introduction.html#acoustic-analysis-workflow",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Acoustic analysis workflow",
    "text": "Acoustic analysis workflow"
  },
  {
    "objectID": "introduction.html#why-bioacoustics-in-r",
    "href": "introduction.html#why-bioacoustics-in-r",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Why bioacoustics in R?",
    "text": "Why bioacoustics in R?\n\nImproves reproducibility of research\nAllows conducting analyses that better fit our research questions and study systems\nDemocratizes access to scientific resources"
  },
  {
    "objectID": "introduction.html#course-outline",
    "href": "introduction.html#course-outline",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Course outline",
    "text": "Course outline\n\nTutorials with combinations of theoretical background, demonstrations and proofs of concept using R code and self-learning practices on their own acoustic data or supplied example data\nAdditional practices and readings assigned after each session"
  },
  {
    "objectID": "intro_to_warbler.html",
    "href": "intro_to_warbler.html",
    "title": "Introduction to warbleR",
    "section": "",
    "text": "The warbleR package is intended to facilitate the analysis of the structure of animal acoustic signals in R. Users can enter their own data into a workflow that facilitates spectrographic visualization and measurement of acoustic parameters warbleR makes use of the fundamental sound analysis tools of the seewave package, and offers new tools for acoustic structure analysis. These tools are available for batch analysis of acoustic signals.\nThe main features of the package are:\nThe package offers functions for:\nMost functions allow the parallelization of tasks, which distributes the tasks among several cores to improve computational efficiency. Tools to evaluate the performance of the analysis at each step are also available. All these tools are provided in a standardized workflow for the analysis of the signal structure, making them accessible to a wide range of users, including those without much knowledge of R.\nwarbleR is a young package (officially published in 2017) currently in a maturation stage:"
  },
  {
    "objectID": "intro_to_warbler.html#selection-tables",
    "href": "intro_to_warbler.html#selection-tables",
    "title": "Introduction to warbleR",
    "section": "1 Selection tables",
    "text": "1 Selection tables\nThese objects are created with the selection_table() function. The function takes data frames containing selection data (name of the sound file, selection, start, end …), verifies if the information is consistent (see the function check_sels() for details) and saves the ‘diagnostic’ metadata as an attribute. The selection tables are basically data frames in which the information contained has been corroborated so it can be read by other warbleR functions. The selection tables must contain (at least) the following columns:\n\nsound files (sound.files)\nselection (select)\nstart\nend\n\nThe sample data “lbh_selec_table” contains these columns:\n\n\n\n\n\nCode\ndata(\"lbh_selec_table\")\n\nlbh_selec_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nPhae.long1.wav\n1\n1\n1.1693549\n1.3423884\n2.220105\n8.604378\n\n\nPhae.long1.wav\n1\n2\n2.1584085\n2.3214565\n2.169437\n8.807053\n\n\nPhae.long1.wav\n1\n3\n0.3433366\n0.5182553\n2.218294\n8.756604\n\n\nPhae.long2.wav\n1\n1\n0.1595983\n0.2921692\n2.316862\n8.822316\n\n\nPhae.long2.wav\n1\n2\n1.4570585\n1.5832087\n2.284006\n8.888027\n\n\nPhae.long3.wav\n1\n1\n0.6265520\n0.7577715\n3.006834\n8.822316\n\n\nPhae.long3.wav\n1\n2\n1.9742132\n2.1043921\n2.776843\n8.888027\n\n\nPhae.long3.wav\n1\n3\n0.1233643\n0.2545812\n2.316862\n9.315153\n\n\nPhae.long4.wav\n1\n1\n1.5168116\n1.6622365\n2.513997\n9.216586\n\n\nPhae.long4.wav\n1\n2\n2.9326920\n3.0768784\n2.579708\n10.235116\n\n\nPhae.long4.wav\n1\n3\n0.1453977\n0.2904966\n2.579708\n9.742279\n\n\n\n\n\n\n \n… and can be converted to the selection_table format like this:\n\n\nCode\n# global parameters\nwarbleR_options(wav.path = \"./examples\")\n\nst <- selection_table(X = lbh_selec_table, pb = FALSE)\n\nst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\n\n\n\n\nPhae.long1.wav\n1\n1\n1.1693549\n1.3423884\n2.220105\n8.604378\n\n\nPhae.long1.wav\n1\n2\n2.1584085\n2.3214565\n2.169437\n8.807053\n\n\nPhae.long1.wav\n1\n3\n0.3433366\n0.5182553\n2.218294\n8.756604\n\n\nPhae.long2.wav\n1\n1\n0.1595983\n0.2921692\n2.316862\n8.822316\n\n\nPhae.long2.wav\n1\n2\n1.4570585\n1.5832087\n2.284006\n8.888027\n\n\nPhae.long3.wav\n1\n1\n0.6265520\n0.7577715\n3.006834\n8.822316\n\n\nPhae.long3.wav\n1\n2\n1.9742132\n2.1043921\n2.776843\n8.888027\n\n\nPhae.long3.wav\n1\n3\n0.1233643\n0.2545812\n2.316862\n9.315153\n\n\nPhae.long4.wav\n1\n1\n1.5168116\n1.6622365\n2.513997\n9.216586\n\n\nPhae.long4.wav\n1\n2\n2.9326920\n3.0768784\n2.579708\n10.235116\n\n\nPhae.long4.wav\n1\n3\n0.1453977\n0.2904966\n2.579708\n9.742279\n\n\n\n\n\n\nNote that the path to the sound files has been provided. This is necessary in order to verify that the data provided conforms to the characteristics of the audio files.\nSelection tables have their own class in R:\n\n\nCode\nclass(st)\n\n\n[1] \"selection_table\" \"data.frame\"     \n\n\n \n\n1.1 Extended selection tables\nWhen the extended = TRUE argument the function generates an object of the extended_selection_table class that also contains a list of ‘wave’ objects corresponding to each of the selections in the data. Therefore, the function transforms the selection table into self-contained objects since the original sound files are no longer needed to perform most of the acoustic analysis in warbleR. This can greatly facilitate the storage and exchange of (bio)acoustic data. In addition, it also speeds up analysis, since it is not necessary to read the sound files every time the data is analyzed.\nNow, as mentioned earlier, you need the selection_table() function to create an extended selection table. You must also set the argument extended = TRUE (otherwise, the class would be a selection table). The following code converts the sample data into an extended selection table:\n\n\nCode\n#  global parameters\nwarbleR_options(wav.path = \"./examples\")\n\next_st <- selection_table(X = lbh_selec_table, pb = FALSE, \n          extended = TRUE, confirm.extended = FALSE)\n\n\n\n\n\n \nAnd that is. Now the acoustic data and the selection data (as well as the additional metadata) are all together in a single R object.\n \n\nExercise\n \n\nRun the example code in the selection_table() function documentation\nWhat do the arguments “mar”, “by.song” and “whole.recs” do?\n\n\n \n\n\n1.2 Handling extended selection tables\nSeveral functions can be used to deal with objects of this class. You can test if the object belongs to the extended_selection_table:\n\n\nCode\nis_extended_selection_table(ext_st)\n\n\n[1] TRUE\n\n\n \nYou can subset the selection in the same way that any other data frame and it will still keep its attributes:\n\n\nCode\next_st2 <- ext_st[1:2, ]\n\nis_extended_selection_table(ext_st2)\n\n\n[1] TRUE\n\n\nThere is also a generic version of print() for this class of objects:\n\n\nCode\n## print\nprint(ext_st)\n\n\nObject of class 'extended_selection_table'\n\n\n* The output of the following call:\n\n\nselection_table(X = lbh_selec_table, extended = TRUE, confirm.extended = FALSE,  pb = FALSE)\n\n\n\nContains: \n*  A selection table data frame with 11 row(s) and 7 columns:\n\n\n|sound.files      | channel| selec| start|    end| bottom.freq|\n\n\n|:----------------|-------:|-----:|-----:|------:|-----------:|\n\n\n|Phae.long1.wav_1 |       1|     1|   0.1| 0.2730|      2.2201|\n\n\n|Phae.long1.wav_2 |       1|     1|   0.1| 0.2630|      2.1694|\n\n\n|Phae.long1.wav_3 |       1|     1|   0.1| 0.2749|      2.2183|\n\n\n|Phae.long2.wav_1 |       1|     1|   0.1| 0.2326|      2.3169|\n\n\n|Phae.long2.wav_2 |       1|     1|   0.1| 0.2262|      2.2840|\n\n\n|Phae.long3.wav_1 |       1|     1|   0.1| 0.2312|      3.0068|\n\n\n... 1 more column(s) (top.freq)\n\n\n and 5 more row(s)\n\n\n\n* 11 wave object(s) (as attributes): \n\n\nPhae.long1.wav_1Phae.long1.wav_2Phae.long1.wav_3Phae.long2.wav_1Phae.long2.wav_2Phae.long3.wav_1\n\n\n... and 5 more\n\n\n\n* A data frame (check.results) generated by check_sels() (as attribute)\n\n\n\nThe selection table was created by element (see 'class_extended_selection_table')\n\n\n* 1 sampling rate(s) (in kHz): 22.5\n\n\n* 1 bit depth(s): 16\n\n\n* Created by warbleR 1.1.28\n\n\n… which is equivalent to:\n\n\nCode\next_st\n\n\n\n\nObject of class 'extended_selection_table'\n\n\n* The output of the following call:\n\n\nselection_table(X = lbh_selec_table, extended = TRUE, confirm.extended = FALSE,  pb = FALSE)\n\n\n\nContains: \n*  A selection table data frame with 11 row(s) and 7 columns:\n\n\n|sound.files      | channel| selec| start|    end| bottom.freq|\n\n\n|:----------------|-------:|-----:|-----:|------:|-----------:|\n\n\n|Phae.long1.wav_1 |       1|     1|   0.1| 0.2730|      2.2201|\n\n\n|Phae.long1.wav_2 |       1|     1|   0.1| 0.2630|      2.1694|\n\n\n|Phae.long1.wav_3 |       1|     1|   0.1| 0.2749|      2.2183|\n\n\n|Phae.long2.wav_1 |       1|     1|   0.1| 0.2326|      2.3169|\n\n\n|Phae.long2.wav_2 |       1|     1|   0.1| 0.2262|      2.2840|\n\n\n|Phae.long3.wav_1 |       1|     1|   0.1| 0.2312|      3.0068|\n\n\n... 1 more column(s) (top.freq)\n\n\n and 5 more row(s)\n\n\n\n* 11 wave object(s) (as attributes): \n\n\nPhae.long1.wav_1Phae.long1.wav_2Phae.long1.wav_3Phae.long2.wav_1Phae.long2.wav_2Phae.long3.wav_1\n\n\n... and 5 more\n\n\n\n* A data frame (check.results) generated by check_sels() (as attribute)\n\n\n\nThe selection table was created by element (see 'class_extended_selection_table')\n\n\n* 1 sampling rate(s) (in kHz): 22.5\n\n\n* 1 bit depth(s): 16\n\n\n* Created by warbleR 1.1.28\n\n\n \nYou can also join them in rows. Here the original extended_selection_table is divided into 2 and bound again using rbind():\n\n\nCode\next_st3 <- ext_st[1:5, ]\n\next_st4 <- ext_st[6:11, ]\n\next_st5 <- rbind(ext_st3, ext_st4)\n\n#print\next_st5\n\n\n\n\nObject of class 'extended_selection_table'\n\n\n* The output of the following call:\n\n\nrbind(deparse.level, ..1, ..2)\n\n\n\nContains: \n*  A selection table data frame with 11 row(s) and 7 columns:\n\n\n|sound.files      | channel| selec| start|    end| bottom.freq|\n\n\n|:----------------|-------:|-----:|-----:|------:|-----------:|\n\n\n|Phae.long1.wav_1 |       1|     1|   0.1| 0.2730|      2.2201|\n\n\n|Phae.long1.wav_2 |       1|     1|   0.1| 0.2630|      2.1694|\n\n\n|Phae.long1.wav_3 |       1|     1|   0.1| 0.2749|      2.2183|\n\n\n|Phae.long2.wav_1 |       1|     1|   0.1| 0.2326|      2.3169|\n\n\n|Phae.long2.wav_2 |       1|     1|   0.1| 0.2262|      2.2840|\n\n\n|Phae.long3.wav_1 |       1|     1|   0.1| 0.2312|      3.0068|\n\n\n... 1 more column(s) (top.freq)\n\n\n and 5 more row(s)\n\n\n\n* 11 wave object(s) (as attributes): \n\n\nPhae.long1.wav_1Phae.long1.wav_2Phae.long1.wav_3Phae.long2.wav_1Phae.long2.wav_2Phae.long3.wav_1\n\n\n... and 5 more\n\n\n\n* A data frame (check.results) generated by check_sels() (as attribute)\n\n\n\nThe selection table was created by element (see 'class_extended_selection_table')\n\n\n* 1 sampling rate(s) (in kHz): 22.5\n\n\n* 1 bit depth(s): 16\n\n\n* Created by warbleR 1.1.28\n\n\n\n\nCode\n# are they equal?\nall.equal(ext_st, ext_st5)\n\n\n[1] \"Attributes: < Component \\\"call\\\": target, current do not match when deparsed >\"\n\n\n \nThe ‘wave’ objects can be read individually using read_wave(), a wrapper for the readWave() function of tuneR, which can handle extended selection tables:\n\n\nCode\nwv1 <- read_wave(X = ext_st, index = 3, from = 0, to = 0.37)\n\n\n \nThese are regular ‘wave’ objects:\n\n\nCode\nclass(wv1)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\nwv1\n\n\n\nWave Object\n    Number of Samples:      8325\n    Duration (seconds):     0.37\n    Samplingrate (Hertz):   22500\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\nCode\nspectro(wv1, wl = 150, grid = FALSE, scale = FALSE, ovlp = 90)\n\n\n\n\n\n\n\nCode\npar(mfrow = c(3, 2), mar = rep(0, 4))\n\nfor(i in 1:6){\n  \n  wv <- read_wave(X = ext_st, index = i, from = 0.05, to = 0.32)\n\n  spectro(wv, wl = 150, grid = FALSE, scale = FALSE, axisX = FALSE,\n          axisY = FALSE, ovlp = 90)\n\n}\n\n\n\n\n\n \nThe read_wave() function requires the selection table, as well as the row index (i.e. the row number) to be able to read the ‘wave’ objects. It can also read a regular ‘wave’ file if the path is provided.\nNote that other functions that modify data frames are likely to delete the attributes in which the ‘wave’ objects and metadata are stored. For example, the merge and the extended selection box will remove its attributes:\n\n\nCode\n# create new data base\nY <- data.frame(sound.files = ext_st$sound.files, site = \"La Selva\", lek = c(rep(\"SUR\", 5), rep(\"CCL\", 6)))\n\n# combine\nmrg_ext_st <- merge(ext_st, Y, by = \"sound.files\")\n\n# check class\nis_extended_selection_table(mrg_ext_st)\n\n\n[1] FALSE\n\n\n \nIn this case, we can use the fix_extended_selection_table() function to transfer the attributes of the original extended selection table:\n\n\nCode\n# fix\nmrg_ext_st <- fix_extended_selection_table(X = mrg_ext_st, Y = ext_st)\n\n# check class\nis_extended_selection_table(mrg_ext_st)\n\n\n[1] TRUE\n\n\n \nThis works as long as some of the original sound files are retained and no other selections are added.\n& nbsp;\n\n\n1.3 Selection table size\nThe size of the extended selection box will depend on the number of selections, the sampling rate, the duration of the selection and the length of margins (i.e. additional time you want to keep on each side of the selection). In this example, a selection table with 1000 selections is created simply by repeating the sample data frame several times and then is converted to an extended selection table:\n\n\nCode\nlng.selec.table <- do.call(rbind, replicate(100, lbh_selec_table, \n                        simplify = FALSE))[1:1000,]\n\nlng.selec.table$selec <- 1:nrow(lng.selec.table)\n\nnrow(lng.selec.table)\n\nlng_ext_st <- selection_table(X = lng.selec.table, pb = FALSE, \n                        extended = TRUE, confirm.extended = FALSE)\n\nlng_ext_st\n\n\n\n\nObject of class 'extended_selection_table'\n\n\n* The output of the following call:\n\n\nselection_table(X = lng.selec.table, extended = TRUE, confirm.extended = FALSE,  pb = FALSE)\n\n\n\nContains: \n*  A selection table data frame with 1000 row(s) and 7 columns:\n\n\n|sound.files      | channel| selec| start|    end| bottom.freq|\n\n\n|:----------------|-------:|-----:|-----:|------:|-----------:|\n\n\n|Phae.long1.wav_1 |       1|     1|   0.1| 0.2730|      2.2201|\n\n\n|Phae.long1.wav_2 |       1|     1|   0.1| 0.2630|      2.1694|\n\n\n|Phae.long1.wav_3 |       1|     1|   0.1| 0.2749|      2.2183|\n\n\n|Phae.long2.wav_4 |       1|     1|   0.1| 0.2326|      2.3169|\n\n\n|Phae.long2.wav_5 |       1|     1|   0.1| 0.2262|      2.2840|\n\n\n|Phae.long3.wav_6 |       1|     1|   0.1| 0.2312|      3.0068|\n\n\n... 1 more column(s) (top.freq)\n\n\n and 994 more row(s)\n\n\n\n* 1000 wave object(s) (as attributes): \n\n\nPhae.long1.wav_1Phae.long1.wav_2Phae.long1.wav_3Phae.long2.wav_4Phae.long2.wav_5Phae.long3.wav_6\n\n\n... and 994 more\n\n\n\n* A data frame (check.results) generated by check_sels() (as attribute)\n\n\n\nThe selection table was created by element (see 'class_extended_selection_table')\n\n\n* 1 sampling rate(s) (in kHz): 22.5\n\n\n* 1 bit depth(s): 16\n\n\n* Created by warbleR 1.1.28\n\n\n\n\nCode\nformat(object.size(lng_ext_st), units = \"auto\")\n\n\n[1] \"31.4 Mb\"\n\n\n \nAs you can see, the object size is only ~ 31 MB. Then, as a guide, a selection box with 1000 selections similar to those of ‘lbh_selec_table’ (average duration of ~ 0.15 seconds) at a sampling rate of 22.5 kHz and the default margin (mar = 0.1) will generate an extended selection box ~ 31 MB or ~ 310 MB for a selection table of 10,000 rows.\n \n\n\n1.4 Analysis using extended selection tables\nThese objects can be used as input for most warbleR functions. Here are some examples of warbleR functions using extended_selection_table:\n\n1.4.1 Spectral parameters\n\n\nCode\n#  spectrographic parameters\nsp <- spectro_analysis(ext_st)\n\nsp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nselec\nduration\nmeanfreq\nsd\nfreq.median\nfreq.Q25\nfreq.Q75\nfreq.IQR\ntime.median\ntime.Q25\ntime.Q75\ntime.IQR\nskew\nkurt\nsp.ent\ntime.ent\nentropy\nsfm\nmeandom\nmindom\nmaxdom\ndfrange\nmodindx\nstartdom\nenddom\ndfslope\nmeanpeakf\n\n\n\n\nPhae.long1.wav_1\n1\n0.1730334\n5.981221\n1.399804\n6.331716\n5.296584\n6.869521\n1.572937\n0.0798564\n0.0532376\n0.1197846\n0.0665470\n2.001382\n7.025606\n0.9434888\n0.9493322\n0.8956843\n0.6518306\n6.663993\n5.251465\n7.360840\n2.109375\n2.895833\n7.316895\n7.185059\n-0.7619101\n7.108806\n\n\nPhae.long1.wav_2\n1\n0.1630480\n5.997299\n1.422930\n6.212125\n5.328746\n6.880795\n1.552049\n0.0815333\n0.0407667\n0.1223000\n0.0815333\n1.918356\n7.334323\n0.9468217\n0.9536154\n0.9029038\n0.6678647\n6.830116\n5.295410\n8.283691\n2.988281\n2.661765\n7.185059\n7.229004\n0.2695238\n6.931635\n\n\nPhae.long1.wav_3\n1\n0.1749187\n6.018300\n1.514853\n6.424759\n5.150246\n6.979144\n1.828898\n0.0941949\n0.0538256\n0.1345641\n0.0807385\n2.496740\n11.147728\n0.9450838\n0.9515916\n0.8993339\n0.6716602\n6.773856\n4.899902\n8.371582\n3.471680\n3.240506\n7.185059\n7.185059\n0.0000000\n6.798757\n\n\nPhae.long2.wav_1\n1\n0.1325709\n6.398304\n1.340412\n6.595971\n5.607323\n7.380852\n1.773529\n0.0736543\n0.0589235\n0.1031160\n0.0441926\n1.568523\n6.016392\n0.9424661\n0.9433998\n0.8891223\n0.6086184\n6.341309\n5.075684\n7.404785\n2.329102\n2.830189\n5.075684\n6.657715\n11.9334722\n7.463147\n\n\nPhae.long2.wav_2\n1\n0.1261502\n6.308252\n1.369242\n6.596836\n5.605837\n7.207292\n1.601455\n0.0840889\n0.0560593\n0.0981037\n0.0420444\n2.470897\n10.896039\n0.9357725\n0.9436684\n0.8830589\n0.6152336\n6.411621\n5.075684\n7.580566\n2.504883\n2.087719\n5.075684\n7.580566\n19.8563528\n6.710171\n\n\nPhae.long3.wav_1\n1\n0.1312195\n6.605993\n1.090498\n6.665328\n6.063201\n7.336052\n1.272851\n0.0583111\n0.0437333\n0.1020444\n0.0583111\n1.770551\n6.665163\n0.9303558\n0.9460672\n0.8801790\n0.5664857\n6.481934\n4.899902\n7.009277\n2.109375\n1.520833\n4.899902\n6.965332\n15.7402610\n6.710171\n\n\nPhae.long3.wav_2\n1\n0.1301789\n6.639859\n1.117356\n6.674164\n6.105325\n7.427493\n1.322168\n0.0723210\n0.0433926\n0.1012494\n0.0578568\n1.545851\n4.969900\n0.9232849\n0.9490351\n0.8762298\n0.5317422\n6.244629\n5.031738\n6.701660\n1.669922\n1.368421\n5.031738\n6.613770\n12.1527447\n6.665879\n\n\nPhae.long3.wav_3\n1\n0.1312170\n6.580739\n1.253000\n6.646959\n6.029463\n7.394054\n1.364591\n0.0583111\n0.0437333\n0.1020444\n0.0583111\n1.802520\n5.886959\n0.9191879\n0.9533815\n0.8763367\n0.5258369\n6.231445\n5.427246\n6.833496\n1.406250\n1.656250\n5.471191\n6.657715\n9.0424551\n6.710171\n\n\nPhae.long4.wav_1\n1\n0.1454249\n6.219479\n1.478869\n6.233074\n5.456261\n7.305488\n1.849227\n0.0872533\n0.0436267\n0.1163378\n0.0727111\n1.274811\n4.458109\n0.9643357\n0.9520564\n0.9181020\n0.7599268\n6.270197\n5.119629\n7.844238\n2.724609\n2.709677\n5.383301\n6.262207\n6.0437118\n6.222951\n\n\nPhae.long4.wav_2\n1\n0.1441864\n6.462809\n1.592876\n6.338070\n5.630777\n7.572366\n1.941589\n0.0865067\n0.0432533\n0.1153422\n0.0720889\n1.695847\n6.442755\n0.9585943\n0.9526078\n0.9131645\n0.7199148\n6.294167\n4.108887\n8.151855\n4.042969\n2.478261\n5.427246\n4.108887\n-9.1434347\n6.222951\n\n\nPhae.long4.wav_3\n1\n0.1450989\n6.122156\n1.541046\n6.081716\n5.178639\n7.239860\n2.061221\n0.0870667\n0.0435333\n0.1160889\n0.0725556\n1.083042\n4.194037\n0.9642064\n0.9536971\n0.9195608\n0.7332565\n6.150346\n4.943848\n7.888184\n2.944336\n3.149254\n5.339355\n5.031738\n-2.1200514\n5.912903\n\n\n\n\n\n\n \n\n\n1.4.2 Signal-to-noise ratio\n\n\nCode\nsnr <- sig2noise(ext_st, mar = 0.05)\n\nsnr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\nSNR\n\n\n\n\nPhae.long1.wav_1\n1\n1\n0.1\n0.2730334\n2.220105\n8.604378\n21.17229\n\n\nPhae.long1.wav_2\n1\n1\n0.1\n0.2630480\n2.169437\n8.807053\n20.36896\n\n\nPhae.long1.wav_3\n1\n1\n0.1\n0.2749187\n2.218294\n8.756604\n19.18211\n\n\nPhae.long2.wav_1\n1\n1\n0.1\n0.2325709\n2.316862\n8.822316\n23.27961\n\n\nPhae.long2.wav_2\n1\n1\n0.1\n0.2261502\n2.284006\n8.888027\n26.21774\n\n\nPhae.long3.wav_1\n1\n1\n0.1\n0.2312195\n3.006834\n8.822316\n25.34264\n\n\nPhae.long3.wav_2\n1\n1\n0.1\n0.2301789\n2.776843\n8.888027\n25.51099\n\n\nPhae.long3.wav_3\n1\n1\n0.1\n0.2312170\n2.316862\n9.315153\n24.68619\n\n\nPhae.long4.wav_1\n1\n1\n0.1\n0.2454249\n2.513997\n9.216586\n27.61899\n\n\nPhae.long4.wav_2\n1\n1\n0.1\n0.2441864\n2.579708\n10.235116\n28.87451\n\n\nPhae.long4.wav_3\n1\n1\n0.1\n0.2450989\n2.579708\n9.742279\n24.30149\n\n\n\n\n\n\n \n\n\n1.4.3 Dynamic time warping (DTW)\n\n\nCode\ndtw.dist <- freq_DTW(ext_st, img = FALSE)\n\ndtw.dist\n\n\n\n\nCode\ndtw.dist <- freq_DTW(ext_st, img = FALSE)\n\n\nmeasuring dominant frequency contours (step 1 of 2): \n\n\nMeasuring fundamental frequency:\n\n\ncalculating DTW distances (step 2 of 2, no progress bar):\n\n\nCode\nas.data.frame(dtw.dist)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhae.long1.wav_1-1\nPhae.long1.wav_2-1\nPhae.long1.wav_3-1\nPhae.long2.wav_1-1\nPhae.long2.wav_2-1\nPhae.long3.wav_1-1\nPhae.long3.wav_2-1\nPhae.long3.wav_3-1\nPhae.long4.wav_1-1\nPhae.long4.wav_2-1\nPhae.long4.wav_3-1\n\n\n\n\nPhae.long1.wav_1-1\n0.0000\n8.6272\n4.3390\n16.6319\n16.6161\n13.8153\n15.6860\n15.5245\n18.6621\n20.8855\n21.5606\n\n\nPhae.long1.wav_2-1\n8.6272\n0.0000\n6.9803\n22.1235\n29.1274\n16.7363\n22.3731\n23.0249\n15.8250\n16.6372\n19.4517\n\n\nPhae.long1.wav_3-1\n4.3390\n6.9803\n0.0000\n18.2558\n20.5344\n15.2054\n18.4506\n16.4662\n17.2609\n19.1440\n21.1586\n\n\nPhae.long2.wav_1-1\n16.6319\n22.1235\n18.2558\n0.0000\n12.1572\n10.3686\n11.2207\n12.0419\n12.4495\n13.5389\n15.3083\n\n\nPhae.long2.wav_2-1\n16.6161\n29.1274\n20.5344\n12.1572\n0.0000\n6.7586\n5.3403\n8.6988\n17.5231\n20.5990\n18.9194\n\n\nPhae.long3.wav_1-1\n13.8153\n16.7363\n15.2054\n10.3686\n6.7586\n0.0000\n3.6377\n4.4201\n13.2529\n15.6284\n15.6699\n\n\nPhae.long3.wav_2-1\n15.6860\n22.3731\n18.4506\n11.2207\n5.3403\n3.6377\n0.0000\n3.6451\n13.6515\n15.9499\n14.4185\n\n\nPhae.long3.wav_3-1\n15.5245\n23.0249\n16.4662\n12.0419\n8.6988\n4.4201\n3.6451\n0.0000\n11.0352\n13.7203\n12.3019\n\n\nPhae.long4.wav_1-1\n18.6621\n15.8250\n17.2609\n12.4495\n17.5231\n13.2529\n13.6515\n11.0352\n0.0000\n5.3861\n5.8845\n\n\nPhae.long4.wav_2-1\n20.8855\n16.6372\n19.1440\n13.5389\n20.5990\n15.6284\n15.9499\n13.7203\n5.3861\n0.0000\n6.2030\n\n\nPhae.long4.wav_3-1\n21.5606\n19.4517\n21.1586\n15.3083\n18.9194\n15.6699\n14.4185\n12.3019\n5.8845\n6.2030\n0.0000\n\n\n\n\n\n\n \n\n\n\n1.5 Performance\nThe use of extended_selection_table objects can improve performance (in our case, measured as time). Here we use microbenchmark to compare the performance of sig2noise() and ggplot2 to plot the results:\n\n\nCode\n# load packages\nlibrary(microbenchmark)\nlibrary(ggplot2)\n\n# take first 100 selections\nmbmrk.snr <- microbenchmark(extended = sig2noise(lng_ext_st[1:100, ], \n      mar = 0.05), regular = sig2noise(lng.selec.table[1:100, ], \n                    mar = 0.05), times = 50)\n\nautoplot(mbmrk.snr) + ggtitle(\"sig2noise\")\n\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n \nThe function runs much faster in the extended selection tables. Performance gain is likely to improve when longer recordings and data sets are used (that is, to compensate for computer overload).\n \n\n\n1.6 Create selections ‘by song’\nThe extended selection above were made by element. That is, each sound file within the object contains a single selection (that is, a 1: 1 correspondence between the selections and the ‘wave’ objects). However, extended selection tables can also be created using a higher hierarchical level with the argument by.song. In this case, “song” represents a higher level that contains one or more selections and that the user may want to keep together for a particular analysis (for example, the duration of the intervals). The by.song argument takes the name of the column of characters or factors with the IDs of the different” songs “within a sound file (note that the function assumes that a given song can only be found in only one sound file, so the selections with the same song ID, but from different sound files are taken as different ‘songs’).\nTo create a selection table by song, let’s add an artificial song column to our example data in which each of the sound files has 2 songs:\n\n\nCode\n# add column\nlbh_selec_table$song <- c(1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2)\n\n\n \nThe data looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\nsong\n\n\n\n\nPhae.long1.wav\n1\n1\n1.1693549\n1.3423884\n2.220105\n8.604378\n1\n\n\nPhae.long1.wav\n1\n2\n2.1584085\n2.3214565\n2.169437\n8.807053\n1\n\n\nPhae.long1.wav\n1\n3\n0.3433366\n0.5182553\n2.218294\n8.756604\n2\n\n\nPhae.long2.wav\n1\n1\n0.1595983\n0.2921692\n2.316862\n8.822316\n1\n\n\nPhae.long2.wav\n1\n2\n1.4570585\n1.5832087\n2.284006\n8.888027\n2\n\n\nPhae.long3.wav\n1\n1\n0.6265520\n0.7577715\n3.006834\n8.822316\n1\n\n\nPhae.long3.wav\n1\n2\n1.9742132\n2.1043921\n2.776843\n8.888027\n1\n\n\nPhae.long3.wav\n1\n3\n0.1233643\n0.2545812\n2.316862\n9.315153\n2\n\n\nPhae.long4.wav\n1\n1\n1.5168116\n1.6622365\n2.513997\n9.216586\n1\n\n\nPhae.long4.wav\n1\n2\n2.9326920\n3.0768784\n2.579708\n10.235116\n2\n\n\nPhae.long4.wav\n1\n3\n0.1453977\n0.2904966\n2.579708\n9.742279\n2\n\n\n\n\n\n\n \nNow we can create an extended selection table ‘by song’ using the column name ‘song’ as input for the argument by.song:\n\n\nCode\nbs_ext_st <- selection_table(X = lbh_selec_table, extended = TRUE,\n                              confirm.extended = FALSE, by.song = \"song\")\n\n\nchecking selections (step 1 of 2):\n\n\nsaving wave objects into extended selection table (step 2 of 2):\n\n\nIn this case, we should only have 8 ‘wave’ objects instead of 11 as when the object was created ‘by selection’:\n\n\nCode\n# by element\nlength(attr(ext_st, \"wave.objects\"))\n\n\n[1] 11\n\n\nCode\n# by song\nlength(attr(bs_ext_st, \"wave.objects\"))\n\n\n[1] 8\n\n\nAgain, these objects can also be used in any analyzes:\n\n\nCode\n# signal to noise ratio\nbs_snr <- sig2noise(bs_ext_st, mar = 0.05)\n\nbs_snr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nchannel\nselec\nstart\nend\nbottom.freq\ntop.freq\nsong\nSNR\n\n\n\n\nPhae.long1.wav-song_1\n1\n1\n0.100000\n0.2730334\n2.220105\n8.604378\n1\n21.17229\n\n\nPhae.long1.wav-song_1\n1\n2\n1.089054\n1.2521016\n2.169437\n8.807053\n1\n20.37064\n\n\nPhae.long1.wav-song_2\n1\n1\n0.100000\n0.2749187\n2.218294\n8.756604\n2\n19.18211\n\n\nPhae.long2.wav-song_1\n1\n1\n0.100000\n0.2325709\n2.316862\n8.822316\n1\n23.27961\n\n\nPhae.long2.wav-song_2\n1\n1\n0.100000\n0.2261502\n2.284006\n8.888027\n2\n26.21774\n\n\nPhae.long3.wav-song_1\n1\n1\n0.100000\n0.2312195\n3.006834\n8.822316\n1\n25.34264\n\n\nPhae.long3.wav-song_1\n1\n2\n1.447661\n1.5778402\n2.776843\n8.888027\n1\n25.51089\n\n\nPhae.long3.wav-song_2\n1\n1\n0.100000\n0.2312170\n2.316862\n9.315153\n2\n24.68619\n\n\nPhae.long4.wav-song_1\n1\n1\n0.100000\n0.2454249\n2.513997\n9.216586\n1\n27.61899\n\n\nPhae.long4.wav-song_2\n1\n1\n2.887294\n3.0314808\n2.579708\n10.235116\n2\n28.88520\n\n\nPhae.long4.wav-song_2\n1\n2\n0.100000\n0.2450989\n2.579708\n9.742279\n2\n24.30149\n\n\n\n\n\n\n \n\nExercise\n \n\nCompare the size of an extended selection table created by element to that of one created by song using the sample data\n\n\n \n\n\n1.7 Sharing acoustic data\nThis new object class allows to share complete data sets, including acoustic data. For example, the following code downloads a subset of the data used in Araya-Salas et al (2017) (can also be downloaded from here):\n\n\nCode\nURL <- \"https://github.com/maRce10/OTS_BIR_2023/raw/master/data/extended.selection.table.araya-salas.et.al.2017.bioacoustics.100.sels.rds\"\n\ndat <- readRDS(gzcon(url(URL)))\n\nnrow(dat)\n\nformat(object.size(dat), units = \"auto\")\n\n\n\n\n[1] 100\n\n\n[1] \"10.1 Mb\"\n\n\nThe total size of the 100 sound files from which these selections were taken adds up to 1.1 GB. The size of the extended selection table is only 10.1 MB.\nThis data is ready to be used:\n\n\nCode\nsp <- spectro_analysis(dat, bp = c(2, 10))\n\nhead(sp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nselec\nduration\nmeanfreq\nsd\nfreq.median\nfreq.Q25\nfreq.Q75\nfreq.IQR\ntime.median\ntime.Q25\ntime.Q75\ntime.IQR\nskew\nkurt\nsp.ent\ntime.ent\nentropy\nsfm\nmeandom\nmindom\nmaxdom\ndfrange\nmodindx\nstartdom\nenddom\ndfslope\nmeanpeakf\n\n\n\n\nPyrrhura rupicola Macaulay Library 132 .wav_2\n1\n0.1504762\n4.662762\n1.767083\n4.279070\n3.435216\n5.647841\n2.212625\n0.0654244\n0.0392547\n0.1046791\n0.0654244\n2.619410\n12.031225\n0.9236435\n0.9508231\n0.8782216\n0.5423756\n3.753955\n2.024121\n6.847559\n4.823437\n5.375000\n4.521973\n2.024121\n-16.599644\n4.020775\n\n\n0.CCE.1971.4.4.ITM70863A-23.wav_1\n1\n0.1655637\n6.254850\n1.648434\n6.350453\n5.601209\n7.202417\n1.601209\n0.0827778\n0.0382051\n0.1209829\n0.0827778\n2.380005\n10.144155\n0.9397550\n0.9410405\n0.8843475\n0.6327902\n6.585970\n3.574512\n8.225684\n4.651172\n3.685185\n8.225684\n6.933691\n-7.803594\n6.096101\n\n\n0.SAT.1989.6.2.ITM70866A-32.wav_5\n1\n0.1542514\n6.093311\n1.645878\n5.844408\n4.904376\n7.393841\n2.489465\n0.0835469\n0.0449868\n0.1156803\n0.0706935\n1.970903\n7.268969\n0.9391274\n0.9432334\n0.8858163\n0.6084129\n6.234293\n3.316113\n8.139551\n4.823437\n3.214286\n6.416894\n3.316113\n-20.102130\n7.047292\n\n\n23.CCE.2011.7.21.7.42.wav_6\n1\n0.1549551\n5.415047\n1.463110\n5.167742\n4.419355\n6.425807\n2.006452\n0.0645692\n0.0387415\n0.1033107\n0.0645692\n2.107408\n8.054270\n0.9227024\n0.9447503\n0.8717234\n0.5060075\n5.028434\n2.368652\n7.795020\n5.426367\n2.158730\n7.364356\n2.368652\n-32.239682\n4.366662\n\n\nCyanoliseus patagonus Macaulay Library 79 .wav_5\n1\n0.1598866\n3.153826\n1.225681\n2.569195\n2.243941\n3.651290\n1.407350\n0.0639546\n0.0383728\n0.0959320\n0.0575592\n4.547286\n29.491407\n0.8230714\n0.9356593\n0.7701144\n0.1265239\n2.590610\n2.024121\n4.435840\n2.411719\n3.071429\n2.454785\n2.282519\n-1.077424\n2.291336\n\n\n0.HC1.2011.8.7.9.20.wav_4\n1\n0.1537989\n6.029456\n1.757841\n6.416260\n4.920325\n7.183740\n2.263415\n0.0769048\n0.0448611\n0.1089484\n0.0640873\n4.161163\n27.901632\n0.9288549\n0.9459573\n0.8786571\n0.6043575\n6.254965\n4.952637\n8.570215\n3.617578\n4.071429\n5.383301\n4.952637\n-2.800177\n4.971966\n\n\n\n\n\n\n… and the spectrograms can be visualized as follows:\n\n\nCode\npar(mfrow = c(3, 2), mar = rep(0, 4))\n\nfor(i in 1:6){\n  \n  wv <- read_wave(X = dat, index = i, from = 0.17, to = 0.4)\n\n  spectro(wv, wl = 250, grid = FALSE, scale = FALSE, axisX = FALSE,\n          axisY = FALSE, ovlp = 90, flim = c(0, 12), \n          palette = reverse.gray.colors.1)\n}\n\n\n\n\n\nThe NatureSounds package contains an extended selection table with long-billed hermit hummingbirds vocalizations from 10 different song types:\n\n\nCode\ndata(\"Phae.long.est\")\n\nPhae.long.est\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsound.files\nselec\nstart\nend\nbottom.freq\ntop.freq\nlek\nlek.song.type\n\n\n\n\nBR2-A1-1\n1\n0.1\n0.2676122\n1.601978\n10.95248\nBR2\nBR2-A1\n\n\nBR2-A1-2\n1\n0.1\n0.2652138\n1.891390\n11.02500\nBR2\nBR2-A1\n\n\nBR2-A1-3\n1\n0.1\n0.2716211\n1.717743\n11.02500\nBR2\nBR2-A1\n\n\nBR2-A1-4\n1\n0.1\n0.2700891\n1.833508\n11.02500\nBR2\nBR2-A1\n\n\nBR2-A1-5\n1\n0.1\n0.2769735\n2.122920\n11.02500\nBR2\nBR2-A1\n\n\nCCE-I3-1\n1\n0.1\n0.2489883\n1.755128\n11.02500\nCCE\nCCE-I3\n\n\nCCE-I3-2\n1\n0.1\n0.2542084\n1.621870\n10.97237\nCCE\nCCE-I3\n\n\nCCE-I3-3\n1\n0.1\n0.2511759\n1.710708\n11.02500\nCCE\nCCE-I3\n\n\nCCE-I3-4\n1\n0.1\n0.2112061\n1.932805\n11.02500\nCCE\nCCE-I3\n\n\nCCE-I3-5\n1\n0.1\n0.2551176\n1.533031\n10.88353\nCCE\nCCE-I3\n\n\nLOC-D1-1\n1\n0.1\n0.2349864\n1.204700\n10.55520\nLOC\nLOC-D1\n\n\nLOC-D1-2\n1\n0.1\n0.2284810\n1.387300\n10.73780\nLOC\nLOC-D1\n\n\nLOC-D1-3\n1\n0.1\n0.2276679\n1.387300\n10.73780\nLOC\nLOC-D1\n\n\nLOC-D1-4\n1\n0.1\n0.2252284\n1.533300\n10.88380\nLOC\nLOC-D1\n\n\nLOC-D1-5\n1\n0.1\n0.2398654\n2.336400\n11.02500\nLOC\nLOC-D1\n\n\nSAT-F1-1\n1\n0.1\n0.2327233\n1.577451\n10.92795\nSAT\nSAT-F1\n\n\nSAT-F1-2\n1\n0.1\n0.2368484\n1.755128\n11.02500\nSAT\nSAT-F1\n\n\nSAT-F1-3\n1\n0.1\n0.2320470\n1.804718\n11.02500\nSAT\nSAT-F1\n\n\nSAT-F1-4\n1\n0.1\n0.2328000\n1.767014\n11.02500\nSAT\nSAT-F1\n\n\nSAT-F1-5\n1\n0.1\n0.2330560\n1.842421\n11.02500\nSAT\nSAT-F1\n\n\nSTR-A2-1\n1\n0.1\n0.2229370\n1.729311\n11.02500\nSTR\nSTR-A2\n\n\nSTR-A2-2\n1\n0.1\n0.2252280\n1.653903\n11.00440\nSTR\nSTR-A2\n\n\nSTR-A2-3\n1\n0.1\n0.2236880\n1.767014\n11.02500\nSTR\nSTR-A2\n\n\nSTR-A2-4\n1\n0.1\n0.2208320\n1.767014\n11.02500\nSTR\nSTR-A2\n\n\nSTR-A2-5\n1\n0.1\n0.2280000\n1.616200\n10.96670\nSTR\nSTR-A2\n\n\nSUR-E1-1\n1\n0.1\n0.2398189\n2.066063\n11.02500\nSUR\nSUR-E1\n\n\nSUR-E1-2\n1\n0.1\n0.2385804\n2.110482\n11.02500\nSUR\nSUR-E1\n\n\nSUR-E1-3\n1\n0.1\n0.2383356\n2.110482\n11.02500\nSUR\nSUR-E1\n\n\nSUR-E1-4\n1\n0.1\n0.2408430\n2.066063\n11.02500\nSUR\nSUR-E1\n\n\nSUR-E1-5\n1\n0.1\n0.2358013\n1.932805\n11.02500\nSUR\nSUR-E1\n\n\nSUR-K4-1\n1\n0.1\n0.2357996\n1.934900\n11.02500\nSUR\nSUR-K4\n\n\nSUR-K4-2\n1\n0.1\n0.2317337\n2.044400\n11.02500\nSUR\nSUR-K4\n\n\nSUR-K4-3\n1\n0.1\n0.2276679\n2.080900\n11.02500\nSUR\nSUR-K4\n\n\nSUR-K4-4\n1\n0.1\n0.2284810\n2.007900\n11.02500\nSUR\nSUR-K4\n\n\nSUR-K4-5\n1\n0.1\n0.2382391\n2.044400\n11.02500\nSUR\nSUR-K4\n\n\nTR1-C2-1\n1\n0.1\n0.1926348\n2.865609\n11.02500\nTR1\nTR1-C2\n\n\nTR1-C2-2\n1\n0.1\n0.1921808\n2.821190\n11.02500\nTR1\nTR1-C2\n\n\nTR1-C2-3\n1\n0.1\n0.1920448\n2.865609\n11.02500\nTR1\nTR1-C2\n\n\nTR1-C2-4\n1\n0.1\n0.1888685\n2.865609\n11.02500\nTR1\nTR1-C2\n\n\nTR1-C2-5\n1\n0.1\n0.1954845\n2.732222\n11.02500\nTR1\nTR1-C2\n\n\nTR1-D4-1\n1\n0.1\n0.2492842\n2.243646\n11.02500\nTR1\nTR1-D4\n\n\nTR1-D4-2\n1\n0.1\n0.2485186\n2.065983\n11.02500\nTR1\nTR1-D4\n\n\nTR1-D4-3\n1\n0.1\n0.2402925\n2.021643\n11.02500\nTR1\nTR1-D4\n\n\nTR1-D4-4\n1\n0.1\n0.2397693\n2.110482\n11.02500\nTR1\nTR1-D4\n\n\nTR1-D4-5\n1\n0.1\n0.2417536\n2.110482\n11.02500\nTR1\nTR1-D4\n\n\nTR1-C5-1\n1\n0.1\n0.1986836\n2.199320\n11.02500\nTR1\nTR1-C5\n\n\nTR1-C5-2\n1\n0.1\n0.1991138\n2.154901\n11.02500\nTR1\nTR1-C5\n\n\nTR1-C5-3\n1\n0.1\n0.2009404\n2.332578\n11.02500\nTR1\nTR1-C5\n\n\nTR1-C5-4\n1\n0.1\n0.1974734\n2.332578\n11.02500\nTR1\nTR1-C5\n\n\nTR1-C5-5\n1\n0.1\n0.2004244\n1.799487\n11.02500\nTR1\nTR1-C5\n\n\n\n\n\n\nCode\ntable(Phae.long.est$lek.song.type)\n\n\n\nBR2-A1 CCE-I3 LOC-D1 SAT-F1 STR-A2 SUR-E1 SUR-K4 TR1-C2 TR1-C5 TR1-D4 \n     5      5      5      5      5      5      5      5      5      5 \n\n\nThe ability to compress large data sets and the ease of performing analyzes that require a single R object can simplify the exchange of data and the reproducibility of bioacoustic analyzes.\n \n\nExercise\n \n\nDownload the extended selection tables of bat social calls from the this figshare repository (scroll till the end of the file list) and create spectrograms for the first 5 selections of each table (either spectrograms() or spectro() would work)"
  },
  {
    "objectID": "intro_to_warbler.html#warbler-functions-and-the-workflow-of-analysis-in-bioacoustics",
    "href": "intro_to_warbler.html#warbler-functions-and-the-workflow-of-analysis-in-bioacoustics",
    "title": "Introduction to warbleR",
    "section": "2 warbleR functions and the workflow of analysis in bioacoustics",
    "text": "2 warbleR functions and the workflow of analysis in bioacoustics\nBioacoustic analyzes generally follow a specific processing sequence and analysis. This sequence can be represented schematically like this:\n\n\n\n\n \nWe can group warbleR functions according to the bioacoustic analysis stages.\n \n\n2.1 Get and prepare recordings\nThe query_xc() function allows you to search and download sounds from the free access database Xeno-Canto. You can also convert .mp3 files to .wav, change the sampling rate of the files and correct corrupt files, among other functions.\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    check_wavs \n    verify if sound files can be read \n    multiple wave files \n    data frame \n  \n  \n    consolidate \n    consolidate sound files in a single folder \n    multiple wave files \n    data frame and wave files \n  \n  \n    fix_wavs \n    fix waves that cannot be read in R \n    multiple wave files \n    wave files \n  \n  \n    mp32wav \n    convert multiple mp3 files to wav format \n    multiple mp3 files \n    wave files \n  \n  \n    query_xc \n    Search and download mp3 files from Xeno-Canto \n    Scientific names/data frame \n    mp3 files \n  \n  \n    resample_est \n    resample wave objects in ext. selection tables \n    extended selection tables \n    extended selection tables \n  \n  \n    remove_channels \n    remove channels in multiple wave files \n    multiple wave files \n    wave files \n  \n  \n    remove_silence \n    remove silences in multiple wave files \n    multiple wave files \n    wave files \n  \n  \n    duration_wavs \n    measures duration in multiple wave files \n    multiple wave files \n    data frame \n  \n  \n    info_wavs \n    extract recording parameters from multiple wave files \n    multiple wave files \n    data frame \n  \n\n\n\n\n\n \n\n\n2.2 Annotating sound\nIt is recommended to make annotations in other programs and then import them into R (for example in Raven and import them with the Rraven package). However, warbleR offers some functions to facilitate manual or automatic annotation of sound files, as well as the subsequent manipulation:\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    auto_detec \n    automatic annotation of wave files \n    multiple wave files \n    data frame, images \n  \n  \n    optimize_auto_detec \n    Try different detection settings to optimize auto_detec detections \n    auto_detec output \n    data frame \n  \n  \n    freq_range \n    detect frequency range in selection tables \n    multiple wave files \n    data frame \n  \n  \n    tailor_sels \n    interactive tailoring of selections \n    selection tables \n    selection tables \n  \n\n\n\n\n\n \n\n\n2.3 Organize annotations\nThe annotations (or selection tables) can be manipulated and refined with a variety of functions. Selection tables can also be converted into the compact format extended selection tables:\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    auto_detec \n    automatic annotation of wave files \n    multiple wave files \n    data frame, images \n  \n  \n    optimize_auto_detec \n    Try different detection settings to optimize auto_detec detections \n    auto_detec output \n    data frame \n  \n  \n    freq_range \n    detect frequency range in selection tables \n    multiple wave files \n    data frame \n  \n  \n    tailor_sels \n    interactive tailoring of selections \n    selection tables \n    selection tables \n  \n\n\n\n\n\n \n\n\n2.4 Measure acoustic signal structure\nMost warbleR functions are dedicated to quantifying the structure of acoustic signals listed in selection tables using batch processing. For this, 4 main measurement methods are offered:\n\nSpectrographic parameters\nCross correlation\nDynamic time warping (DTW)\nStatistical descriptors of cepstral coefficients\n\nMost functions gravitate around these methods, or variations of these methods:\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    freq_range \n    detect frequency range in selection tables \n    multiple wave files \n    data frame \n  \n  \n    song_analysis \n    measures acoustic parameters at higher structural levels of organization \n    selection tables, ext. selection tables \n    data frame, selection tables \n  \n  \n    compare_methods \n    compare the performance of methods to measure acoustic structure \n    selection tables, ext. selection tables \n    images \n  \n  \n    freq_DTW \n    measures dynamic time warping (DTW) on dominant/fundamental frequency contours \n    selection tables, ext. selection tables \n    (di)similarity matrix, images \n  \n  \n    freq_ts \n    mesaures dominant/fundamental frequency contours \n    selection tables, ext. selection tables \n    data frame with frequency contours \n  \n  \n    inflections \n    measures number of inflections in frequency contours \n    data frame with frequency contours \n    data frame \n  \n  \n    mfcc_stats \n    measures statistical descriptors of Mel cepstral coefficients \n    selection tables, ext. selection tables \n    data frame \n  \n  \n    multi_DTW \n    measures dynamic time warping (DTW) on multiple contours \n    selection tables, ext. selection tables \n    (di)similarity matrix \n  \n  \n    sig2noise \n    measures signal-to-noise ratio \n    selection tables, ext. selection tables \n    selection tables, ext. selection tables \n  \n  \n    spectro_analysis \n    measures spectrographic parameters \n    selection tables, ext. selection tables \n    data frame \n  \n  \n    cross_correlation \n    measurec spectrographic cross-correlation \n    selection tables, ext. selection tables \n    (di)similarity matrix \n  \n\n\n\n\n\n \n\nExercise\n \n\nCompare the performance of spectro_analysis() on the example ‘lbh_selec_table’ with “the argument ‘fast = TRUE’ vs ‘fast = FALSE’. What does this argument do and which seewave function might be involved?\n\n\n \n\n\n2.5 Verify annotations\nFunctions are provided to detect inconsistencies in the selection tables or modify selection tables. The package also offers several functions to generate spectrograms showing the annotations, which can be organized by annotation categories. This allows you to verify if the annotations match the previously defined categories, which is particularly useful if the annotations were automatically generated.\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    check_sels \n    double-check selection tables \n    selection tables \n    selection tables \n  \n  \n    overlapping_sels \n    finds (time) overlapping selections \n    selection tables, ext. selection tables \n    selection tables, ext. selection tables \n  \n  \n    catalog \n    creates spectrogram catalog \n    selection tables, ext. selection tables \n    images \n  \n  \n    catalog2pdf \n    convert catalogs to .pdf \n    images \n    images \n  \n  \n    spectrograms \n    create spectrogram images \n    selection tables, ext. selection tables \n    images \n  \n  \n    full_spectrograms \n    create spectrograms of whole sound files \n    multiple wave files, selection tables, ext. selection tables \n    images \n  \n  \n    full_spectrogram2pdf \n    convert full spectrograms to .pfg \n    images \n    images \n  \n\n\n\n\n\n \n\n\n2.6 Visually inspection of annotations and measurements\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    snr_spectrograms \n    plots spectrograms highlighting areas where signal-to-noise ratio is measured \n    selection tables, ext. selection tables \n    images \n  \n  \n    spectrograms \n    create spectrogram images \n    selection tables, ext. selection tables \n    images \n  \n  \n    track_freqs \n    create spectrogram images including frequency contours \n    selection tables, ext. selection tables \n    images \n  \n  \n    plot_coordination \n    create schematic plots of coordinated signals \n    data frame \n    images \n  \n  \n    full_spectrograms \n    create spectrograms of whole sound files \n    multiple wave files, selection tables, ext. selection tables \n    images \n  \n\n\n\n\n\n \n\n\n2.7 Additional functions\nFinally, warbleR offers functions to simplify the use of extended selection tables, organize large numbers of images with spectrograms and generate elaborated signal visualizations:\n\n\n\n\n \n  \n    Function \n    Description \n    Works.on \n    Output \n  \n \n\n  \n    is_extended_selection_table \n    check if object is extended selection tables \n    data frame \n    TRUE/FALSE \n  \n  \n    is_selection_table \n    check if object is selection tables \n    data frame \n    TRUE/FALSE \n  \n  \n    catalog2pdf \n    convert catalogs to .pdf \n    images \n    images \n  \n  \n    move_imgs \n    moves images among folders \n    images \n    images \n  \n  \n    harmonic_track \n    measures harmonics with highest energy \n    wave object \n    data frame with frequency contours \n  \n  \n    map_xc \n    created maps from Xeno-Canto recordings \n    data frame \n    images \n  \n  \n    test_coordination \n    test statistical significance of vocal coordination \n    data frame \n    data frame \n  \n  \n    full_spectrogram2pdf \n    convert full spectrograms to .pfg \n    images \n    images \n  \n  \n    color_spectro \n    highlight signals with colors in a spectrogram \n    wave object \n    plot in R \n  \n  \n    freq_range_detec \n    detect frequency range in wave objetcs \n    wave object \n    data frame, plot in R \n  \n  \n    open_wd \n    open working directory \n     \n     \n  \n  \n    phylo_spectro \n    plots phylogenetic trees with spectrograms \n    selection tables \n    plot in R \n  \n  \n    read_wave \n    read wave files and wave objects \n    selection tables, ext. selection tables \n    wave object \n  \n  \n    sim_songs \n    simulate songs \n     \n    wave object, wave file and selection table \n  \n  \n    tweak_spectro \n    creates mosaic plots with spectrograms with different display parameters \n    selection tables, ext. selection tables \n    images \n  \n  \n    warbleR_options \n    define global parameters for warbleR functions \n     \n     \n  \n\n\n\n\n\n \n\nExercise\n \n\nRun the examples of the functions phylo_spectro() and color_spectro()\nUse the query_xc() and map_xc() functions to explore the geographical distribution of the Xeno-Canto recordings of a species (of bird) of your interest (if any!)"
  },
  {
    "objectID": "intro_to_warbler.html#references",
    "href": "intro_to_warbler.html#references",
    "title": "Introduction to warbleR",
    "section": "3 References",
    "text": "3 References\n\nAraya-Salas M, G Smith-Vidaurre & M Webster. (2017). Assessing the effect of sound file compression and background noise on measures of acoustic signal structure. Bioacoustics 4622, 1–17\nAraya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to streamline analysis of animal acoustic signals. Methods Ecol Evol 8:184–191.\n\n \n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.4.0        microbenchmark_1.4.9 warbleR_1.1.28      \n[4] NatureSounds_1.0.4   knitr_1.42           seewave_2.2.0       \n[7] tuneR_1.4.4         \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10       svglite_2.1.0     fftw_1.0-7        digest_0.6.31    \n [5] foreach_1.5.2     utf8_1.2.3        R6_2.5.1          signal_0.7-7     \n [9] evaluate_0.21     httr_1.4.6        pillar_1.9.0      rlang_1.1.1      \n[13] rstudioapi_0.14   rmarkdown_2.21    webshot_0.5.4     stringr_1.5.0    \n[17] htmlwidgets_1.5.4 RCurl_1.98-1.12   munsell_0.5.0     proxy_0.4-27     \n[21] compiler_4.2.2    xfun_0.39         pkgconfig_2.0.3   systemfonts_1.0.4\n[25] htmltools_0.5.5   tidyselect_1.2.0  tibble_3.2.1      dtw_1.23-1       \n[29] codetools_0.2-19  fansi_1.0.4       viridisLite_0.4.1 dplyr_1.1.0      \n[33] withr_2.5.0       shinyBS_0.61.1    MASS_7.3-58.2     bitops_1.0-7     \n[37] brio_1.1.3        grid_4.2.2        jsonlite_1.8.4    gtable_0.3.1     \n[41] lifecycle_1.0.3   magrittr_2.0.3    scales_1.2.1      cli_3.6.1        \n[45] stringi_1.7.12    pbapply_1.7-0     farver_2.1.1      testthat_3.1.8   \n[49] xml2_1.3.4        vctrs_0.6.2       generics_0.1.3    kableExtra_1.3.4 \n[53] rjson_0.2.21      iterators_1.0.14  tools_4.2.2       glue_1.6.2       \n[57] parallel_4.2.2    fastmap_1.1.1     yaml_2.3.7        colorspace_2.1-0 \n[61] soundgen_2.5.3    rvest_1.0.3"
  },
  {
    "objectID": "measure_structure_green_hermit.html#download-xeno-canto-data",
    "href": "measure_structure_green_hermit.html#download-xeno-canto-data",
    "title": "Case study",
    "section": "1 Download Xeno-Canto data",
    "text": "1 Download Xeno-Canto data\nThe warbleR function query_xc() queries for avian vocalization recordings in the open-access online repository Xeno-Canto. It can return recordings metadata or download the associated sound files.\nGet recording metadata for green hermits (Phaethornis guy):\n\n\n\n\n\nCode\nlibrary(warbleR)\n\npg <- query_xc(qword = 'Phaethornis guy', download = FALSE)\n\n\n \nKeep only song vocalizations of high quality:\n\n\nCode\nsong_pg <- pg[grepl(\"song\", ignore.case = TRUE, pg$Vocalization_type) & pg$Quality == \"A\", ]\n\n# remove 1 site from Colombia to have a few samples per country\nsong_pg <- song_pg[song_pg$Locality != \"Suaita, Santander\", ]\n\n\n\n\n\nMap locations using map_xc():\n\nCode\nmap_xc(song_pg, leaflet.map = TRUE)\n\n\n\n\n\n \nOnce you feel fine with the subset of data you can go ahead and download the sound files and save the metadata as a .csv file:\n\n\nCode\nquery_xc(X = song_pg, path = \"./examples/p_guy\", parallel = 3)\n\nwrite.csv(song_pg, file = \"./examples/p_guy/metadata_p_guy_XC.csv\", row.names = FALSE)"
  },
  {
    "objectID": "measure_structure_green_hermit.html#preparing-sound-files-for-analysis-optional",
    "href": "measure_structure_green_hermit.html#preparing-sound-files-for-analysis-optional",
    "title": "Case study",
    "section": "2 Preparing sound files for analysis (optional)",
    "text": "2 Preparing sound files for analysis (optional)\nNow convert all to .wav format (mp3_2_wav) and homogenizing sampling rate and bit depth (fix_wavs):\n\n\nCode\nmp3_2_wav(samp.rate = 22.05, path =  \"./examples/p_guy\")\n\nfix_wavs(path =  \"./examples/p_guy\", samp.rate = 44.1, bit.depth = 16)"
  },
  {
    "objectID": "measure_structure_green_hermit.html#annotating-sound-files-in-raven",
    "href": "measure_structure_green_hermit.html#annotating-sound-files-in-raven",
    "title": "Case study",
    "section": "3 Annotating sound files in Raven",
    "text": "3 Annotating sound files in Raven\nNow songs should be manually annotated and all the selection in the .txt files should be pooled together in a single spreadsheet."
  },
  {
    "objectID": "measure_structure_green_hermit.html#importing-annotations-into-r",
    "href": "measure_structure_green_hermit.html#importing-annotations-into-r",
    "title": "Case study",
    "section": "4 Importing annotations into R",
    "text": "4 Importing annotations into R\nOnce that is done we can read the spreadsheet with the package ‘readxl’ as follows:\n\n\n\n\n\nCode\n# install.packages(\"readxl\") # install if needed\n\n# load package\nlibrary(readxl)\n\n# read data\nannotations <- read_excel(path = \"./examples/p_guy/annotations_p_guy.xlsx\")\n\n# check data\nhead(annotations)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselec\nChannel\nstart\nend\nbottom.freq\ntop.freq\nselec.file\n\n\n\n\n1\n1\n0.7737\n0.9939384\n2.0962\n7.7252\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n2\n1\n1.6837\n1.9068363\n2.0726\n7.6074\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n3\n1\n10.1657\n10.3917342\n1.8371\n8.0078\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n4\n1\n16.3237\n16.5468363\n2.0726\n7.3248\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n5\n1\n1.6069\n1.7517937\n1.7193\n8.7615\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n6\n1\n1.0129\n1.1548958\n1.7193\n8.9264\nPhaethornis-guy-2022.Table.1.selections.txt\n\n\n\n\n\nNote that the column names should be: “start”, “end”, “bottom.freq”, “top.freq” and “sound.files”. In addition frequency columns (“bottom.freq” and “top.freq”) must be in kHz, not in Hz. We can check if the annotations are in the right format using warbleR’s check_sels():\n\n\nCode\nsound_file_path <- \"./examples/p_guy/converted_sound_files/\"\n\ncs <- check_sels(annotations, path = sound_file_path)\n\n\nall selections are OK"
  },
  {
    "objectID": "measure_structure_green_hermit.html#measure-acoustic-structure",
    "href": "measure_structure_green_hermit.html#measure-acoustic-structure",
    "title": "Case study",
    "section": "5 Measure acoustic structure",
    "text": "5 Measure acoustic structure\nWe can measured several parameters of acoustic structure with the warbleR function spectro_analysis():\n\n\nCode\nsp <- spectro_analysis(X = annotations, path = sound_file_path)\n\n\n \nThen we summarize those parameters with a Principal Component Analysis (PCA):\n\n\nCode\n# run excluding sound file and selec columns\npca <- prcomp(sp[, -c(1, 2)])\n\n\n# add first 2 PCs to sound file and selec columns\npca_data <- cbind(sp[, c(1, 2)], pca$x[, 1:2])\n\n\n \nAt this point should should get someting like this:\n\n\nCode\nhead(pca_data)\n\n\n\n\n\n\n\nsound.files\nselec\nPC1\nPC2\n\n\n\n\nPhaethornis-guy-227574.wav\n1\n-22.6069606\n-13.127152\n\n\nPhaethornis-guy-227574.wav\n2\n0.0586673\n-17.321796\n\n\nPhaethornis-guy-227574.wav\n3\n5.9795115\n5.601346\n\n\nPhaethornis-guy-227574.wav\n4\n-6.8159094\n4.462788\n\n\nPhaethornis-guy-238804.wav\n5\n11.2315003\n6.895327\n\n\nPhaethornis-guy-238804.wav\n6\n4.6828306\n7.918963\n\n\n\n\n\n \n‘PC1’ and ‘PC2’ are the 2 new dimensions that will be used to represent the acoustic space."
  },
  {
    "objectID": "measure_structure_green_hermit.html#adding-metadata",
    "href": "measure_structure_green_hermit.html#adding-metadata",
    "title": "Case study",
    "section": "6 Adding metadata",
    "text": "6 Adding metadata\nNow we just need to add any metadata we considered important to try to explain acoustic similarities shown in the acoustic space scatterplot:\n\n\nCode\n# read XC metadata\nsong_pg <- read.csv(\"./examples/p_guy/metadata_p_guy_XC.csv\")\n\n# create a column with the file name in the metadata\nsong_pg$sound.files <- paste0(song_pg$Genus, \"-\", song_pg$Specific_epithet, \"-\", song_pg$Recording_ID, \".wav\")\n\n# and merge based on sound files and any metadata column we need\npca_data_md <- merge(pca_data, song_pg[, c(\"sound.files\", \"Country\", \"Latitude\", \"Longitude\")])"
  },
  {
    "objectID": "measure_structure_green_hermit.html#assessing-geographic-patterns-of-variation",
    "href": "measure_structure_green_hermit.html#assessing-geographic-patterns-of-variation",
    "title": "Case study",
    "section": "7 Assessing geographic patterns of variation",
    "text": "7 Assessing geographic patterns of variation\nWe are ready to plot the acoustic space scatterplot. For this we will use the package ‘ggplot2’:\n\n\nCode\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# install.packages(\"viridis\")\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nCode\n# plot\nggplot(data = pca_data_md, aes(x = PC1, y = PC2, color = Country, shape = Country)) +\n  geom_point(size = 3) + \n  scale_color_viridis_d()\n\n\n\n\n\n \nYou can also add information about their geographic location (in this case longitude) to the plot as follows:\n\n\nCode\n# plot\nggplot(data = pca_data_md, aes(x = PC1, y = PC2, color = Longitude, shape = Country)) +\n  geom_point(size = 3) +\n  scale_color_viridis_c()\n\n\n\n\n\n \nWe can even test if geographic distance is associated to acoustic distance (i.e. if individuals geographically closer produce more similar songs) using a mantel test (mantel function from the package vegan):\n\n\nCode\n# create geographic and acoustic distance matrices\ngeo_dist <- dist(pca_data_md[, c(\"Latitude\", \"Longitude\")])\nacoust_dist <- dist(pca_data_md[, c(\"PC1\", \"PC2\")])\n\n# install.packages(\"vegan\")\nlibrary(vegan)\n\n# run test\nmantel(geo_dist, acoust_dist)\n\n\n\nMantel statistic based on Pearson's product-moment correlation \n\nCall:\nmantel(xdis = geo_dist, ydis = acoust_dist) \n\nMantel statistic r: 0.02928 \n      Significance: 0.242 \n\nUpper quantiles of permutations (null model):\n   90%    95%  97.5%    99% \n0.0715 0.1144 0.1379 0.1839 \nPermutation: free\nNumber of permutations: 999\n\n\n \nIn this example no association between geographic and acoustic distance was detected (p value > 0.05).\n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] vegan_2.6-4        lattice_0.20-45    permute_0.9-7      viridis_0.6.2     \n [5] viridisLite_0.4.1  ggplot2_3.4.0      readxl_1.4.1       warbleR_1.1.28    \n [9] NatureSounds_1.0.4 knitr_1.42         seewave_2.2.0      tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10       fftw_1.0-7        digest_0.6.31     foreach_1.5.2    \n [5] utf8_1.2.3        R6_2.5.1          cellranger_1.1.0  signal_0.7-7     \n [9] evaluate_0.21     pillar_1.9.0      rlang_1.1.1       rstudioapi_0.14  \n[13] Matrix_1.5-1      rmarkdown_2.21    splines_4.2.2     labeling_0.4.2   \n[17] htmlwidgets_1.5.4 RCurl_1.98-1.12   munsell_0.5.0     proxy_0.4-27     \n[21] compiler_4.2.2    xfun_0.39         pkgconfig_2.0.3   mgcv_1.8-41      \n[25] htmltools_0.5.5   tidyselect_1.2.0  tibble_3.2.1      gridExtra_2.3    \n[29] dtw_1.23-1        codetools_0.2-19  fansi_1.0.4       dplyr_1.1.0      \n[33] withr_2.5.0       shinyBS_0.61.1    MASS_7.3-58.2     bitops_1.0-7     \n[37] brio_1.1.3        grid_4.2.2        nlme_3.1-162      jsonlite_1.8.4   \n[41] gtable_0.3.1      lifecycle_1.0.3   magrittr_2.0.3    scales_1.2.1     \n[45] cli_3.6.1         pbapply_1.7-0     farver_2.1.1      leaflet_2.1.1    \n[49] testthat_3.1.8    vctrs_0.6.2       generics_0.1.3    rjson_0.2.21     \n[53] iterators_1.0.14  tools_4.2.2       glue_1.6.2        maps_3.4.1       \n[57] crosstalk_1.2.0   parallel_4.2.2    fastmap_1.1.1     yaml_2.3.7       \n[61] colorspace_2.1-0  cluster_2.1.4     soundgen_2.5.3"
  },
  {
    "objectID": "get_xc_recordings.html#getting-recordings-from-xeno-canto",
    "href": "get_xc_recordings.html#getting-recordings-from-xeno-canto",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "1 Getting recordings from Xeno-Canto",
    "text": "1 Getting recordings from Xeno-Canto\nThe warbleR function query_xc() queries for avian vocalization recordings in the open-access online repository Xeno-Canto. It can return recordings metadata or download the associated sound files.\nExample on how to get recording’s metadata (no downloading):\n\n\nCode\nlibrary(warbleR)\n\npl <- query_xc(qword = 'Parus major', download = FALSE)\n\n\nKeep only song vocalizations:\n\n\nCode\nsong_pl <- pl[grep(\"song\", ignore.case = TRUE, pl$Vocalization_type), ]\n\n\nMap locations using map_xc():\n\nCode\nmap_xc(song_pl, leaflet.map = TRUE)\n\n\n\n\n\nOnce you feel fine with the subset of data you can go ahead and download it as follows:\n\n\nCode\nquery_xc(X = song_pl, download = TRUE, path = \"DIRECTORY WHERE YOU WANT TO SAVE THE FILES\")\n\n\n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] warbleR_1.1.28     NatureSounds_1.0.4 knitr_1.42         seewave_2.2.0     \n[5] tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10       rstudioapi_0.14   magrittr_2.0.3    maps_3.4.1       \n [5] MASS_7.3-58.2     R6_2.5.1          rjson_0.2.21      rlang_1.1.1      \n [9] fastmap_1.1.1     pbapply_1.7-0     tools_4.2.2       parallel_4.2.2   \n[13] xfun_0.39         dtw_1.23-1        cli_3.6.1         crosstalk_1.2.0  \n[17] htmltools_0.5.5   leaflet_2.1.1     yaml_2.3.7        digest_0.6.31    \n[21] brio_1.1.3        htmlwidgets_1.5.4 bitops_1.0-7      testthat_3.1.8   \n[25] RCurl_1.98-1.12   signal_0.7-7      evaluate_0.21     rmarkdown_2.21   \n[29] proxy_0.4-27      compiler_4.2.2    jsonlite_1.8.4    fftw_1.0-7"
  },
  {
    "objectID": "annotations.html#annotation-tables",
    "href": "annotations.html#annotation-tables",
    "title": "Import annotations into R",
    "section": "1 Annotation tables",
    "text": "1 Annotation tables\nAn annotation table (or selection table in Raven’s terminology and warbleR) is a spreadsheet that contains information about the location (and frequency) of the sounds of interest in one or more sound files. Therefore, the basic annotation table should contain at least 3 columns:\n\n\n\n\n \n  \n    sound.files \n    start \n    end \n  \n \n\n  \n    sound_file_1.wav \n    3.82 \n    5.47 \n  \n  \n    sound_file_1.wav \n    2.81 \n    2.99 \n  \n  \n    sound_file_2.wav \n    2.22 \n    3.60 \n  \n  \n    sound_file_2.wav \n    3.45 \n    3.96 \n  \n\n\n\n\n\n \nIdeally we should also include the frequency range of the annotations:\n\n\n\n\n \n  \n    sound.files \n    start \n    end \n    bottom.freq \n    top.freq \n  \n \n\n  \n    sound_file_1.wav \n    3.82 \n    5.47 \n    7.97 \n    9.05 \n  \n  \n    sound_file_1.wav \n    2.81 \n    2.99 \n    4.52 \n    9.23 \n  \n  \n    sound_file_2.wav \n    2.22 \n    3.60 \n    5.00 \n    8.49 \n  \n  \n    sound_file_2.wav \n    3.45 \n    3.96 \n    4.23 \n    9.79 \n  \n\n\n\n\n\n \n.. and a unique identifier (at least within each sound file) for each annotation:\n\n\n\n\n \n  \n    sound.files \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n  \n \n\n  \n    sound_file_1.wav \n    1 \n    3.82 \n    5.47 \n    7.97 \n    9.05 \n  \n  \n    sound_file_1.wav \n    2 \n    2.81 \n    2.99 \n    4.52 \n    9.23 \n  \n  \n    sound_file_2.wav \n    1 \n    2.22 \n    3.60 \n    5.00 \n    8.49 \n  \n  \n    sound_file_2.wav \n    2 \n    3.45 \n    3.96 \n    4.23 \n    9.79 \n  \n\n\n\n\n\nFinally, for sound files with multiple channels, the annotation table should indicate in which channel the sound of interest is located:\n\n\n\n\n \n  \n    sound.files \n    channel \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n  \n \n\n  \n    sound_file_1.wav \n    1 \n    1 \n    3.82 \n    5.47 \n    7.97 \n    9.05 \n  \n  \n    sound_file_1.wav \n    1 \n    2 \n    2.81 \n    2.99 \n    4.52 \n    9.23 \n  \n  \n    sound_file_2.wav \n    1 \n    1 \n    2.22 \n    3.60 \n    5.00 \n    8.49 \n  \n  \n    sound_file_2.wav \n    1 \n    2 \n    3.45 \n    3.96 \n    4.23 \n    9.79 \n  \n\n\n\n\n\n \nThis format, with the same column names as in the previous example, is the one used by the warbleR package as a basic data object to work on batches of sounds (“batches”). The mandatory columns are “sound.files”, “selec”, “start”, and “end”. The frequency range columns (“bottom.freq” and “top.freq”) and the channel number (“channel”) are optional.\nAnnotation tables can be generated within R, or imported from sound analysis programs (mainly, Raven, Avisoft, Syrinx and Audacity)."
  },
  {
    "objectID": "annotations.html#raven",
    "href": "annotations.html#raven",
    "title": "Import annotations into R",
    "section": "2 Raven",
    "text": "2 Raven\nRaven sound analysis software (Cornell Lab of Ornithology) provides very powerful tools for the analysis of sounds (animals). Raven allows you to use the cursor to manually define the frequency and time limits of the signals. It is a very flexible and user friendly program. The annotations can be saved in a selection file (selection table) in .txt format:\n \n\n \nSelections can be reopened on the original file where they were made:\n \n\n \nThe selections with sound (sound selection table) are a special type of annotation that contains all the information about the address of the files and allows to be opened directly without opening the sound file first. To create these selections, you must include the ‘Begin File’, ‘Begin Path’ and “File offset (s) ’columns (the latter only if the file contains annotations for more than one sound file):\n \n\n \nThese selections open easily in Raven, as long as the sound files are kept in the original folders:"
  },
  {
    "objectID": "annotations.html#rraven",
    "href": "annotations.html#rraven",
    "title": "Import annotations into R",
    "section": "3 Rraven",
    "text": "3 Rraven\n \nThe Rraven package is designed to facilitate data exchange between R and Raven sound analysis software. R can simplify the automation of complex analysis routines. In addition, R packages such as warbleR, seewave and monitorR (among others) provide additional methods of analysis, which work as a perfect complement to those found in Raven. Therefore, bridging these applications can greatly expand the bioacoustic toolkit.\nCurrently, most Raven analyzes cannot be run in the background from a command terminal. Therefore, most of the Rraven functions are designed to simplify the exchange of data between the two programs, and in some cases, export files to Raven for further analysis. This tutorial provides detailed examples for each function in Rraven, including both the R code and the additional steps required to fully conduct the analyses. Raven Pro must be installed in order to run some of the code.\nIn this link you will find several videos that show in detail the different tools in Raven.\nhttp://ravensoundsoftware.com/video-tutorials/"
  },
  {
    "objectID": "annotations.html#import-raven-data",
    "href": "annotations.html#import-raven-data",
    "title": "Import annotations into R",
    "section": "4 Import Raven data",
    "text": "4 Import Raven data\n\n4.1 imp_raven\nThis function imports Raven selection tables. You can import several files at once. Raven can also import selection tables that include data from multiple recordings. The function returns a single data frame with the information contained in the selection files. We already have 4 Raven selection tables in the example directory:\n\n\nCode\nlist.files(path = \"./examples\", pattern = \"\\\\.txt$\")\n\n\n[1] \"Label Track3.txt\"                  \"LBH 1 selection table example.txt\"\n[3] \"LBH 2 selection table example.txt\" \"LBH 3 selection table example.txt\"\n[5] \"LBH 4 selection table example.txt\"\n\n\n \nThis code shows how to import all the data contained in those files into R:\n\n\nCode\nrvn.dat <- imp_raven(all.data = TRUE, path = \"./examples\")\n\nhead(rvn.dat)\n\n\n\n\n1 file(s) could not be read:  Label Track3.txt\n\n\n\n\n \n  \n    Selection \n    View \n    Channel \n    Begin Time (s) \n    End Time (s) \n    Low Freq (Hz) \n    High Freq (Hz) \n    Begin File \n    channel \n    Begin Path \n    File Offset (s) \n    File Offset \n    selec.file \n  \n \n\n  \n    1 \n    Spectrogram 1 \n    1 \n    1.169 \n    1.342 \n    2220 \n    8604 \n    Phae.long1.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long1.wav \n    1.169 \n    NA \n    LBH 1 selection table example.txt \n  \n  \n    2 \n    Spectrogram 1 \n    1 \n    2.158 \n    2.321 \n    2169 \n    8807 \n    Phae.long1.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long1.wav \n    2.158 \n    NA \n    LBH 1 selection table example.txt \n  \n  \n    3 \n    Spectrogram 1 \n    1 \n    0.343 \n    0.518 \n    2218 \n    8757 \n    Phae.long1.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long1.wav \n    0.343 \n    NA \n    LBH 1 selection table example.txt \n  \n  \n    1 \n    Spectrogram 1 \n    1 \n    0.160 \n    0.292 \n    2317 \n    8822 \n    Phae.long2.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long2.wav \n    0.160 \n    NA \n    LBH 2 selection table example.txt \n  \n  \n    2 \n    Spectrogram 1 \n    1 \n    1.457 \n    1.583 \n    2284 \n    8888 \n    Phae.long2.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long2.wav \n    1.457 \n    NA \n    LBH 2 selection table example.txt \n  \n  \n    1 \n    Spectrogram 1 \n    1 \n    0.627 \n    0.758 \n    3007 \n    8822 \n    Phae.long3.wav \n    1 \n    /tmp/RtmpWpOeaR/Phae.long3.wav \n    NA \n    0.627 \n    LBH 3 selection table example.txt \n  \n\n\n\n\n\n \nNote that the ‘waveform’ view data has been deleted. It can also be imported as follows (but note that the example selection tables do not have waveform data):\n\n\nCode\nrvn.dat <- imp_raven(all.data = TRUE, waveform = TRUE, path = \"./examples\")\n\n\n \nRaven selections can also be imported in ‘selection.table’ format so that you can input directly into warbleR functions. To do this, you only need to set warbler.format = TRUE:\n\n\nCode\nrvn.dat <- imp_raven(all.data = FALSE, freq.cols = TRUE, path = \"./examples\", warbler.format = TRUE, all.data = FALSE)\n\nhead(rvn.dat)\n\n\n\n\n1 file(s) could not be read:  Label Track3.txt\n\n\n\n\n \n  \n    selec \n    Channel \n    start \n    end \n    bottom.freq \n    top.freq \n    sound.files \n    channel \n    selec.file \n  \n \n\n  \n    1 \n    1 \n    1.169355 \n    1.342388 \n    2.22011 \n    8.60438 \n    Phae.long1.wav \n    1 \n    LBH 1 selection table example.txt \n  \n  \n    2 \n    1 \n    2.158408 \n    2.321457 \n    2.16944 \n    8.80705 \n    Phae.long1.wav \n    1 \n    LBH 1 selection table example.txt \n  \n  \n    3 \n    1 \n    0.343337 \n    0.518255 \n    2.21829 \n    8.75660 \n    Phae.long1.wav \n    1 \n    LBH 1 selection table example.txt \n  \n  \n    1 \n    1 \n    0.159598 \n    0.292169 \n    2.31686 \n    8.82232 \n    Phae.long2.wav \n    1 \n    LBH 2 selection table example.txt \n  \n  \n    2 \n    1 \n    1.457058 \n    1.583209 \n    2.28401 \n    8.88803 \n    Phae.long2.wav \n    1 \n    LBH 2 selection table example.txt \n  \n  \n    1 \n    1 \n    0.626552 \n    0.757771 \n    3.00683 \n    8.82232 \n    Phae.long3.wav \n    1 \n    LBH 3 selection table example.txt \n  \n\n\n\n\n\n \nThe output data frame contains the following columns: “sound.files”, “channel”, “selec”, “start”, “end” and “selec.file.” You can also import the frequency range parameters in ‘selection.table’ by setting ‘freq.cols’ tp TRUE. The data frame returned by imp_raven() (when in the warbleR format) can be entered into several functions of warbleR for a more detailed analysis.\n\n\n4.2 relabel_colms\nThis is a simple function to re-label the columns to match the format of the selection table used in warbleR:\n\n\nCode\n# para simplificar solo las primeras 7 columnas\nst1 <- rvn.dat[ ,1:7]\n\nst1\n\n\n\n\n\n\n\nCode\nrelabel_colms(st1)\n\n\n\n\n\n \nAdditional columns can also be re-labeled:\n\n\nCode\nrelabel_colms(st1, extra.cols.name = \"View\",\n              extra.cols.new.name = \"Raven view\")\n\n\n\n\n\n\n \n  \n    selec \n    Channel \n    start \n    end \n    bottom.freq \n    top.freq \n    sound.files \n  \n \n\n  \n    1 \n    1 \n    1.169355 \n    1.342388 \n    2.22011 \n    8.60438 \n    Phae.long1.wav \n  \n  \n    2 \n    1 \n    2.158408 \n    2.321457 \n    2.16944 \n    8.80705 \n    Phae.long1.wav \n  \n  \n    3 \n    1 \n    0.343337 \n    0.518255 \n    2.21829 \n    8.75660 \n    Phae.long1.wav \n  \n  \n    1 \n    1 \n    0.159598 \n    0.292169 \n    2.31686 \n    8.82232 \n    Phae.long2.wav \n  \n  \n    2 \n    1 \n    1.457058 \n    1.583209 \n    2.28401 \n    8.88803 \n    Phae.long2.wav \n  \n  \n    1 \n    1 \n    0.626552 \n    0.757771 \n    3.00683 \n    8.82232 \n    Phae.long3.wav \n  \n  \n    2 \n    1 \n    1.974213 \n    2.104392 \n    2.77684 \n    8.88803 \n    Phae.long3.wav \n  \n  \n    3 \n    1 \n    0.123364 \n    0.254581 \n    2.31686 \n    9.31515 \n    Phae.long3.wav \n  \n  \n    1 \n    1 \n    1.516812 \n    1.662236 \n    2.51400 \n    9.21659 \n    Phae.long4.wav \n  \n  \n    2 \n    1 \n    2.932692 \n    3.076878 \n    2.57971 \n    10.23512 \n    Phae.long4.wav \n  \n  \n    3 \n    1 \n    0.145398 \n    0.290497 \n    2.57971 \n    9.74228 \n    Phae.long4.wav"
  },
  {
    "objectID": "annotations.html#export-r-data-to-raven",
    "href": "annotations.html#export-r-data-to-raven",
    "title": "Import annotations into R",
    "section": "5 Export R data to Raven",
    "text": "5 Export R data to Raven\n\n5.1 exp_raven\nexp_raven saves a selection table in ‘.txt’ format that can be opened directly in Raven. No objects are returned to the R environment. The following code exports a selection table from a single sound file:\n\n\nCode\nst1 <- lbh_selec_table[lbh_selec_table$sound.files == \"Phae.long1.wav\",]\n\nexp_raven(st1, file.name = \"Phaethornis 1\", khz.to.hz = TRUE)\n\n\n \nIf the path to the sound file is provided, the functions export a ‘sound selection table’ that can be opened directly by Raven (and which will also open the associated sound file):\n\n\nCode\nst1 <- lbh_selec_table[lbh_selec_table$sound.files == \"Phae.long1.wav\",]\n\nexp_raven(st1, file.name = \"Phaethornis 1\", khz.to.hz = TRUE, sound.file.path = \"./examples\")\n\n\n\n \nThis is useful for adding new selections or even new measurements:\n  \nIf there are several sound files available, users can export them as a single selection file or as multiple selection files (one for each sound file). This example creates a multiple selection of sound files:\n\n\nCode\nexp_raven(X = lbh_selec_table, file.name = \"Phaethornis multiple sound files\", \nsound.file.path = \"./examples\", single.file = TRUE)\n\n\n \nThese types of tables can be opened as a multi-file display in Raven:\n\n\n\nex\n\n\n \n\n \n\nExercise\n \n\nAnnotate 2 sound files from the “./examples” folder using Raven\n\n \n\nImport the annotation files into R using Rraven’s imp_raven()"
  },
  {
    "objectID": "annotations.html#warbler-formats",
    "href": "annotations.html#warbler-formats",
    "title": "Import annotations into R",
    "section": "6 warbleR formats",
    "text": "6 warbleR formats\n\n6.1 Selection tables\nThese objects are created with the selection_table() function. The function takes data frames containing selection data (name of the sound file, selection, start, end …), verifies if the information is consistent (see the function check_sels() for details) and saves the ‘diagnostic’ metadata as an attribute. The selection tables are basically data frames in which the information contained has been corroborated so it can be read by other warbleR functions. The selection tables must contain (at least) the following columns:\n\nsound files (sound.files)\nselection (selec)\nstart\nend\n\nThe sample data “lbh_selec_table” contains these columns:\n\n\n\n\n\nCode\ndata(\"lbh_selec_table\")\n\nlbh_selec_table\n\n\n\n\n\n\n \n  \n    sound.files \n    channel \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    1 \n    1.169355 \n    1.342388 \n    2.22011 \n    8.60438 \n  \n  \n    Phae.long1.wav \n    1 \n    2 \n    2.158408 \n    2.321457 \n    2.16944 \n    8.80705 \n  \n  \n    Phae.long1.wav \n    1 \n    3 \n    0.343337 \n    0.518255 \n    2.21829 \n    8.75660 \n  \n  \n    Phae.long2.wav \n    1 \n    1 \n    0.159598 \n    0.292169 \n    2.31686 \n    8.82232 \n  \n  \n    Phae.long2.wav \n    1 \n    2 \n    1.457058 \n    1.583209 \n    2.28401 \n    8.88803 \n  \n  \n    Phae.long3.wav \n    1 \n    1 \n    0.626552 \n    0.757771 \n    3.00683 \n    8.82232 \n  \n  \n    Phae.long3.wav \n    1 \n    2 \n    1.974213 \n    2.104392 \n    2.77684 \n    8.88803 \n  \n  \n    Phae.long3.wav \n    1 \n    3 \n    0.123364 \n    0.254581 \n    2.31686 \n    9.31515 \n  \n  \n    Phae.long4.wav \n    1 \n    1 \n    1.516812 \n    1.662236 \n    2.51400 \n    9.21659 \n  \n  \n    Phae.long4.wav \n    1 \n    2 \n    2.932692 \n    3.076878 \n    2.57971 \n    10.23512 \n  \n  \n    Phae.long4.wav \n    1 \n    3 \n    0.145398 \n    0.290497 \n    2.57971 \n    9.74228 \n  \n\n\n\n\n\n \n… and can be converted to the selection_table format like this:\n\n\nCode\n# global parameters\nwarbleR_options(wav.path = \"./examples\")\n\nst <- selection_table(X = lbh_selec_table, pb = FALSE)\n\nst\n\n\n\n\n\n\n\n\n\n\nsound.files\n\n\nchannel\n\n\nselec\n\n\nstart\n\n\nend\n\n\nbottom.freq\n\n\ntop.freq\n\n\n\n\n\n\nPhae.long1.wav\n\n\n1\n\n\n1\n\n\n1.169355\n\n\n1.342388\n\n\n2.22011\n\n\n8.60438\n\n\n\n\nPhae.long1.wav\n\n\n1\n\n\n2\n\n\n2.158408\n\n\n2.321457\n\n\n2.16944\n\n\n8.80705\n\n\n\n\nPhae.long1.wav\n\n\n1\n\n\n3\n\n\n0.343337\n\n\n0.518255\n\n\n2.21829\n\n\n8.75660\n\n\n\n\nPhae.long2.wav\n\n\n1\n\n\n1\n\n\n0.159598\n\n\n0.292169\n\n\n2.31686\n\n\n8.82232\n\n\n\n\nPhae.long2.wav\n\n\n1\n\n\n2\n\n\n1.457058\n\n\n1.583209\n\n\n2.28401\n\n\n8.88803\n\n\n\n\nPhae.long3.wav\n\n\n1\n\n\n1\n\n\n0.626552\n\n\n0.757771\n\n\n3.00683\n\n\n8.82232\n\n\n\n\nPhae.long3.wav\n\n\n1\n\n\n2\n\n\n1.974213\n\n\n2.104392\n\n\n2.77684\n\n\n8.88803\n\n\n\n\nPhae.long3.wav\n\n\n1\n\n\n3\n\n\n0.123364\n\n\n0.254581\n\n\n2.31686\n\n\n9.31515\n\n\n\n\nPhae.long4.wav\n\n\n1\n\n\n1\n\n\n1.516812\n\n\n1.662236\n\n\n2.51400\n\n\n9.21659\n\n\n\n\nPhae.long4.wav\n\n\n1\n\n\n2\n\n\n2.932692\n\n\n3.076878\n\n\n2.57971\n\n\n10.23512\n\n\n\n\nPhae.long4.wav\n\n\n1\n\n\n3\n\n\n0.145398\n\n\n0.290497\n\n\n2.57971\n\n\n9.74228\n\n\n\n\n\n\n\n\nNote that the path to the sound files has been provided. This is necessary in order to verify that the data provided conforms to the characteristics of the audio files.\nSelection tables have their own class in R:\n\n\nCode\nclass(st)\n\n\n[1] \"selection_table\" \"data.frame\"     \n\n\n \n\n\n6.2 Extended selection tables\nWhen the extended = TRUE argument the function generates an object of the extended_selection_table class that also contains a list of ‘wave’ objects corresponding to each of the selections in the data. Therefore, the function transforms the selection table into self-contained objects since the original sound files are no longer needed to perform most of the acoustic analysis in warbleR. This can greatly facilitate the storage and exchange of (bio)acoustic data. In addition, it also speeds up analysis, since it is not necessary to read the sound files every time the data is analyzed.\nNow, as mentioned earlier, you need the selection_table() function to create an extended selection table. You must also set the argument extended = TRUE (otherwise, the class would be a selection table). The following code converts the sample data into an extended selection table:\n\n\nCode\n#  global parameters\nwarbleR_options(wav.path = \"./examples\")\n\next_st <- selection_table(X = lbh_selec_table, pb = FALSE, \n          extended = TRUE, confirm.extended = FALSE)\n\n\n\n\n\n \nAnd that is. Now the acoustic data and the selection data (as well as the additional metadata) are all together in a single R object.\n \n\nExercise\n \n\nRun the example code in the selection_table() function documentation\nWhat do the arguments “mar” and “by.song” do?"
  },
  {
    "objectID": "annotations.html#references",
    "href": "annotations.html#references",
    "title": "Import annotations into R",
    "section": "7 References",
    "text": "7 References\n\nAraya-Salas (2017), Rraven: connecting R and Raven bioacoustic software. R package version 1.0.2.\n\n\n \nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C               LC_TIME=es_CR.UTF-8       \n [4] LC_COLLATE=es_ES.UTF-8     LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                  LC_ADDRESS=C              \n[10] LC_TELEPHONE=C             LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4   warbleR_1.1.28     NatureSounds_1.0.4 knitr_1.42         seewave_2.2.0     \n[6] tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10       compiler_4.2.2    highr_0.10        bitops_1.0-7      tools_4.2.2      \n [6] testthat_3.1.8    digest_0.6.31     jsonlite_1.8.4    evaluate_0.21     lifecycle_1.0.3  \n[11] viridisLite_0.4.1 fftw_1.0-7        rlang_1.1.1       cli_3.6.1         rstudioapi_0.14  \n[16] yaml_2.3.7        parallel_4.2.2    xfun_0.39         fastmap_1.1.1     httr_1.4.6       \n[21] stringr_1.5.0     xml2_1.3.4        htmlwidgets_1.5.4 vctrs_0.6.2       systemfonts_1.0.4\n[26] webshot_0.5.4     svglite_2.1.0     glue_1.6.2        R6_2.5.1          dtw_1.23-1       \n[31] pbapply_1.7-0     rmarkdown_2.21    magrittr_2.0.3    scales_1.2.1      htmltools_0.5.5  \n[36] MASS_7.3-58.2     rvest_1.0.3       colorspace_2.1-0  proxy_0.4-27      stringi_1.7.12   \n[41] RCurl_1.98-1.12   signal_0.7-7      munsell_0.5.0     rjson_0.2.21      Rraven_1.0.14    \n[46] brio_1.1.3"
  },
  {
    "objectID": "measure_acoustic_structure.html",
    "href": "measure_acoustic_structure.html",
    "title": "Measures of acoustic structure",
    "section": "",
    "text": "Acoustic signals are multidimensional traits; they vary complexly in time, frequency, amplitude and combinations of these dimensions. Generally, in biology we want to measure aspects of acoustic signals that vary in response to the factors predicted by our hypotheses. In some cases we even lack predictions for specific acoustic parameters and we need to evaluate the relative similarity between the variants of a signal in a population. These analyses require a diversity of tools for quantifying the multiple dimensions in which we can decompose the signals.\nThe warbleR package is designed to quantify the acoustic structure of a population of signals using 4 main methods of analysis. 2 of them are absolute measures of the structure:\nThe other 2 provide a relative similarity value between signals:"
  },
  {
    "objectID": "measure_acoustic_structure.html#spectrographic-parameters",
    "href": "measure_acoustic_structure.html#spectrographic-parameters",
    "title": "Measures of acoustic structure",
    "section": "1 Spectrographic parameters",
    "text": "1 Spectrographic parameters\nThe spectro_analysis() function measures the following spectrographic parameters related to amplitude distributions in time and frequency, descriptors of the fundamental and dominant frequency contours and descriptors of harmonic content:\n \n\n\n1.0.1 Time and frequency (measured on the spectrogram)\n\nduration: signal length (in s)\nmeanfreq: medium frequency. Weighted average frequency by amplitude (in kHz)\nsd: standard deviation of the amplitude weighted frequency\n\n \n\n\n1.0.2 Energy distribution across frequencies (measured on the power spetrum)\n\nfreq.median: medium frequency. The frequency at which the signal is divided into two frequency intervals of equal energy (in kHz)\nfreq.Q25: first frequency quartile. The frequency at which the signal is divided into two frequency ranges of 25% and 75% energy respectively (in kHz)\nfreq.Q75: third frequency quartile. The frequency at which the signal is divided into two frequency ranges of 75% and 25% energy respectively (in kHz)\nfreq.IQR: interquartile frequency range. Frequency range between ‘freq.Q25’ and ‘freq.Q75’ (in kHz)\nsp.ent: spectral entropy. Frequency spectrum energy distribution. Pure tone ~ 0; loud ~ 1\npeakf: peak frequency. Frequency with the highest energy. This parameter can take a considerable amount of time to measure. Only generated if fast = FALSE. It provides a more accurate measurement of the peak frequency than meanpeakf(), but can be more easily affected by background noise\nmeanpeakf: mean peak frequency. Frequency with the highest energy of the medium frequency spectrum (see meanspec()). Typically more consistent than peakf()\n\n \n\n\n1.0.3 Energy distribution across time (measured on the amplitude envelope)\n\ntime.median: average time. The time at which the signal is divided into two time intervals of equal energy (in s)\ntime.Q25: first quartile. The time in which the signal is divided into two time intervals of 25% and 75% energy respectively (in s)\ntime Q75: third quartile. The time in which the signal is divided into two time intervals of 75% and 25% energy respectively (in s)\ntime.IQR: interquartile time range. Time range between ‘time.Q25’ and ‘time.Q75’ (in s)\nskew (skewness): Asymmetry of the amplitude distribution\nkurt (kurtosis): measure of “peakedness” of the spectrum\ntime.ent: temporary entropy. Energy distribution in the time envelope. Pure tone ~ 0; loud ~ 1\nentropy: Product of the spectral and temporal entropy: sp.ent * time.ent\nsfm: spectral flatness. Similar to sp.ent (pure tone ~ 0; loud ~ 1)\n\n \n\n\n1.0.4 Fundamental frequency contour descriptors (measured on the spectrogram)\n\nmeanfun: average of the fundamental frequency measured through the signal\nminfun: minimum fundamental frequency measured through the signal\nmaxfun: maximum fundamental frequency measured through the signal\n\n \n\n\n1.0.5 Dominant frequency contour descriptors (measured on the spectrogram)\n\nmeandom: average of the dominant frequency measured through the signal\nmindom: minimum dominant frequency measured through the signal\nmaxdom: maximum of the dominant frequency measured through the signal\ndfrange: dominant frequency range measured through the signal\nmodindx: modulation index. Calculated as the cumulative absolute difference between adjacent measurements of dominant frequencies divided by the dominant frequency range. 1 means that the signals are not modulated\nstartdom: measurement of dominant frequency at the beginning of the signal\nenddom: dominant frequency measurement at the end of the signal\ndfslope: pending change in the dominant frequency over time ((enddom-startdom)/duration). The units are kHz/s\n\n \n\n\n1.0.6 Harmonic content descriptors (measured on the spectrogram)\n\nhn_freq: average frequency of the upper ‘n’ harmonics (kHz) The number of harmonics is defined with the argument ‘nharmonics’\nhn_width: average bandwidth of the upper ‘n’ harmonics (kHz) (see analysis). The number of harmonics is defined with the argument ‘nharmonics’\nharmonics: the amount of energy in higher harmonics. The number of harmonics is defined with the argument ‘nharmonics’\nHNR: relationship between harmonics and noise (dB). A measure of harmonic content\n\n\n\n \nWe can easily measure them as follows:\n\n\n\n\n\nCode\nlibrary(warbleR)\n\n# load examples\ndata(\"lbh_selec_table\")\n\n# global parameters\nwarbleR_options(wav.path = \"./examples\", flim = c(1, 10), wl = 200, ovlp = 90, pb = FALSE)\n\nsp <- spectro_analysis(lbh_selec_table)\n\nsp\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    duration \n    meanfreq \n    sd \n    freq.median \n    freq.Q25 \n    freq.Q75 \n    freq.IQR \n    time.median \n    time.Q25 \n    time.Q75 \n    time.IQR \n    skew \n    kurt \n    sp.ent \n    time.ent \n    entropy \n    sfm \n    meandom \n    mindom \n    maxdom \n    dfrange \n    modindx \n    startdom \n    enddom \n    dfslope \n    meanpeakf \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    0.1730334 \n    5.979896 \n    1.399059 \n    6.327995 \n    5.293800 \n    6.865314 \n    1.571513 \n    0.0761870 \n    0.0479696 \n    0.1175725 \n    0.0696029 \n    1.999405 \n    7.027830 \n    0.9434264 \n    0.8885049 \n    0.8382390 \n    0.6510692 \n    6.477971 \n    2.30625 \n    8.38125 \n    6.0750 \n    5.518518 \n    7.03125 \n    2.30625 \n    -27.306859 \n    7.14375 \n  \n  \n    Phae.long1.wav \n    2 \n    0.1630480 \n    5.997299 \n    1.422930 \n    6.212125 \n    5.328746 \n    6.880795 \n    1.552049 \n    0.0763491 \n    0.0452439 \n    0.1149950 \n    0.0697511 \n    1.918356 \n    7.334323 \n    0.9468217 \n    0.8908364 \n    0.8434632 \n    0.6678647 \n    6.712500 \n    3.88125 \n    8.49375 \n    4.6125 \n    4.756098 \n    6.91875 \n    7.25625 \n    2.069942 \n    6.91875 \n  \n  \n    Phae.long1.wav \n    3 \n    0.1749187 \n    6.018300 \n    1.514853 \n    6.424759 \n    5.150246 \n    6.979144 \n    1.828898 \n    0.0893477 \n    0.0545491 \n    0.1279082 \n    0.0733591 \n    2.496740 \n    11.147728 \n    0.9450838 \n    0.8882080 \n    0.8394311 \n    0.6716602 \n    6.560194 \n    2.30625 \n    8.71875 \n    6.4125 \n    6.842105 \n    2.30625 \n    7.25625 \n    28.298854 \n    7.14375 \n  \n  \n    Phae.long2.wav \n    1 \n    0.1325709 \n    6.398304 \n    1.340412 \n    6.595971 \n    5.607323 \n    7.380852 \n    1.773529 \n    0.0763038 \n    0.0534126 \n    0.1039639 \n    0.0505512 \n    1.568523 \n    6.016392 \n    0.9424661 \n    0.9000328 \n    0.8482504 \n    0.6086184 \n    6.510728 \n    4.89375 \n    7.93125 \n    3.0375 \n    9.703704 \n    7.14375 \n    6.24375 \n    -6.788820 \n    7.36875 \n  \n  \n    Phae.long2.wav \n    2 \n    0.1261502 \n    6.308252 \n    1.369242 \n    6.596836 \n    5.605837 \n    7.207292 \n    1.601455 \n    0.0770280 \n    0.0539196 \n    0.0991735 \n    0.0452539 \n    2.470897 \n    10.896039 \n    0.9357725 \n    0.9029598 \n    0.8449650 \n    0.6152336 \n    6.223139 \n    3.09375 \n    7.70625 \n    4.6125 \n    7.048781 \n    5.68125 \n    6.46875 \n    6.242559 \n    6.69375 \n  \n  \n    Phae.long3.wav \n    1 \n    0.1312195 \n    6.608301 \n    1.092168 \n    6.665328 \n    6.063201 \n    7.343674 \n    1.280473 \n    0.0641852 \n    0.0431095 \n    0.0890929 \n    0.0459835 \n    1.775295 \n    6.632376 \n    0.9301880 \n    0.9007131 \n    0.8378325 \n    0.5700750 \n    6.708750 \n    4.89375 \n    8.04375 \n    3.1500 \n    7.928571 \n    5.68125 \n    7.93125 \n    17.146838 \n    6.69375 \n  \n  \n    Phae.long3.wav \n    2 \n    0.1301789 \n    6.639859 \n    1.117356 \n    6.674164 \n    6.105325 \n    7.427493 \n    1.322168 \n    0.0689176 \n    0.0449879 \n    0.0938046 \n    0.0488167 \n    1.545851 \n    4.969900 \n    0.9232849 \n    0.9014187 \n    0.8322663 \n    0.5317422 \n    6.532190 \n    4.66875 \n    8.15625 \n    3.4875 \n    7.870968 \n    5.68125 \n    6.58125 \n    6.913561 \n    6.69375 \n  \n  \n    Phae.long3.wav \n    3 \n    0.1312170 \n    6.580739 \n    1.253000 \n    6.646959 \n    6.029463 \n    7.394054 \n    1.364591 \n    0.0641635 \n    0.0402219 \n    0.0928934 \n    0.0526715 \n    1.802520 \n    5.886959 \n    0.9191879 \n    0.9013920 \n    0.8285486 \n    0.5258369 \n    6.379076 \n    2.98125 \n    8.04375 \n    5.0625 \n    5.244444 \n    2.98125 \n    6.80625 \n    29.150196 \n    6.69375 \n  \n  \n    Phae.long4.wav \n    1 \n    0.1454249 \n    6.219479 \n    1.478869 \n    6.233074 \n    5.456261 \n    7.305488 \n    1.849227 \n    0.0826911 \n    0.0446722 \n    0.1121557 \n    0.0674835 \n    1.274811 \n    4.458109 \n    0.9643357 \n    0.8959714 \n    0.8640172 \n    0.7599268 \n    6.209416 \n    3.43125 \n    8.71875 \n    5.2875 \n    7.702128 \n    7.93125 \n    3.43125 \n    -30.943804 \n    6.24375 \n  \n  \n    Phae.long4.wav \n    2 \n    0.1441864 \n    6.462809 \n    1.592876 \n    6.338070 \n    5.630777 \n    7.572366 \n    1.941589 \n    0.0834713 \n    0.0426842 \n    0.1081333 \n    0.0654491 \n    1.695847 \n    6.442755 \n    0.9585943 \n    0.8964128 \n    0.8592962 \n    0.7199148 \n    6.386397 \n    3.31875 \n    9.05625 \n    5.7375 \n    3.921569 \n    8.04375 \n    3.31875 \n    -32.770070 \n    6.24375 \n  \n  \n    Phae.long4.wav \n    3 \n    0.1450989 \n    6.122156 \n    1.541046 \n    6.081716 \n    5.178639 \n    7.239860 \n    2.061221 \n    0.0806173 \n    0.0436282 \n    0.1100189 \n    0.0663907 \n    1.083042 \n    4.194037 \n    0.9642064 \n    0.8962628 \n    0.8641823 \n    0.7332565 \n    6.180195 \n    3.31875 \n    8.60625 \n    5.2875 \n    6.255319 \n    7.81875 \n    3.31875 \n    -31.013324 \n    6.01875 \n  \n\n\n\n\n\n \n\nExercise\n \n\nThe parameters related to harmonic content were not calculated. How can I have do that?\nHow does measuring harmonic content affect performance?\nWhat does the argument ‘threshold’ do?"
  },
  {
    "objectID": "measure_acoustic_structure.html#statistical-descriptors-of-cepstral-coefficients",
    "href": "measure_acoustic_structure.html#statistical-descriptors-of-cepstral-coefficients",
    "title": "Measures of acoustic structure",
    "section": "2 Statistical descriptors of cepstral coefficients",
    "text": "2 Statistical descriptors of cepstral coefficients\nThese coefficients were designed to decompose the sounds in a similar way than the human auditory system in order to facilitate speech recognition. The central idea is to compress the acoustic data maintaining only relevant information for the detection of phonetic differences. The principle refers to human hearing using the Mel logarithmic scale whose definition is based on how the human ear perceives frequency and loudness (Sueur 2018). Cepstral coefficients are literally defined as “the result of a cosine transformation of the real logarithm of short-term energy spectra expressed on a Mel frequency scale”.\nThe descriptive statistics that are extracted from the cepstral coefficients are: minimum, maximum, average, median, asymmetry, kurtosis and variance. It also returns the mean and variance for the first and second derivatives of the coefficients. These parameters are commonly used in the processing and detection of acoustic signals (e.g. Salamon et al 2014). They have been widely used for human voice analysis and its use has extended to mammalian bioacoustics, although they also appear to be useful for quantifying the structure of acoustic signals in other groups.\nIn warbleR we can calculate statistical descriptors of cepstral coefficients with the mfcc_stats() function:\n\n\nCode\ncc <- mfcc_stats(X = lbh_selec_table)\n\ncc\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    min.cc1 \n    min.cc2 \n    min.cc3 \n    min.cc4 \n    min.cc5 \n    min.cc6 \n    min.cc7 \n    min.cc8 \n    min.cc9 \n    min.cc10 \n    min.cc11 \n    min.cc12 \n    min.cc13 \n    min.cc14 \n    min.cc15 \n    min.cc16 \n    min.cc17 \n    min.cc18 \n    min.cc19 \n    min.cc20 \n    min.cc21 \n    min.cc22 \n    min.cc23 \n    min.cc24 \n    min.cc25 \n    max.cc1 \n    max.cc2 \n    max.cc3 \n    max.cc4 \n    max.cc5 \n    max.cc6 \n    max.cc7 \n    max.cc8 \n    max.cc9 \n    max.cc10 \n    max.cc11 \n    max.cc12 \n    max.cc13 \n    max.cc14 \n    max.cc15 \n    max.cc16 \n    max.cc17 \n    max.cc18 \n    max.cc19 \n    max.cc20 \n    max.cc21 \n    max.cc22 \n    max.cc23 \n    max.cc24 \n    max.cc25 \n    median.cc1 \n    median.cc2 \n    median.cc3 \n    median.cc4 \n    median.cc5 \n    median.cc6 \n    median.cc7 \n    median.cc8 \n    median.cc9 \n    median.cc10 \n    median.cc11 \n    median.cc12 \n    median.cc13 \n    median.cc14 \n    median.cc15 \n    median.cc16 \n    median.cc17 \n    median.cc18 \n    median.cc19 \n    median.cc20 \n    median.cc21 \n    median.cc22 \n    median.cc23 \n    median.cc24 \n    median.cc25 \n    mean.cc1 \n    mean.cc2 \n    mean.cc3 \n    mean.cc4 \n    mean.cc5 \n    mean.cc6 \n    mean.cc7 \n    mean.cc8 \n    mean.cc9 \n    mean.cc10 \n    mean.cc11 \n    mean.cc12 \n    mean.cc13 \n    mean.cc14 \n    mean.cc15 \n    mean.cc16 \n    mean.cc17 \n    mean.cc18 \n    mean.cc19 \n    mean.cc20 \n    mean.cc21 \n    mean.cc22 \n    mean.cc23 \n    mean.cc24 \n    mean.cc25 \n    var.cc1 \n    var.cc2 \n    var.cc3 \n    var.cc4 \n    var.cc5 \n    var.cc6 \n    var.cc7 \n    var.cc8 \n    var.cc9 \n    var.cc10 \n    var.cc11 \n    var.cc12 \n    var.cc13 \n    var.cc14 \n    var.cc15 \n    var.cc16 \n    var.cc17 \n    var.cc18 \n    var.cc19 \n    var.cc20 \n    var.cc21 \n    var.cc22 \n    var.cc23 \n    var.cc24 \n    var.cc25 \n    skew.cc1 \n    skew.cc2 \n    skew.cc3 \n    skew.cc4 \n    skew.cc5 \n    skew.cc6 \n    skew.cc7 \n    skew.cc8 \n    skew.cc9 \n    skew.cc10 \n    skew.cc11 \n    skew.cc12 \n    skew.cc13 \n    skew.cc14 \n    skew.cc15 \n    skew.cc16 \n    skew.cc17 \n    skew.cc18 \n    skew.cc19 \n    skew.cc20 \n    skew.cc21 \n    skew.cc22 \n    skew.cc23 \n    skew.cc24 \n    skew.cc25 \n    kurt.cc1 \n    kurt.cc2 \n    kurt.cc3 \n    kurt.cc4 \n    kurt.cc5 \n    kurt.cc6 \n    kurt.cc7 \n    kurt.cc8 \n    kurt.cc9 \n    kurt.cc10 \n    kurt.cc11 \n    kurt.cc12 \n    kurt.cc13 \n    kurt.cc14 \n    kurt.cc15 \n    kurt.cc16 \n    kurt.cc17 \n    kurt.cc18 \n    kurt.cc19 \n    kurt.cc20 \n    kurt.cc21 \n    kurt.cc22 \n    kurt.cc23 \n    kurt.cc24 \n    kurt.cc25 \n    mean.d1.cc \n    var.d1.cc \n    mean.d2.cc \n    var.d2.cc \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    84.32923 \n    -11.76513 \n    -11.18492 \n    -6.0584627 \n    -19.48781 \n    -18.925700 \n    -29.78141 \n    -20.108571 \n    -30.013144 \n    -35.33559 \n    -18.78548 \n    -14.72824 \n    -17.34269 \n    -15.038620 \n    -16.88236 \n    -19.350662 \n    -18.31898 \n    -22.172183 \n    -14.48335 \n    -18.022615 \n    -12.746066 \n    -11.956576 \n    -16.452832 \n    -11.271758 \n    -17.689274 \n    113.99735 \n    -3.504852 \n    4.9044888 \n    14.01473 \n    11.926071 \n    23.15194 \n    18.45006 \n    18.279624 \n    13.24953 \n    19.780421 \n    25.037088 \n    11.088286 \n    9.420685 \n    19.068858 \n    15.261244 \n    27.81587 \n    14.76590 \n    23.18529 \n    23.323491 \n    13.35063 \n    13.489834 \n    11.386929 \n    14.879921 \n    17.460077 \n    17.881148 \n    100.78462 \n    -8.014139 \n    -2.523547 \n    4.5129178 \n    -4.654038 \n    1.7101299 \n    0.4097267 \n    -8.2092001 \n    -0.6494351 \n    -12.2767547 \n    3.2440322 \n    -1.2003857 \n    0.5455499 \n    4.5166704 \n    -0.3083392 \n    -5.0343073 \n    -0.8391115 \n    0.1977175 \n    5.0807704 \n    -0.4957302 \n    0.4521028 \n    1.4788429 \n    0.4990238 \n    2.4981325 \n    -3.1430709 \n    101.08282 \n    -7.858590 \n    -2.583408 \n    3.6987932 \n    -4.971305 \n    4.1609654 \n    -2.0280573 \n    -4.7209259 \n    -2.8665075 \n    -11.1703248 \n    3.2227089 \n    -1.6356360 \n    -0.5039902 \n    4.3564081 \n    -0.1989548 \n    -2.9284445 \n    -1.1523253 \n    -0.7210100 \n    6.2913939 \n    -0.3807152 \n    0.3753687 \n    1.3054995 \n    1.0918911 \n    2.5730086 \n    -3.4629084 \n    38.54742 \n    3.080550 \n    9.676699 \n    24.878891 \n    51.02731 \n    143.44956 \n    228.64581 \n    92.565654 \n    81.37786 \n    183.97728 \n    110.99179 \n    31.78753 \n    32.98640 \n    50.46467 \n    49.74505 \n    101.25749 \n    53.45791 \n    70.55530 \n    77.18366 \n    58.48509 \n    28.36997 \n    18.42023 \n    43.55758 \n    36.11912 \n    50.53745 \n    -0.8525715 \n    0.0070749 \n    -0.3394632 \n    -0.0228898 \n    -0.0499756 \n    0.0314614 \n    -0.3777624 \n    0.7563943 \n    -0.8795527 \n    0.1369849 \n    0.0356844 \n    -0.2693451 \n    -0.5837437 \n    -0.1670622 \n    -0.1587374 \n    1.0948912 \n    -0.3489756 \n    -0.1417061 \n    0.0615221 \n    -0.3280103 \n    0.0002460 \n    -0.3000768 \n    -0.0950197 \n    0.1054436 \n    0.2366725 \n    3.978925 \n    2.572158 \n    3.259741 \n    1.969604 \n    2.439503 \n    1.555814 \n    1.817494 \n    2.429605 \n    3.295335 \n    1.736930 \n    2.187305 \n    2.322068 \n    2.838789 \n    2.518899 \n    2.388298 \n    3.845852 \n    2.422849 \n    3.322209 \n    2.096780 \n    2.617920 \n    2.845040 \n    2.944752 \n    2.695023 \n    2.404698 \n    2.979525 \n    -162.8716 \n    120738.39 \n    2274.538 \n    13988635 \n  \n  \n    Phae.long1.wav \n    2 \n    86.07548 \n    -11.91646 \n    -12.18542 \n    -8.6272984 \n    -18.72726 \n    -19.122828 \n    -29.55422 \n    -15.419662 \n    -23.873777 \n    -39.56706 \n    -16.48812 \n    -15.67352 \n    -20.04686 \n    -16.567527 \n    -23.43945 \n    -16.600334 \n    -20.51312 \n    -20.710603 \n    -10.18992 \n    -19.518550 \n    -10.980131 \n    -9.042274 \n    -22.290707 \n    -13.343676 \n    -18.216693 \n    113.72199 \n    -4.613946 \n    4.0046793 \n    17.26028 \n    11.839680 \n    20.98899 \n    18.18485 \n    16.048474 \n    13.01459 \n    26.481963 \n    23.840422 \n    12.489321 \n    12.888397 \n    17.280133 \n    11.552351 \n    30.00600 \n    26.34564 \n    26.60756 \n    26.783712 \n    14.75662 \n    12.181809 \n    9.479065 \n    16.702203 \n    10.074379 \n    27.159221 \n    102.96939 \n    -8.232139 \n    -3.305544 \n    5.3750185 \n    -5.522622 \n    -1.4281089 \n    -0.8799003 \n    -4.0623761 \n    1.2965903 \n    -10.9291358 \n    0.9674887 \n    -2.5717512 \n    2.3195448 \n    2.7489489 \n    -2.4962780 \n    -0.4686710 \n    -1.4110075 \n    0.3941393 \n    4.5034699 \n    -3.1118899 \n    0.8915142 \n    0.8774014 \n    0.9537821 \n    0.6016009 \n    -2.3760850 \n    102.11641 \n    -8.110811 \n    -3.270509 \n    4.0824555 \n    -5.279448 \n    2.1963647 \n    -3.8359976 \n    -1.9337745 \n    -0.1455146 \n    -7.1102704 \n    2.3428896 \n    -1.8141892 \n    0.8499174 \n    2.1053632 \n    -3.0172479 \n    1.9352943 \n    -2.4889097 \n    0.8561653 \n    4.7234929 \n    -2.8633469 \n    0.9329030 \n    0.5541757 \n    0.4571885 \n    0.3962518 \n    -1.7985663 \n    32.69969 \n    3.272744 \n    12.120477 \n    34.220961 \n    59.92448 \n    161.62623 \n    190.11835 \n    87.309406 \n    76.27199 \n    197.43674 \n    100.12692 \n    30.49991 \n    43.78743 \n    34.62127 \n    64.53584 \n    113.70042 \n    73.03144 \n    94.22433 \n    84.13487 \n    70.17767 \n    24.55948 \n    16.36854 \n    71.95985 \n    28.68820 \n    78.75229 \n    -0.7937595 \n    0.0368251 \n    -0.1836676 \n    -0.2477335 \n    0.2052126 \n    0.0785791 \n    -0.3988799 \n    0.2427482 \n    -0.7602454 \n    0.2264087 \n    0.2118971 \n    0.0189160 \n    -0.6390020 \n    -0.1645549 \n    -0.4137205 \n    1.0354560 \n    0.1110707 \n    0.2029748 \n    0.2052125 \n    0.0468125 \n    -0.1614243 \n    -0.0904110 \n    -0.6670217 \n    -0.2735971 \n    0.9766275 \n    3.499764 \n    2.309498 \n    2.535486 \n    2.574509 \n    2.153644 \n    1.473513 \n    1.943041 \n    1.637756 \n    2.839401 \n    2.478765 \n    2.033868 \n    3.389931 \n    2.726985 \n    3.201433 \n    2.395783 \n    3.746845 \n    3.235674 \n    3.263642 \n    2.040132 \n    2.243469 \n    2.405112 \n    2.403771 \n    3.177252 \n    2.332764 \n    4.299571 \n    -162.7222 \n    125044.72 \n    2358.420 \n    14610321 \n  \n  \n    Phae.long1.wav \n    3 \n    84.71447 \n    -12.86693 \n    -12.37385 \n    -6.6677525 \n    -17.93314 \n    -15.855967 \n    -28.84733 \n    -18.620027 \n    -20.857060 \n    -38.24592 \n    -16.96329 \n    -12.18738 \n    -22.86534 \n    -7.317589 \n    -20.06833 \n    -22.161444 \n    -19.36095 \n    -21.741610 \n    -10.87104 \n    -12.149563 \n    -14.662678 \n    -7.931532 \n    -16.423956 \n    -10.964721 \n    -21.643870 \n    108.18040 \n    -2.964319 \n    4.0996661 \n    14.58979 \n    9.184255 \n    23.05499 \n    20.77710 \n    17.371439 \n    14.50500 \n    18.461626 \n    22.936062 \n    16.707360 \n    13.913267 \n    21.969152 \n    15.766074 \n    21.96113 \n    11.44151 \n    15.36057 \n    24.586317 \n    13.99253 \n    13.378289 \n    12.853060 \n    17.257267 \n    12.082475 \n    20.207047 \n    98.16825 \n    -9.028246 \n    -3.016906 \n    3.5703002 \n    -5.831004 \n    1.3350682 \n    0.7441784 \n    -5.8756895 \n    -1.9412309 \n    -11.3615555 \n    3.6082495 \n    0.7845383 \n    1.0138900 \n    3.5563993 \n    -0.9615083 \n    -4.9571527 \n    -0.2061702 \n    0.3086402 \n    3.8898702 \n    0.2277695 \n    -0.2069073 \n    1.0601127 \n    2.3452034 \n    1.8802654 \n    -2.8945657 \n    97.81067 \n    -8.405651 \n    -2.853761 \n    2.6311424 \n    -4.651573 \n    4.8392030 \n    -2.3114324 \n    -2.8713025 \n    -2.5946477 \n    -10.7281817 \n    3.0926057 \n    0.7038435 \n    0.4572550 \n    4.2125981 \n    -0.7717674 \n    -2.7353614 \n    -1.0883229 \n    -0.4691156 \n    4.9406418 \n    0.5472174 \n    0.6017814 \n    0.7476270 \n    2.2475173 \n    1.4723863 \n    -3.0864121 \n    27.66152 \n    5.455827 \n    13.984391 \n    26.119854 \n    47.45200 \n    145.84450 \n    173.16803 \n    82.233643 \n    59.94727 \n    209.29478 \n    78.04604 \n    33.45872 \n    49.39895 \n    41.80205 \n    58.96178 \n    92.02909 \n    46.43705 \n    57.16307 \n    57.65391 \n    36.67725 \n    24.79103 \n    18.71207 \n    41.84955 \n    29.14779 \n    46.46215 \n    -0.6098012 \n    0.4598246 \n    -0.2788199 \n    0.0353535 \n    0.2516610 \n    0.1118688 \n    -0.3816367 \n    0.6782386 \n    -0.1451220 \n    -0.1623321 \n    -0.0378343 \n    0.0683836 \n    -0.7565889 \n    0.7368333 \n    -0.2841870 \n    0.7107961 \n    -0.4949666 \n    -0.4362038 \n    0.4053479 \n    -0.0378969 \n    0.1268823 \n    0.2473709 \n    -0.4867252 \n    -0.1591703 \n    0.4457043 \n    2.959010 \n    2.274255 \n    2.543097 \n    2.113162 \n    2.188736 \n    1.531366 \n    1.978457 \n    2.438865 \n    2.724626 \n    2.068398 \n    1.966382 \n    2.968897 \n    4.250107 \n    3.039181 \n    2.639594 \n    3.085653 \n    2.924919 \n    2.873747 \n    2.593373 \n    2.389900 \n    3.110694 \n    2.716579 \n    3.275660 \n    2.298071 \n    4.609402 \n    -156.7522 \n    112731.22 \n    2207.924 \n    13414726 \n  \n  \n    Phae.long2.wav \n    1 \n    50.56041 \n    -18.77867 \n    -19.18023 \n    -5.1156831 \n    -15.31201 \n    -14.853539 \n    -19.67227 \n    -11.337266 \n    -14.293743 \n    -19.31601 \n    -18.31851 \n    -11.52312 \n    -11.87761 \n    -11.474193 \n    -15.59440 \n    -13.046359 \n    -13.47313 \n    -12.666432 \n    -17.30676 \n    -16.478239 \n    -10.301012 \n    -8.518116 \n    -12.098098 \n    -9.938733 \n    -21.899395 \n    95.82797 \n    -1.476256 \n    0.5356803 \n    14.14524 \n    4.987772 \n    18.03277 \n    12.57080 \n    9.708234 \n    15.57415 \n    14.235474 \n    14.932578 \n    11.346420 \n    13.755391 \n    10.716971 \n    15.203273 \n    15.99467 \n    14.70524 \n    19.57898 \n    15.465918 \n    15.76738 \n    17.087750 \n    9.627947 \n    11.107409 \n    14.562106 \n    5.685059 \n    89.56016 \n    -13.281239 \n    -6.201262 \n    6.3350504 \n    -6.726423 \n    2.5687735 \n    -0.8244336 \n    0.2318829 \n    -1.7580541 \n    0.1028389 \n    0.4976419 \n    -0.3414484 \n    1.4830689 \n    -0.3087596 \n    1.0895142 \n    2.8904778 \n    1.5452386 \n    -0.6254576 \n    -0.6399199 \n    -0.1125934 \n    1.0698166 \n    -1.2195655 \n    1.1398485 \n    -0.5621275 \n    -2.9780041 \n    87.54748 \n    -12.254268 \n    -6.689966 \n    4.8505420 \n    -5.763817 \n    2.1524591 \n    -0.9377664 \n    0.0118461 \n    0.0193052 \n    -0.5631844 \n    -0.1486082 \n    -0.3659984 \n    1.0885994 \n    -0.8844645 \n    0.5384982 \n    2.1560721 \n    1.2031469 \n    0.2965713 \n    -1.1924972 \n    0.4344829 \n    1.9361923 \n    -0.9634357 \n    1.2080221 \n    -0.3801088 \n    -3.1717546 \n    55.43443 \n    14.197314 \n    16.523243 \n    31.191793 \n    27.36259 \n    68.21222 \n    46.19293 \n    20.532498 \n    40.28372 \n    45.91169 \n    74.09408 \n    26.48263 \n    36.44235 \n    21.84555 \n    38.27894 \n    28.54412 \n    30.11865 \n    36.06963 \n    33.54773 \n    29.39322 \n    31.44592 \n    14.06754 \n    24.09755 \n    25.55710 \n    29.30412 \n    -2.3617737 \n    0.5620661 \n    -0.7853844 \n    -0.3253047 \n    0.2921540 \n    -0.2184238 \n    -0.4646152 \n    -0.4495660 \n    0.5446993 \n    -0.5564179 \n    -0.2611293 \n    0.0441089 \n    0.0447220 \n    -0.3642512 \n    -0.1266515 \n    -0.4195171 \n    -0.1044080 \n    0.8177531 \n    -0.1788509 \n    -0.1490543 \n    0.2207317 \n    0.2935838 \n    -0.2534314 \n    0.6611163 \n    -0.7195757 \n    10.387312 \n    2.523812 \n    3.744378 \n    1.698074 \n    1.992397 \n    2.233481 \n    3.220366 \n    2.799218 \n    2.868719 \n    3.223175 \n    2.366506 \n    2.316063 \n    2.252824 \n    2.680087 \n    3.092792 \n    3.440594 \n    2.869778 \n    4.211831 \n    3.825819 \n    3.657709 \n    2.519131 \n    2.689710 \n    2.733973 \n    3.322531 \n    3.460724 \n    -139.5949 \n    89559.79 \n    1997.491 \n    11269953 \n  \n  \n    Phae.long2.wav \n    2 \n    69.23577 \n    -17.18596 \n    -20.25226 \n    -3.7917317 \n    -13.67741 \n    -17.062368 \n    -17.69824 \n    -9.737039 \n    -9.347726 \n    -17.34610 \n    -18.18316 \n    -13.37309 \n    -13.09030 \n    -14.342290 \n    -27.31758 \n    -7.811027 \n    -25.92640 \n    -12.031356 \n    -11.93306 \n    -14.425461 \n    -13.885818 \n    -10.478242 \n    -15.213300 \n    -12.064791 \n    -10.104834 \n    99.97835 \n    -4.534624 \n    0.6537113 \n    14.64448 \n    5.035473 \n    14.83004 \n    12.36953 \n    7.862668 \n    16.93760 \n    16.292855 \n    6.457178 \n    7.007890 \n    8.478286 \n    15.513147 \n    27.147724 \n    28.06045 \n    12.82798 \n    12.55751 \n    19.160344 \n    16.53261 \n    6.806786 \n    11.746044 \n    7.754506 \n    7.473303 \n    16.955569 \n    93.62319 \n    -12.426364 \n    -6.821915 \n    6.3893860 \n    -7.186507 \n    2.4640075 \n    1.4933313 \n    0.9153600 \n    3.0598443 \n    -3.5772945 \n    -2.7305020 \n    -1.6300288 \n    -5.2094337 \n    -0.8965981 \n    1.6895035 \n    2.3893437 \n    -0.9681590 \n    -2.3933031 \n    2.6390477 \n    -0.3572365 \n    -2.6157354 \n    0.7066969 \n    -1.5801441 \n    -2.8620984 \n    -0.0191788 \n    91.53344 \n    -10.863905 \n    -7.527386 \n    5.9027922 \n    -6.464367 \n    1.9244645 \n    -0.0164966 \n    1.0469669 \n    3.1630834 \n    -3.8855019 \n    -2.9781009 \n    -2.2099903 \n    -4.3612298 \n    -0.5546178 \n    2.2416490 \n    3.4286326 \n    -1.4016094 \n    -1.4672608 \n    2.5565898 \n    0.2292764 \n    -2.4664863 \n    0.1968881 \n    -1.9062477 \n    -3.2960670 \n    0.6406991 \n    42.73550 \n    15.345963 \n    19.913883 \n    24.344033 \n    27.18264 \n    60.09685 \n    52.08649 \n    9.928084 \n    41.39179 \n    62.20534 \n    25.28970 \n    17.17876 \n    23.13800 \n    38.11626 \n    75.92628 \n    56.07860 \n    60.29012 \n    24.88702 \n    28.85301 \n    41.57108 \n    14.55141 \n    24.51716 \n    26.07821 \n    16.32374 \n    26.10237 \n    -0.9733968 \n    0.3680001 \n    -0.8780162 \n    -0.2218139 \n    0.6471153 \n    -0.4018160 \n    -0.9860828 \n    -0.4577860 \n    0.0500170 \n    0.5902452 \n    -0.3561700 \n    -0.3136212 \n    0.4138770 \n    0.1423488 \n    0.0932327 \n    0.9353019 \n    -1.2559760 \n    0.5598416 \n    0.0464672 \n    0.1264826 \n    -0.2631874 \n    -0.1127727 \n    -0.4960467 \n    -0.0491214 \n    0.9040419 \n    3.545202 \n    1.599688 \n    3.474896 \n    1.883349 \n    2.362472 \n    2.373087 \n    3.289100 \n    3.615628 \n    2.182782 \n    3.277128 \n    2.785593 \n    2.535871 \n    2.494026 \n    2.737171 \n    5.351909 \n    3.692174 \n    4.843621 \n    2.994884 \n    3.474904 \n    3.118363 \n    3.011344 \n    2.785522 \n    2.839144 \n    2.718442 \n    4.140334 \n    -142.0430 \n    98525.41 \n    2216.821 \n    11213543 \n  \n  \n    Phae.long3.wav \n    1 \n    51.52696 \n    -18.48908 \n    -13.54987 \n    0.1644875 \n    -16.40398 \n    -7.595591 \n    -14.27574 \n    -13.213955 \n    -5.091165 \n    -22.49984 \n    -12.61909 \n    -10.28927 \n    -13.54220 \n    -11.767158 \n    -16.44382 \n    -12.936966 \n    -12.66129 \n    -9.618623 \n    -32.60175 \n    -7.317495 \n    -9.127416 \n    -8.994948 \n    -13.015914 \n    -12.708262 \n    -20.945804 \n    91.03291 \n    -6.438211 \n    4.1405479 \n    14.33518 \n    4.606884 \n    13.01582 \n    11.18171 \n    8.266875 \n    16.40768 \n    8.103246 \n    9.485075 \n    9.574047 \n    8.639773 \n    10.709409 \n    11.329384 \n    11.18601 \n    10.36107 \n    10.71221 \n    9.950225 \n    16.03712 \n    24.730990 \n    11.957692 \n    9.093840 \n    21.792011 \n    15.059743 \n    83.39758 \n    -14.844842 \n    -1.573749 \n    7.1924013 \n    -11.810949 \n    7.0300692 \n    -2.1941132 \n    -1.7703202 \n    2.0828468 \n    -2.5327296 \n    -0.7059684 \n    0.3015867 \n    -0.0640079 \n    -0.6900560 \n    1.0762733 \n    -1.1077216 \n    0.4657508 \n    -0.3412012 \n    -1.1536515 \n    0.1696893 \n    0.0833877 \n    0.3784441 \n    0.2870068 \n    -0.1596489 \n    -0.2142131 \n    80.68792 \n    -14.271362 \n    -2.618999 \n    7.0638940 \n    -9.956171 \n    5.6958684 \n    -1.7031731 \n    -1.5878484 \n    3.2049362 \n    -2.8055485 \n    -0.9146070 \n    -0.2788690 \n    -0.0414812 \n    -0.6791649 \n    0.6176580 \n    -1.0845294 \n    0.2814645 \n    -0.1251147 \n    -2.6923536 \n    0.3492016 \n    0.3582097 \n    0.1590165 \n    -0.1397560 \n    0.3851191 \n    -1.0172323 \n    66.70615 \n    6.369703 \n    18.995024 \n    10.241030 \n    23.52605 \n    29.71595 \n    32.12247 \n    13.928651 \n    22.63694 \n    23.42001 \n    26.71856 \n    18.26408 \n    20.07234 \n    23.35500 \n    26.39624 \n    19.14299 \n    23.76156 \n    24.56074 \n    70.11466 \n    22.99117 \n    43.60260 \n    17.67860 \n    21.30309 \n    37.59117 \n    41.89435 \n    -1.4009528 \n    0.7010760 \n    -0.7045305 \n    -0.1574926 \n    1.5154837 \n    -0.7520569 \n    0.4028089 \n    -0.0182238 \n    0.7948237 \n    -1.3661896 \n    -0.2498680 \n    -0.2481627 \n    -0.4269518 \n    -0.2017573 \n    -0.7938926 \n    0.0193557 \n    -0.4020360 \n    0.3084959 \n    -1.4577410 \n    0.8179731 \n    1.3592290 \n    -0.0870922 \n    -0.5356686 \n    1.1259595 \n    -1.1072573 \n    4.357722 \n    2.810805 \n    2.649706 \n    2.619563 \n    4.438030 \n    2.480966 \n    2.730453 \n    3.850931 \n    3.129568 \n    7.021544 \n    2.527106 \n    2.478784 \n    3.173013 \n    2.777882 \n    4.113397 \n    3.492418 \n    2.974481 \n    2.135857 \n    5.292465 \n    3.666222 \n    5.296414 \n    2.925071 \n    2.714289 \n    5.456608 \n    4.853802 \n    -125.8625 \n    76790.36 \n    1904.035 \n    9282622 \n  \n  \n    Phae.long3.wav \n    2 \n    52.65548 \n    -18.25355 \n    -15.46921 \n    -0.9814104 \n    -16.17827 \n    -11.888869 \n    -16.43251 \n    -12.413136 \n    -13.303840 \n    -18.75192 \n    -14.12018 \n    -9.94332 \n    -15.28994 \n    -12.331302 \n    -15.61214 \n    -18.423967 \n    -15.98526 \n    -5.863614 \n    -28.96201 \n    -15.711890 \n    -8.452064 \n    -15.948944 \n    -11.434859 \n    -9.863952 \n    -20.625615 \n    89.25353 \n    -6.267069 \n    3.5404749 \n    15.45726 \n    3.923592 \n    13.21030 \n    15.00087 \n    5.169150 \n    12.97379 \n    15.827433 \n    8.115085 \n    9.779450 \n    14.480119 \n    14.525023 \n    12.480762 \n    15.99009 \n    11.95247 \n    15.40194 \n    9.997352 \n    13.60333 \n    19.515747 \n    13.013623 \n    12.235432 \n    24.335281 \n    8.532834 \n    83.94096 \n    -14.785131 \n    -1.626893 \n    8.0511617 \n    -11.939951 \n    7.3666675 \n    -1.5767325 \n    -1.9304223 \n    3.9549825 \n    -2.3628779 \n    -2.2937143 \n    0.0689487 \n    0.0419978 \n    0.5506128 \n    2.6936255 \n    -0.0828549 \n    -0.7624452 \n    1.5933829 \n    -1.3107263 \n    1.6486724 \n    -1.0636650 \n    -0.2454464 \n    1.3396674 \n    -1.7917913 \n    -0.2708519 \n    82.21010 \n    -13.854677 \n    -3.431409 \n    7.7150520 \n    -9.685058 \n    5.3855526 \n    -1.2871304 \n    -2.4902302 \n    3.7755805 \n    -2.3687067 \n    -2.3079403 \n    -0.2260396 \n    0.2929752 \n    0.3122023 \n    2.0454844 \n    -0.6811508 \n    -0.4060026 \n    2.1806622 \n    -1.9948232 \n    1.2881456 \n    -0.3267198 \n    -0.7317912 \n    0.8438387 \n    -0.8889085 \n    -0.8361620 \n    42.25413 \n    8.560160 \n    21.123699 \n    11.025058 \n    31.26867 \n    30.94029 \n    35.54967 \n    11.817944 \n    26.23967 \n    25.55947 \n    21.88716 \n    22.68222 \n    33.16704 \n    24.62160 \n    22.34397 \n    30.74143 \n    33.72703 \n    22.44852 \n    47.16585 \n    34.92344 \n    23.26969 \n    23.58834 \n    22.45083 \n    35.62439 \n    29.97117 \n    -1.8930677 \n    0.7772158 \n    -0.8901376 \n    -0.6048479 \n    1.2768606 \n    -1.2004938 \n    0.0747053 \n    -0.4227167 \n    -0.6352537 \n    -0.1500344 \n    -0.0730368 \n    0.0198622 \n    0.0637853 \n    0.0755629 \n    -0.8779759 \n    -0.4276955 \n    -0.2752871 \n    0.5433153 \n    -1.3120250 \n    -0.3899823 \n    1.5951218 \n    -0.4461833 \n    -0.2426493 \n    2.1671706 \n    -1.2672366 \n    7.269170 \n    2.738719 \n    2.834298 \n    3.106652 \n    3.141681 \n    3.639527 \n    3.305778 \n    3.084076 \n    3.757768 \n    6.197029 \n    2.777729 \n    2.279314 \n    2.980824 \n    3.161024 \n    4.942372 \n    4.732342 \n    2.939234 \n    2.815338 \n    6.004826 \n    2.879276 \n    6.931951 \n    3.576478 \n    2.834893 \n    9.005364 \n    5.273010 \n    -128.3608 \n    78964.35 \n    1944.363 \n    9439147 \n  \n  \n    Phae.long3.wav \n    3 \n    63.52696 \n    -17.43387 \n    -14.57354 \n    0.1866403 \n    -15.93326 \n    -14.396968 \n    -18.36977 \n    -11.647362 \n    -13.343003 \n    -17.98165 \n    -13.11832 \n    -16.41835 \n    -20.33493 \n    -12.775589 \n    -11.20505 \n    -18.584587 \n    -20.62499 \n    -13.964906 \n    -12.06025 \n    -4.988363 \n    -16.109423 \n    -10.213555 \n    -8.516935 \n    -18.866201 \n    -8.701287 \n    91.12650 \n    -7.503753 \n    2.5826560 \n    13.48428 \n    2.834422 \n    13.10069 \n    13.65352 \n    7.302118 \n    16.15262 \n    20.472092 \n    9.671298 \n    10.719213 \n    9.769547 \n    9.010339 \n    9.883183 \n    15.91783 \n    12.01769 \n    12.32896 \n    18.515104 \n    15.44906 \n    9.016017 \n    6.910449 \n    11.349493 \n    5.825247 \n    14.245435 \n    85.51208 \n    -13.948072 \n    -1.998810 \n    7.8273577 \n    -11.837170 \n    7.9332887 \n    -1.2026988 \n    -2.1468697 \n    3.1807107 \n    -0.3384937 \n    0.5821092 \n    1.6764583 \n    -0.3457622 \n    -2.1694142 \n    0.1874178 \n    0.6440910 \n    -0.4249719 \n    -0.9916752 \n    -1.5969691 \n    2.9801660 \n    -1.2317481 \n    0.5436020 \n    1.7971479 \n    -0.7717557 \n    -0.4096777 \n    83.58466 \n    -13.343884 \n    -3.480298 \n    7.6206982 \n    -9.972402 \n    4.7428909 \n    -1.4516448 \n    -2.0991832 \n    3.3138790 \n    0.5980103 \n    -0.5171419 \n    0.8157284 \n    -1.0814442 \n    -2.0648980 \n    0.1486486 \n    0.6509199 \n    -0.3674902 \n    -0.4438106 \n    -1.2793043 \n    2.9934971 \n    -1.7243883 \n    -0.2204965 \n    1.5920567 \n    -1.8211853 \n    -0.1166597 \n    38.26609 \n    6.180594 \n    19.588460 \n    6.252635 \n    23.15894 \n    46.70831 \n    34.22287 \n    12.178370 \n    23.56747 \n    38.06949 \n    26.36688 \n    25.49769 \n    36.48648 \n    20.44102 \n    17.02402 \n    31.61947 \n    36.24182 \n    29.78152 \n    39.96716 \n    23.83514 \n    23.49238 \n    16.21960 \n    17.51334 \n    21.88707 \n    17.32209 \n    -1.3816749 \n    0.5840598 \n    -0.8610223 \n    -0.3178518 \n    1.4011049 \n    -1.1539001 \n    -0.1064684 \n    -0.0661053 \n    -0.4368150 \n    0.6554118 \n    -0.4674317 \n    -1.2386606 \n    -0.7150418 \n    0.0684964 \n    -0.1159066 \n    -0.2000664 \n    -0.5671129 \n    0.1496434 \n    0.9414522 \n    0.4587045 \n    -0.7037730 \n    -0.4643647 \n    -0.1825552 \n    -1.5298169 \n    0.5314529 \n    4.343781 \n    2.312242 \n    2.915892 \n    3.155969 \n    3.884295 \n    3.095343 \n    3.790482 \n    3.333604 \n    4.731681 \n    6.012400 \n    2.580577 \n    4.922548 \n    3.601541 \n    2.964935 \n    3.123543 \n    4.569744 \n    3.543262 \n    2.893773 \n    3.845489 \n    2.555675 \n    3.552395 \n    2.311025 \n    2.649072 \n    6.034749 \n    3.781649 \n    -129.6083 \n    82306.84 \n    2000.256 \n    9816630 \n  \n  \n    Phae.long4.wav \n    1 \n    81.17215 \n    -13.36883 \n    -14.32334 \n    -11.2320300 \n    -21.52305 \n    -26.124102 \n    -18.05137 \n    -22.670714 \n    -35.172175 \n    -21.21141 \n    -28.89065 \n    -13.84315 \n    -14.23210 \n    -20.236207 \n    -28.90261 \n    -33.119291 \n    -31.18754 \n    -22.665818 \n    -21.62963 \n    -14.673295 \n    -9.679038 \n    -12.263665 \n    -14.691732 \n    -13.439850 \n    -15.336906 \n    108.29921 \n    -2.380876 \n    5.1480565 \n    16.00147 \n    17.696067 \n    25.97502 \n    28.93749 \n    16.489024 \n    20.13634 \n    38.976446 \n    24.093448 \n    13.231904 \n    22.257771 \n    18.321101 \n    23.887375 \n    26.77188 \n    23.13669 \n    21.54162 \n    18.211784 \n    21.22086 \n    19.988181 \n    12.688617 \n    14.944629 \n    14.155653 \n    12.275442 \n    97.53010 \n    -8.899641 \n    -4.317321 \n    1.2989451 \n    -6.241419 \n    -0.8226447 \n    -0.6885103 \n    1.4713862 \n    1.4524089 \n    -0.3251444 \n    3.6198024 \n    -0.8311248 \n    0.3989674 \n    0.9558217 \n    0.6628059 \n    0.2776693 \n    -1.7683483 \n    -2.0984331 \n    1.1769481 \n    -0.2437460 \n    -0.1247434 \n    1.8517956 \n    1.4611222 \n    1.4174313 \n    -2.0160800 \n    97.51269 \n    -8.327846 \n    -4.516365 \n    1.8982430 \n    -4.664118 \n    0.5742034 \n    0.8859148 \n    -1.1323628 \n    -3.7109920 \n    1.8688164 \n    1.7046859 \n    -0.6551707 \n    1.0868581 \n    1.0509441 \n    0.4126990 \n    -1.5140302 \n    -2.0060895 \n    -1.8214670 \n    0.1645343 \n    0.6260965 \n    1.1556291 \n    2.1507938 \n    0.7881952 \n    1.1083693 \n    -2.4252677 \n    20.76587 \n    6.457194 \n    20.796837 \n    37.013566 \n    104.13563 \n    210.47161 \n    130.82306 \n    91.173299 \n    235.12157 \n    214.58224 \n    145.76044 \n    45.72456 \n    66.99274 \n    69.16793 \n    164.63625 \n    220.09873 \n    117.15945 \n    73.78062 \n    73.86750 \n    62.68677 \n    33.68980 \n    20.75617 \n    39.16623 \n    34.48815 \n    34.11364 \n    -0.4807034 \n    0.5421475 \n    0.0438345 \n    0.1902813 \n    0.2445038 \n    -0.1111487 \n    0.4616688 \n    -0.4352715 \n    -0.6308532 \n    0.5428213 \n    -0.3824620 \n    0.2214837 \n    0.1234758 \n    -0.1601147 \n    -0.3068665 \n    -0.3711681 \n    0.1123062 \n    0.0542471 \n    -0.4097968 \n    0.6422774 \n    1.0350717 \n    -0.0875763 \n    -0.0956040 \n    -0.0911201 \n    -0.0404165 \n    4.419232 \n    2.571636 \n    2.702961 \n    2.563584 \n    1.968245 \n    1.689001 \n    2.557529 \n    2.212657 \n    2.168318 \n    2.549528 \n    2.553938 \n    2.109329 \n    2.098725 \n    2.811059 \n    2.180414 \n    2.540761 \n    3.042899 \n    2.909990 \n    2.772233 \n    2.916813 \n    3.810587 \n    3.135353 \n    2.707688 \n    2.576292 \n    2.502401 \n    -154.9780 \n    113957.89 \n    2232.101 \n    14009335 \n  \n  \n    Phae.long4.wav \n    2 \n    85.93936 \n    -14.02047 \n    -15.27076 \n    -10.5223514 \n    -21.86064 \n    -26.243661 \n    -16.96860 \n    -20.261418 \n    -36.413874 \n    -23.77254 \n    -31.68066 \n    -11.46582 \n    -21.10015 \n    -22.447486 \n    -29.29393 \n    -35.520761 \n    -23.81466 \n    -22.990313 \n    -18.68782 \n    -15.799625 \n    -13.474434 \n    -10.433447 \n    -14.891138 \n    -14.433316 \n    -15.925166 \n    110.11022 \n    -2.888071 \n    6.3154347 \n    15.49963 \n    17.182754 \n    23.51133 \n    26.58182 \n    13.639927 \n    19.19507 \n    37.673677 \n    24.696463 \n    13.765457 \n    18.146237 \n    21.112545 \n    28.348188 \n    27.94444 \n    24.87239 \n    22.86546 \n    20.101624 \n    19.59156 \n    18.809891 \n    11.751474 \n    13.824306 \n    14.065797 \n    14.749977 \n    97.62676 \n    -9.075638 \n    -4.180906 \n    0.8455709 \n    -5.464755 \n    -3.8783404 \n    0.2011186 \n    2.4132025 \n    0.8420818 \n    3.8453213 \n    3.6287976 \n    -0.3849610 \n    0.3042227 \n    0.3793168 \n    0.9711272 \n    0.1646577 \n    -1.6891571 \n    -1.4415768 \n    2.3309450 \n    -0.3271556 \n    -0.6194160 \n    1.1803271 \n    -0.4432385 \n    2.5612843 \n    -2.3673988 \n    97.69409 \n    -8.629931 \n    -4.223445 \n    0.9874605 \n    -4.946718 \n    0.4212339 \n    0.9734149 \n    -0.9115828 \n    -3.0815390 \n    3.9563844 \n    0.6744244 \n    -0.2094277 \n    0.9697767 \n    1.2571860 \n    0.3891992 \n    -0.8064589 \n    -0.9359416 \n    -1.3903643 \n    1.7194488 \n    0.9394113 \n    0.9244046 \n    1.5109870 \n    -0.1368488 \n    2.2985079 \n    -2.0471891 \n    17.53077 \n    5.755176 \n    23.388071 \n    35.774561 \n    106.22716 \n    213.03310 \n    109.73196 \n    88.997339 \n    230.46437 \n    213.92753 \n    184.07761 \n    36.39303 \n    63.59556 \n    93.95415 \n    172.02878 \n    220.11469 \n    103.62913 \n    80.62873 \n    64.42422 \n    61.13239 \n    49.90626 \n    20.17111 \n    29.70700 \n    40.19999 \n    30.50474 \n    0.2243093 \n    0.4586838 \n    0.0530041 \n    0.0998925 \n    0.1729316 \n    0.0212245 \n    0.2581881 \n    -0.4631797 \n    -0.7580968 \n    0.2449392 \n    -0.2923182 \n    0.1278012 \n    -0.1615675 \n    0.0110015 \n    -0.2495133 \n    -0.4236119 \n    0.4903018 \n    0.0939729 \n    -0.0785067 \n    0.4191953 \n    0.6288227 \n    0.0016867 \n    0.0707094 \n    -0.3447260 \n    0.3036929 \n    3.950107 \n    2.781237 \n    2.675812 \n    2.269614 \n    1.914863 \n    1.628221 \n    2.401728 \n    1.906990 \n    2.459879 \n    2.356779 \n    2.187576 \n    2.259377 \n    2.426807 \n    2.712683 \n    2.404569 \n    2.661049 \n    3.155811 \n    2.682496 \n    2.704227 \n    2.672580 \n    2.741615 \n    2.677712 \n    3.087750 \n    2.703029 \n    2.962267 \n    -154.4238 \n    114845.97 \n    2256.109 \n    14157377 \n  \n  \n    Phae.long4.wav \n    3 \n    79.26665 \n    -12.80419 \n    -17.38993 \n    -9.1865953 \n    -22.10634 \n    -23.168022 \n    -21.52971 \n    -17.775317 \n    -33.515447 \n    -16.75138 \n    -21.45461 \n    -17.72236 \n    -18.61181 \n    -25.293114 \n    -24.76783 \n    -32.651173 \n    -17.66339 \n    -20.192774 \n    -17.69250 \n    -12.900804 \n    -13.454919 \n    -8.309600 \n    -18.038889 \n    -12.132479 \n    -18.855531 \n    103.38287 \n    -2.418141 \n    4.9158186 \n    16.55906 \n    16.961050 \n    24.28676 \n    27.11997 \n    13.883459 \n    15.48901 \n    36.938046 \n    22.377769 \n    13.133743 \n    15.103839 \n    24.859209 \n    27.855612 \n    24.87172 \n    19.61238 \n    16.24134 \n    25.142440 \n    20.91978 \n    15.526477 \n    11.448421 \n    16.093285 \n    11.618132 \n    15.042704 \n    93.31006 \n    -8.253301 \n    -5.133685 \n    2.6243344 \n    -5.454540 \n    -1.8141510 \n    -0.1533529 \n    -0.6834088 \n    -1.9405703 \n    -0.0492234 \n    6.0518700 \n    1.1188716 \n    1.2974693 \n    1.0912988 \n    -0.0965371 \n    -1.2181218 \n    -1.0935165 \n    -1.8645593 \n    2.1029980 \n    1.5365135 \n    -2.5229097 \n    0.4406871 \n    0.9182953 \n    0.2588781 \n    -1.8460634 \n    93.50548 \n    -7.961212 \n    -4.915597 \n    2.6947909 \n    -4.828739 \n    -0.2335291 \n    0.2235244 \n    -1.6375964 \n    -5.8615842 \n    3.2727209 \n    3.5683672 \n    0.0112065 \n    1.2587745 \n    0.4999968 \n    -0.3752456 \n    -1.8739761 \n    -0.2379464 \n    -1.9890846 \n    1.4523510 \n    2.1725026 \n    -1.0218243 \n    0.7895443 \n    0.8952665 \n    0.0606613 \n    -1.6922789 \n    17.57932 \n    5.824846 \n    21.306269 \n    35.872770 \n    100.32666 \n    198.66160 \n    150.15671 \n    82.012748 \n    176.94881 \n    183.95851 \n    141.62882 \n    42.73552 \n    53.34466 \n    80.98733 \n    131.01281 \n    185.14814 \n    73.94438 \n    66.10613 \n    74.20800 \n    57.13816 \n    38.63585 \n    19.43314 \n    41.18653 \n    29.34954 \n    34.09512 \n    -0.1872895 \n    0.4808115 \n    -0.1492917 \n    0.2137390 \n    0.1219909 \n    0.0595207 \n    0.2072385 \n    -0.1410997 \n    -0.6087014 \n    0.5782024 \n    -0.4875747 \n    -0.3851620 \n    -0.5099451 \n    -0.4866950 \n    -0.0790980 \n    -0.3480380 \n    0.2234092 \n    -0.1314042 \n    0.1389349 \n    0.2740072 \n    0.4294181 \n    0.2147506 \n    -0.6054106 \n    0.0163128 \n    -0.2643390 \n    3.599611 \n    2.380272 \n    3.195556 \n    2.393710 \n    1.969326 \n    1.714357 \n    2.303348 \n    1.774513 \n    2.195820 \n    2.359424 \n    2.138020 \n    2.494256 \n    3.193837 \n    4.141875 \n    2.705730 \n    2.595008 \n    2.324069 \n    2.590252 \n    3.128677 \n    2.322027 \n    2.671382 \n    2.453939 \n    4.095454 \n    2.486660 \n    3.300506 \n    -148.1063 \n    106126.37 \n    2177.672 \n    12979235"
  },
  {
    "objectID": "measure_acoustic_structure.html#spectrographic-cross-correlation",
    "href": "measure_acoustic_structure.html#spectrographic-cross-correlation",
    "title": "Measures of acoustic structure",
    "section": "3 (Spectrographic) cross correlation",
    "text": "3 (Spectrographic) cross correlation\nThis analysis correlates the amplitude values in the frequency and time space pairwise for all signals in a selection table. The correlation represents a measure of spectrographic similarity of the signals:\n\n\nCode\nxcor <- cross_correlation(X = lbh_selec_table)\n\nxcor\n\n\n\n\n\n\n \n  \n      \n    Phae.long1.wav-1 \n    Phae.long1.wav-2 \n    Phae.long1.wav-3 \n    Phae.long2.wav-1 \n    Phae.long2.wav-2 \n    Phae.long3.wav-1 \n    Phae.long3.wav-2 \n    Phae.long3.wav-3 \n    Phae.long4.wav-1 \n    Phae.long4.wav-2 \n    Phae.long4.wav-3 \n  \n \n\n  \n    Phae.long1.wav-1 \n    1.0000000 \n    0.6638508 \n    0.6491063 \n    0.1946160 \n    0.2615196 \n    0.3339740 \n    0.2992381 \n    0.3383126 \n    0.1834400 \n    0.1577694 \n    0.2048526 \n  \n  \n    Phae.long1.wav-2 \n    0.6638508 \n    1.0000000 \n    0.7118060 \n    0.2458648 \n    0.2660671 \n    0.3280084 \n    0.2835975 \n    0.3409463 \n    0.0954318 \n    0.0913951 \n    0.1307878 \n  \n  \n    Phae.long1.wav-3 \n    0.6491063 \n    0.7118060 \n    1.0000000 \n    0.2442306 \n    0.3080008 \n    0.3520654 \n    0.3175826 \n    0.3426542 \n    0.1610333 \n    0.1476679 \n    0.1905664 \n  \n  \n    Phae.long2.wav-1 \n    0.1946160 \n    0.2458648 \n    0.2442306 \n    1.0000000 \n    0.5949237 \n    0.5617453 \n    0.5729078 \n    0.5002876 \n    0.2741691 \n    0.2470523 \n    0.2871090 \n  \n  \n    Phae.long2.wav-2 \n    0.2615196 \n    0.2660671 \n    0.3080008 \n    0.5949237 \n    1.0000000 \n    0.5098819 \n    0.5427296 \n    0.5103951 \n    0.2097443 \n    0.1923960 \n    0.2334284 \n  \n  \n    Phae.long3.wav-1 \n    0.3339740 \n    0.3280084 \n    0.3520654 \n    0.5617453 \n    0.5098819 \n    1.0000000 \n    0.7865409 \n    0.7247518 \n    0.1340282 \n    0.1314775 \n    0.1516756 \n  \n  \n    Phae.long3.wav-2 \n    0.2992381 \n    0.2835975 \n    0.3175826 \n    0.5729078 \n    0.5427296 \n    0.7865409 \n    1.0000000 \n    0.7259070 \n    0.1766590 \n    0.1735262 \n    0.1979071 \n  \n  \n    Phae.long3.wav-3 \n    0.3383126 \n    0.3409463 \n    0.3426542 \n    0.5002876 \n    0.5103951 \n    0.7247518 \n    0.7259070 \n    1.0000000 \n    0.1879558 \n    0.1754047 \n    0.2092285 \n  \n  \n    Phae.long4.wav-1 \n    0.1834400 \n    0.0954318 \n    0.1610333 \n    0.2741691 \n    0.2097443 \n    0.1340282 \n    0.1766590 \n    0.1879558 \n    1.0000000 \n    0.5277140 \n    0.8161098 \n  \n  \n    Phae.long4.wav-2 \n    0.1577694 \n    0.0913951 \n    0.1476679 \n    0.2470523 \n    0.1923960 \n    0.1314775 \n    0.1735262 \n    0.1754047 \n    0.5277140 \n    1.0000000 \n    0.5197698 \n  \n  \n    Phae.long4.wav-3 \n    0.2048526 \n    0.1307878 \n    0.1905664 \n    0.2871090 \n    0.2334284 \n    0.1516756 \n    0.1979071 \n    0.2092285 \n    0.8161098 \n    0.5197698 \n    1.0000000 \n  \n\n\n\n\n\n \nSpectrographic cross-correlation is the standard way to calculate signal similarity for amplitude variation in frequency and time\n\nExercise\n \n\nWhat does the argument type do and how does it affect the performance of the function?\nWhat does the pb argument do?"
  },
  {
    "objectID": "measure_acoustic_structure.html#dynamic-time-warping",
    "href": "measure_acoustic_structure.html#dynamic-time-warping",
    "title": "Measures of acoustic structure",
    "section": "4 Dynamic time warping",
    "text": "4 Dynamic time warping\nIn time series analysis, time dynamics distortion (DTW) is one of the algorithms to measure the similarity between two time sequences, which may vary in their ‘speed’. The sequences are nonlinearly ‘warped’ in the temporal dimension to determine a measure of their similarity independent of certain nonlinear variations in the temporal dimension.\n\n \nThe freq_DTW() function extracts the dominant frequency values as a time series and then calculates the acoustic dissimilarity using dynamic time warping. The function uses the approx() function to interpolate values between the dominant frequency measurements:\n\n\nCode\ndtwdist <- freq_DTW(lbh_selec_table)\n\n\n\n\n\n\n \n  \n      \n    Phae.long1.wav-1 \n    Phae.long1.wav-2 \n    Phae.long1.wav-3 \n    Phae.long2.wav-1 \n    Phae.long2.wav-2 \n    Phae.long3.wav-1 \n    Phae.long3.wav-2 \n    Phae.long3.wav-3 \n    Phae.long4.wav-1 \n    Phae.long4.wav-2 \n    Phae.long4.wav-3 \n  \n \n\n  \n    Phae.long1.wav-1 \n    0.0000 \n    12.7239 \n    27.8228 \n    19.2961 \n    21.7416 \n    21.2271 \n    19.4742 \n    25.1001 \n    26.2900 \n    27.1488 \n    23.8441 \n  \n  \n    Phae.long1.wav-2 \n    12.7239 \n    0.0000 \n    18.5390 \n    15.8735 \n    20.2081 \n    17.6739 \n    18.1535 \n    24.4244 \n    26.3725 \n    27.7397 \n    24.8443 \n  \n  \n    Phae.long1.wav-3 \n    27.8228 \n    18.5390 \n    0.0000 \n    29.5158 \n    29.0963 \n    24.9517 \n    28.4032 \n    28.1725 \n    31.7433 \n    33.2878 \n    31.1858 \n  \n  \n    Phae.long2.wav-1 \n    19.2961 \n    15.8735 \n    29.5158 \n    0.0000 \n    14.3232 \n    13.8198 \n    12.7713 \n    17.9298 \n    20.9547 \n    19.6867 \n    20.0898 \n  \n  \n    Phae.long2.wav-2 \n    21.7416 \n    20.2081 \n    29.0963 \n    14.3232 \n    0.0000 \n    11.3861 \n    8.1233 \n    11.0131 \n    25.7860 \n    23.6662 \n    22.5058 \n  \n  \n    Phae.long3.wav-1 \n    21.2271 \n    17.6739 \n    24.9517 \n    13.8198 \n    11.3861 \n    0.0000 \n    7.0170 \n    9.9718 \n    28.4507 \n    31.6782 \n    26.2246 \n  \n  \n    Phae.long3.wav-2 \n    19.4742 \n    18.1535 \n    28.4032 \n    12.7713 \n    8.1233 \n    7.0170 \n    0.0000 \n    8.0238 \n    24.8983 \n    26.0703 \n    23.6189 \n  \n  \n    Phae.long3.wav-3 \n    25.1001 \n    24.4244 \n    28.1725 \n    17.9298 \n    11.0131 \n    9.9718 \n    8.0238 \n    0.0000 \n    31.0330 \n    32.2880 \n    28.7885 \n  \n  \n    Phae.long4.wav-1 \n    26.2900 \n    26.3725 \n    31.7433 \n    20.9547 \n    25.7860 \n    28.4507 \n    24.8983 \n    31.0330 \n    0.0000 \n    10.2553 \n    3.6062 \n  \n  \n    Phae.long4.wav-2 \n    27.1488 \n    27.7397 \n    33.2878 \n    19.6867 \n    23.6662 \n    31.6782 \n    26.0703 \n    32.2880 \n    10.2553 \n    0.0000 \n    8.3373 \n  \n  \n    Phae.long4.wav-3 \n    23.8441 \n    24.8443 \n    31.1858 \n    20.0898 \n    22.5058 \n    26.2246 \n    23.6189 \n    28.7885 \n    3.6062 \n    8.3373 \n    0.0000 \n  \n\n\n\n\n\n \nThe function returns a matrix with paired dissimilarity values.\nIf img = TRUE, the function also produces image files with the spectrograms of the signals listed in the input data frame that shows the location of the dominant frequencies.\n\n\nCode\nfreq_DTW(lbh_selec_table, img = TRUE, col = \"red\", pch = 21, line = FALSE)\n\n\n \n\nFrequency contours can be calculated independently using the freq_ts() function. These contours can be adjusted manually with the tailor_sels() function.\n \n\nExercise\n \n\nWhat do the length.out argument infreq_DTW()?\nCalculate spectrographic cross-correlation for the inquiry calls from these individuals: c(\"206433\", \"279470\", \"279533\", \"279820\"). The extended selection table can be downloaded as follows:\n\n\n\nCode\ndownload.file(url = \"https://ndownloader.figshare.com/files/21167052\", \n destfile = \"iniquiry_calls.RDS\")\n\n\n\nWe can use a binary matrix to represent call membership. It has to be a pairwise matrix in which 0 denotes pairs of calls that belong to the same individual and 1 pairs that belong to different individuals. The following function creates this type of matrix:\n\n\n\nCode\n#function to create group membership binary matrix\nbi_mats <- function(X, labels) {\n  \n  # create empty matrix to store memebership matrix\n  mat <- matrix(nrow = ncol(X), ncol = ncol(X))\n \n  # add labels to row and col names\n  rownames(mat) <- colnames(mat) <- labels\n  \n  # add 0 if same group and 1 if else \n  out <- lapply(1:(length(labels) - 1), function(i){\n  sapply((i + 1):length(labels), function(j) \n    if (labels[i] == labels[j]) 0 else 1)  \n    })\n\n  # add to mat\n  mat[lower.tri(mat)] <- unlist(out)\n\n  # retunr as distance matrix\n  return(as.dist(mat))\n  }\n\n\nThe function takes as arguments the cross-correlation similarity matrix (‘X’ argument) and a label vector indicating group membership (‘labels’ argument). Compare dissimilarity from cross-correlation (1 - correlation matrix) with call membership using Mantel test (you can use vegan::mantel())\n \n\nDo the same test but this time using cepstral coefficient cross-correlation\nDo the same test using dynamic time warping distances"
  },
  {
    "objectID": "measure_acoustic_structure.html#additional-measures",
    "href": "measure_acoustic_structure.html#additional-measures",
    "title": "Measures of acoustic structure",
    "section": "5 Additional measures",
    "text": "5 Additional measures\n\n5.1 Signal-to-noise ratio\nsig2noise() measures this parameter. The duration of the margin in which to measure the background noise must be provided (mar argument):\n\n\nCode\nsnr <- sig2noise(X = lbh_selec_table, mar = 0.06)\n\nsnr\n\n\n\n\n\n\n \n  \n    sound.files \n    channel \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n    SNR \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    1 \n    1.1693549 \n    1.3423884 \n    2.220105 \n    8.604378 \n    21.88086 \n  \n  \n    Phae.long1.wav \n    1 \n    2 \n    2.1584085 \n    2.3214565 \n    2.169437 \n    8.807053 \n    21.17991 \n  \n  \n    Phae.long1.wav \n    1 \n    3 \n    0.3433366 \n    0.5182553 \n    2.218294 \n    8.756604 \n    19.79567 \n  \n  \n    Phae.long2.wav \n    1 \n    1 \n    0.1595983 \n    0.2921692 \n    2.316862 \n    8.822316 \n    23.60318 \n  \n  \n    Phae.long2.wav \n    1 \n    2 \n    1.4570585 \n    1.5832087 \n    2.284006 \n    8.888027 \n    26.99167 \n  \n  \n    Phae.long3.wav \n    1 \n    1 \n    0.6265520 \n    0.7577715 \n    3.006834 \n    8.822316 \n    25.80051 \n  \n  \n    Phae.long3.wav \n    1 \n    2 \n    1.9742132 \n    2.1043921 \n    2.776843 \n    8.888027 \n    26.05994 \n  \n  \n    Phae.long3.wav \n    1 \n    3 \n    0.1233643 \n    0.2545812 \n    2.316862 \n    9.315153 \n    24.61822 \n  \n  \n    Phae.long4.wav \n    1 \n    1 \n    1.5168116 \n    1.6622365 \n    2.513997 \n    9.216586 \n    28.15947 \n  \n  \n    Phae.long4.wav \n    1 \n    2 \n    2.9326920 \n    3.0768784 \n    2.579708 \n    10.235116 \n    29.30194 \n  \n  \n    Phae.long4.wav \n    1 \n    3 \n    0.1453977 \n    0.2904966 \n    2.579708 \n    9.742279 \n    24.75542 \n  \n\n\n\n\n\n \n\n\n5.2 Inflections\nInflections in this case are defined as changes in the slope of a frequency contour. They can be used as a measure of frequency modulation. They can be calculated using the inflections() function on previously measured frequency contours:\n\n\nCode\ncntrs <- freq_ts(X = lbh_selec_table)\n\ninflcts <- inflections(cntrs)\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    inflections \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    9 \n  \n  \n    Phae.long1.wav \n    2 \n    10 \n  \n  \n    Phae.long1.wav \n    3 \n    8 \n  \n  \n    Phae.long2.wav \n    1 \n    13 \n  \n  \n    Phae.long2.wav \n    2 \n    9 \n  \n  \n    Phae.long3.wav \n    1 \n    11 \n  \n  \n    Phae.long3.wav \n    2 \n    8 \n  \n  \n    Phae.long3.wav \n    3 \n    10 \n  \n  \n    Phae.long4.wav \n    1 \n    5 \n  \n  \n    Phae.long4.wav \n    2 \n    5 \n  \n  \n    Phae.long4.wav \n    3 \n    5 \n  \n\n\n\n\n\n \n\n\n5.3 Calculates parameters at higher levels of organization\nVocalizations can be organized above the basic signal units like in long repertoire songs or multi-syllable calls. We can calculate average or extreme values of acoustic parameters of the sub-units for these higher levels of organization using the function song_analysis():\n\n\nCode\n# add a 'song' column\nlbh_selec_table$song <- rep(1:4, each = 3)[1:11]\n\n# measure default parameters\nsong_analysis(X = lbh_selec_table, song_colm = \"song\", parallel = 1, pb = TRUE)\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    start \n    end \n    top.freq \n    bottom.freq \n    song \n    num.elms \n    elm.duration \n    freq.range \n    song.duration \n    song.rate \n    gap.duration \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    0.3433366 \n    2.3214565 \n    8.807053 \n    2.169437 \n    1 \n    3 \n    0.1703334 \n    6.637617 \n    1.9781199 \n    1.6528271 \n    0.7335599 \n  \n  \n    Phae.long2.wav \n    1 \n    0.1595983 \n    1.5832087 \n    8.888027 \n    2.284006 \n    2 \n    2 \n    0.1293606 \n    6.604022 \n    1.4236104 \n    1.5414731 \n    1.1648893 \n  \n  \n    Phae.long3.wav \n    1 \n    0.6265520 \n    0.7577715 \n    8.822316 \n    3.006834 \n    2 \n    1 \n    0.1312195 \n    5.815482 \n    0.1312195 \n    NA \n    NA \n  \n  \n    Phae.long3.wav \n    1 \n    0.1233643 \n    2.1043921 \n    9.315153 \n    2.316862 \n    3 \n    2 \n    0.1306979 \n    6.998291 \n    1.9810279 \n    1.0805852 \n    1.7196320 \n  \n  \n    Phae.long4.wav \n    1 \n    1.5168116 \n    1.6622365 \n    9.216586 \n    2.513997 \n    3 \n    1 \n    0.1454249 \n    6.702589 \n    0.1454249 \n    NA \n    NA \n  \n  \n    Phae.long4.wav \n    1 \n    0.1453977 \n    3.0768784 \n    10.235116 \n    2.579708 \n    4 \n    2 \n    0.1446427 \n    7.655408 \n    2.9314808 \n    0.7175417 \n    2.6421954 \n  \n\n\n\n\n\nThis can also be done on parameters extracted from other functions:\n\n\nCode\n# measure acoustic parameters\nsp <- spectro_analysis(lbh_selec_table[1:8, ], bp = c(1, 11), 300, fast = TRUE)\n\nsp <- merge(sp, lbh_selec_table[1:8, ], by = c(\"sound.files\", \"selec\"))\n\n# caculate song-level parameters for all numeric parameters\nsong_analysis(X = sp, song_colm = \"song\", parallel = 1, pb = TRUE)\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    start \n    end \n    top.freq \n    bottom.freq \n    song \n    duration \n    meanfreq \n    sd \n    freq.median \n    freq.Q25 \n    freq.Q75 \n    freq.IQR \n    time.median \n    time.Q25 \n    time.Q75 \n    time.IQR \n    skew \n    kurt \n    sp.ent \n    time.ent \n    entropy \n    sfm \n    meandom \n    mindom \n    maxdom \n    dfrange \n    modindx \n    startdom \n    enddom \n    dfslope \n    meanpeakf \n    num.elms \n    elm.duration \n    freq.range \n    song.duration \n    song.rate \n    gap.duration \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    0.3433366 \n    2.3214565 \n    8.807053 \n    2.169437 \n    1 \n    0.1703334 \n    6.214573 \n    1.886934 \n    6.398906 \n    5.279726 \n    7.088539 \n    1.808814 \n    0.0812936 \n    0.0493581 \n    0.1209826 \n    0.0716246 \n    2.641668 \n    11.645191 \n    0.9311848 \n    0.8946313 \n    0.8330688 \n    0.5799687 \n    6.717429 \n    4.2125 \n    8.4875 \n    4.2750 \n    4.743245 \n    7.0625 \n    7.2125 \n    0.8991633 \n    6.958953 \n    3 \n    0.1703334 \n    6.637617 \n    1.9781199 \n    1.652827 \n    0.7335599 \n  \n  \n    Phae.long2.wav \n    1 \n    0.1595983 \n    1.5832087 \n    8.888027 \n    2.284006 \n    2 \n    0.1293606 \n    6.587160 \n    1.811403 \n    6.713650 \n    5.632792 \n    7.562909 \n    1.930116 \n    0.0777719 \n    0.0538421 \n    0.1016897 \n    0.0478477 \n    2.543173 \n    11.544951 \n    0.9264893 \n    0.9119612 \n    0.8449154 \n    0.5528136 \n    6.397644 \n    4.0125 \n    7.7250 \n    3.7125 \n    5.151639 \n    6.0000 \n    6.4125 \n    3.4570754 \n    7.059628 \n    2 \n    0.1293606 \n    6.604022 \n    1.4236104 \n    1.541473 \n    1.1648893 \n  \n  \n    Phae.long3.wav \n    1 \n    0.6265520 \n    0.7577715 \n    8.822316 \n    3.006834 \n    2 \n    0.1312195 \n    6.737204 \n    1.649035 \n    6.724085 \n    6.053354 \n    7.585366 \n    1.532012 \n    0.0626394 \n    0.0402682 \n    0.0894848 \n    0.0492167 \n    2.502406 \n    10.411846 \n    0.9105878 \n    0.9112879 \n    0.8298076 \n    0.4934158 \n    6.622331 \n    4.8375 \n    8.0625 \n    3.2250 \n    3.674419 \n    7.0125 \n    8.0625 \n    8.0018575 \n    6.757601 \n    1 \n    0.1312195 \n    5.815482 \n    0.1312195 \n    NA \n    NA \n  \n  \n    Phae.long3.wav \n    1 \n    0.1233643 \n    2.1043921 \n    9.315153 \n    2.316862 \n    3 \n    0.1306979 \n    6.713171 \n    1.644077 \n    6.711681 \n    6.046112 \n    7.591542 \n    1.545430 \n    0.0664694 \n    0.0410781 \n    0.0940970 \n    0.0530189 \n    2.280022 \n    8.186695 \n    0.9069198 \n    0.9123649 \n    0.8274417 \n    0.4830629 \n    6.315848 \n    4.6500 \n    7.2750 \n    2.6250 \n    4.211745 \n    5.7000 \n    6.8250 \n    8.5827023 \n    6.719848 \n    2 \n    0.1306979 \n    6.998291 \n    1.9810279 \n    1.080585 \n    1.7196320 \n  \n\n\n\n\n\n \nCalculate song-level parameters selecting parameters with ‘mean_colm’:\n\n\nCode\n# caculate song-level parameters selecting parameters with mean_colm\nsong_analysis(X = sp, song_colm = \"song\",mean_colm = c(\"dfrange\", \"duration\"), parallel = 1, pb = TRUE)\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    start \n    end \n    top.freq \n    bottom.freq \n    song \n    dfrange \n    duration \n    num.elms \n    elm.duration \n    freq.range \n    song.duration \n    song.rate \n    gap.duration \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    0.3433366 \n    2.3214565 \n    8.807053 \n    2.169437 \n    1 \n    4.2750 \n    0.1703334 \n    3 \n    0.1703334 \n    6.637617 \n    1.9781199 \n    1.652827 \n    0.7335599 \n  \n  \n    Phae.long2.wav \n    1 \n    0.1595983 \n    1.5832087 \n    8.888027 \n    2.284006 \n    2 \n    3.7125 \n    0.1293606 \n    2 \n    0.1293606 \n    6.604022 \n    1.4236104 \n    1.541473 \n    1.1648893 \n  \n  \n    Phae.long3.wav \n    1 \n    0.6265520 \n    0.7577715 \n    8.822316 \n    3.006834 \n    2 \n    3.2250 \n    0.1312195 \n    1 \n    0.1312195 \n    5.815482 \n    0.1312195 \n    NA \n    NA \n  \n  \n    Phae.long3.wav \n    1 \n    0.1233643 \n    2.1043921 \n    9.315153 \n    2.316862 \n    3 \n    2.6250 \n    0.1306979 \n    2 \n    0.1306979 \n    6.998291 \n    1.9810279 \n    1.080585 \n    1.7196320 \n  \n\n\n\n\n\n \nCalculate song-level parameters for selecting parameters with ‘mean_colm’, ‘max_colm’ and ‘min_colm’ and weighted by duration:\n\n\nCode\nsong_analysis(X = sp, weight = \"duration\", song_colm = \"song\",\nmean_colm =  c(\"dfrange\", \"duration\"), min_colm =  \"mindom\", max_colm = \"maxdom\", \n  parallel = 1, pb = TRUE)\n\n\n\n\n\n\n \n  \n    sound.files \n    selec \n    start \n    end \n    top.freq \n    bottom.freq \n    song \n    dfrange \n    duration \n    min.mindom \n    max.maxdom \n    num.elms \n    elm.duration \n    freq.range \n    song.duration \n    song.rate \n    gap.duration \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    0.3433366 \n    2.3214565 \n    8.807053 \n    2.169437 \n    1 \n    4.281334 \n    0.1704927 \n    3.8625 \n    8.6625 \n    3 \n    0.1703334 \n    6.637617 \n    1.9781199 \n    1.652827 \n    0.7335599 \n  \n  \n    Phae.long2.wav \n    1 \n    0.1595983 \n    1.5832087 \n    8.888027 \n    2.284006 \n    2 \n    3.691095 \n    0.1294402 \n    3.0375 \n    7.8375 \n    2 \n    0.1293606 \n    6.604022 \n    1.4236104 \n    1.541473 \n    1.1648893 \n  \n  \n    Phae.long3.wav \n    1 \n    0.6265520 \n    0.7577715 \n    8.822316 \n    3.006834 \n    2 \n    3.225000 \n    0.1312195 \n    4.8375 \n    8.0625 \n    1 \n    0.1312195 \n    5.815482 \n    0.1312195 \n    NA \n    NA \n  \n  \n    Phae.long3.wav \n    1 \n    0.1233643 \n    2.1043921 \n    9.315153 \n    2.316862 \n    3 \n    2.623809 \n    0.1307000 \n    4.6125 \n    7.5375 \n    2 \n    0.1306979 \n    6.998291 \n    1.9810279 \n    1.080585 \n    1.7196320 \n  \n\n\n\n\n\n \n \n\nExercise\n \n\nSpix’s disc-winged bats (Thyroptera tricolor) its a Neotropical species that uses a specific call type to reply to social mates looking for their roosts. Those ‘response’ calls look like this:\n\n \n\n \nAn extended selection table with response calls can be read from github as follows:\n\n\n\n\n\nCode\ndownload.file(url = \"https://github.com/maRce10/OTS_BIR_2023/raw/master/examples/response_calls.RDS\", \n destfile = \"./examples/response_calls.RDS\")\n\nresponse_calls <- readRDS(\"./examples/response_calls.RDS\")\n\n\n \n\nCalculate spectrographic parameters (spectro_analysis()) for the Spix’s disc-winged bat response calls.\nSummarize parameters by call (song_analysis()). To do that you should add the column ‘start’, ‘end’ and ‘call’ to the output of spectro_analysis()"
  },
  {
    "objectID": "measure_acoustic_structure.html#references",
    "href": "measure_acoustic_structure.html#references",
    "title": "Measures of acoustic structure",
    "section": "6 References",
    "text": "6 References\n\nAraya-Salas M, A Hernández-Pinsón N RojasΔ, G Chaverri. (2020). Ontogeny of an interactive call-and-response system in Spix’s disc-winged bats. Animal Behaviour.\nAraya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to streamline analysis of animal acoustic signals. Methods Ecol Evol 8:184–191.\nLyon, R. H., & Ordubadi, A. (1982). Use of cepstra in acoustical signal analysis. Journal of Mechanical Design, 104(2), 303-306.\nSalamon, J., Jacoby, C., & Bello, J. P. (2014). A dataset and taxonomy for urban sound research. In Proceedings of the 22nd ACM international conference on Multimedi. 1041-1044.\n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4   warbleR_1.1.28     NatureSounds_1.0.4 knitr_1.42        \n[5] seewave_2.2.0      tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] xfun_0.39         pbapply_1.7-0     vctrs_0.6.2       colorspace_2.1-0 \n [5] testthat_3.1.8    htmltools_0.5.5   viridisLite_0.4.1 yaml_2.3.7       \n [9] rlang_1.1.1       glue_1.6.2        foreach_1.5.2     lifecycle_1.0.3  \n[13] stringr_1.5.0     munsell_0.5.0     rvest_1.0.3       htmlwidgets_1.5.4\n[17] codetools_0.2-19  evaluate_0.21     fastmap_1.1.1     fftw_1.0-7       \n[21] parallel_4.2.2    highr_0.10        Rcpp_1.0.10       scales_1.2.1     \n[25] webshot_0.5.4     jsonlite_1.8.4    Sim.DiffProc_4.8  soundgen_2.5.3   \n[29] systemfonts_1.0.4 Deriv_4.1.3       brio_1.1.3        rjson_0.2.21     \n[33] digest_0.6.31     stringi_1.7.12    dtw_1.23-1        cli_3.6.1        \n[37] tools_4.2.2       bitops_1.0-7      magrittr_2.0.3    RCurl_1.98-1.12  \n[41] proxy_0.4-27      MASS_7.3-58.2     xml2_1.3.4        shinyBS_0.61.1   \n[45] rmarkdown_2.21    svglite_2.1.0     httr_1.4.6        rstudioapi_0.14  \n[49] iterators_1.0.14  R6_2.5.1          signal_0.7-7      compiler_4.2.2"
  },
  {
    "objectID": "ohun.html",
    "href": "ohun.html",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "",
    "text": "Get familiar with concepts and data formatting practices related to automatic acoustic signals detection\nLearn how to run automatic detection using the package ohun\nohun is intended to facilitate the automated detection of sound events, providing functions to diagnose and optimize detection routines. Detections from other software can also be explored and optimized.\nAll functions allow the parallelization of tasks, which distributes the tasks among several processors to improve computational efficiency. The package works on sound files in ‘.wav’, ‘.mp3’, ‘.flac’ and ‘.wac’ format.\nTo install the latest developmental version from github you will need the R package remotes:"
  },
  {
    "objectID": "ohun.html#energy-based-detection",
    "href": "ohun.html#energy-based-detection",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "3.1 Energy-based detection",
    "text": "3.1 Energy-based detection\nThis detector uses amplitude envelopes to infer the position of sound events. Amplitude envelopes are representations of the variation in energy through time. The following code plots an amplitude envelope along with the spectrogram for the example data lbh1:\n\n\nCode\n# plot spectrogram and envelope\nlabel_spectro(\n  wave = cutw(\n    lbh1,\n    from = 0,\n    to = 1.5,\n    output = \"Wave\"\n  ),\n  ovlp = 90,\n  hop.size = 10,\n  flim = c(0, 10),\n  envelope = TRUE\n)\n\n\n\n\n\n\n\n\n\n \nThis type of detector doesn’t require highly stereotyped sound events, although they work better on high quality recordings in which the amplitude of target sound events is higher than the background noise (i.e. high signal-to-noise ratio). The function ernergy_detector() performs this type of detection.\n \n\n3.1.1 How it works\nWe can understand how to use ernergy_detector() using simulated sound events. We will do that using the function simulate_songs() from warbleR. In this example we simulate a recording with 10 sounds with two different frequency ranges and durations:\n\n\nCode\n# install this package first if not installed\n# install.packages(\"Sim.DiffProc\")\n\n#Creating vector for duration \ndurs <- rep(c(0.3, 1), 5)\n\n#Creating simulated song\nset.seed(12)\nsimulated_1 <-\n  warbleR::simulate_songs(\n    n = 10,\n    durs = durs,\n    freqs = 5,\n    sig2 = 0.01,\n    gaps = 0.5,\n    harms = 1,\n    bgn = 0.1,\n    path = tempdir(),\n    file.name = \"simulated_1\",\n    selec.table = TRUE,\n    shape = \"cos\",\n    fin = 0.3,\n    fout = 0.35,\n    samp.rate = 18\n  )$wave\n\n\n \nThe function call saves a ‘.wav’ sound file in a temporary directory (tempdir()) and also returns a wave object in the R environment. This outputs will be used to run energy-based detection and creating plots, respectively. This is how the spectrogram and amplitude envelope of the simulated recording look like:\n\n\nCode\n# plot spectrogram and envelope\nlabel_spectro(wave = simulated_1,\n              env = TRUE,\n              fastdisp = TRUE)\n\n\n\n\n\n\n\n\n\n \nNote that the amplitude envelope shows a high signal-to-noise ratio of the sound events, which is ideal for energy-based detection. This can be conducted using ernergy_detector() as follows:\n\n\nCode\n# run detection\ndetection <-\n  energy_detector(\n    files = \"simulated_1.wav\",\n    bp = c(2, 8),\n    threshold = 50,\n    smooth = 150,\n    path = tempdir()\n  )\n\n# plot spectrogram and envelope\nlabel_spectro(\n  wave = simulated_1,\n  envelope = TRUE,\n  detection = detection,\n  threshold = 50\n)\n\n\n\n\n\n\n\n\n\n \nThe output is a selection table:\n\n\nCode\ndetection\n\n\n\n\n\n\nsound.files\nduration\nselec\nstart\nend\n\n\n\n\nsimulated_1.wav\n0.2328344\n1\n0.5309469\n0.7637813\n\n\nsimulated_1.wav\n0.7946703\n2\n1.3954509\n2.1901213\n\n\nsimulated_1.wav\n0.2334455\n3\n2.8307909\n3.0642364\n\n\nsimulated_1.wav\n0.7943926\n4\n3.6955171\n4.4899097\n\n\nsimulated_1.wav\n0.2333344\n5\n5.1307460\n5.3640804\n\n\nsimulated_1.wav\n0.7945037\n6\n5.9955833\n6.7900870\n\n\nsimulated_1.wav\n0.2330566\n7\n7.4307566\n7.6638133\n\n\nsimulated_1.wav\n0.7948926\n8\n8.2954273\n9.0903199\n\n\nsimulated_1.wav\n0.2334455\n9\n9.7307673\n9.9642128\n\n\nsimulated_1.wav\n0.7946148\n10\n10.5954935\n11.3901083\n\n\n\n\n\n\nNow we will make use of some additional arguments to filter out specific sound events based on their structural features. For instance we can use the argument minimum.duration to provide a time treshold (in ms) to exclude short sound events and keep only the longest sound events:\n\n\nCode\n# run detection\ndetection <-\n  energy_detector(\n    files = \"simulated_1.wav\",\n    bp = c(1, 8),\n    threshold = 50,\n    min.duration = 500,\n    smooth = 150,\n    path = tempdir()\n  )\n\n# plot spectrogram\nlabel_spectro(wave = simulated_1, detection = detection)\n\n\n\n\n\n\n\n\n\n \nWe can use the argument max.duration (also in ms) to exclude long sound events and keep the short ones:\n\n\nCode\n# run detection\ndetection <- energy_detector(files = \"simulated_1.wav\", bp = c(1, 8),  threshold = 50, smooth = 150, max.duration = 500, path = tempdir())\n\n# plot spectrogram\nlabel_spectro(wave = simulated_1,  detection = detection)\n\n\n\n\n\n\n\n\n\n \nWe can also focus the detection on specific frequency ranges using the argument bp (bandpass). By setting bp = c(5, 8) only those sound events found within that frequency range (5-8 kHz) will be detected, which excludes sound events below 5 kHz:\n\n\nCode\n# Detecting \ndetection <- energy_detector(files = \"simulated_1.wav\", bp = c(5, 8), threshold = 50, smooth = 150, path = tempdir())\n\n# plot spectrogram\nlabel_spectro(wave = simulated_1,  detection = detection)\n\n\n\n\n\n\n\n\n\n \nThe same logic can be applied to detect those sound events found below 5 kHz. We just need to set the upper bound of the band pass filter below the range of the higher frequency sound events (for instance bp = (0, 6)):\n\n\nCode\n# Detect\ndetection <-\n  energy_detector(\n    files = \"simulated_1.wav\",\n    bp = c(0, 6),\n    threshold = 50,\n    min.duration = 1,\n    smooth = 150,\n    path = tempdir()\n  )\n\n# plot spectrogram\nlabel_spectro(wave = simulated_1,  detection = detection)\n\n\n\n\n\n\n\n\n\n \nAmplitude modulation (variation in amplitude across a sound event) can be problematic for detection based on amplitude envelopes. We can also simulate some amplitude modulation using warbleR::simulate_songs():\n\n\nCode\n#Creating simulated song\nset.seed(12)\n\n#Creating vector for duration\ndurs <- rep(c(0.3, 1), 5)\n\nsim_2 <-\n  sim_songs(\n    n = 10,\n    durs = durs,\n    freqs = 5,\n    sig2 = 0.01,\n    gaps = 0.5,\n    harms = 1,\n    bgn = 0.1,\n    path = tempdir(),\n    file.name = \"simulated_2\",\n    selec.table = TRUE,\n    shape = \"cos\",\n    fin = 0.3,\n    fout = 0.35,\n    samp.rate = 18,\n    am.amps = c(1, 2, 3, 2, 0.1, 2, 3, 3, 2, 1)\n  )\n\n# extract wave object and selection table\nsimulated_2 <- sim_2$wave\nsim2_sel_table <- sim_2$selec.table\n\n# plot spectrogram\nlabel_spectro(wave = simulated_2, envelope = TRUE)\n\n\n\n\n\n\n\n\n\n \nWhen sound events have strong amplitude modulation they can be split during detection:\n\n\nCode\n# detect sounds\ndetection <- energy_detector(files = \"simulated_2.wav\", threshold = 50, path = tempdir())\n\n# plot spectrogram\nlabel_spectro(wave = simulated_2, envelope = TRUE, threshold = 50, detection = detection)\n\n\n\n\n\n\n\n\n\n \nThere are two arguments that can deal with this: holdtime and smooth. hold.time allows to merge split sound events that are found within a given time range (in ms). This time range should be high enough to merge things belonging to the same sound event but not too high so it merges different sound events. For this example a hold.time of 200 ms can do the trick (we know gaps between sound events are ~0.5 s long):\n\n\nCode\n# detect sounds\ndetection <-\n  energy_detector(\n    files = \"simulated_2.wav\",\n    threshold = 50,\n    min.duration = 1,\n    path = tempdir(),\n    hold.time = 200\n  )\n\n# plot spectrogram\nlabel_spectro(\n  wave = simulated_2,\n  envelope = TRUE,\n  threshold = 50,\n  detection = detection\n)\n\n\n\n\n\n\n\n\n\n \nsmooth works by merging the amplitude envelope ‘hills’ of the split sound events themselves. It smooths envelopes by applying a sliding window averaging of amplitude values. It’s given in ms of the window size. A smooth of 350 ms can merged back split sound events from our example:\n\n\nCode\n# detect sounds\ndetection <-\n  energy_detector(\n    files = \"simulated_2.wav\",\n    threshold = 50,\n    min.duration = 1,\n    path = tempdir(),\n    smooth = 350\n  )\n\n# plot spectrogram\nlabel_spectro(\n  wave = simulated_2,\n  envelope = TRUE,\n  threshold = 50,\n  detection = detection,\n  smooth = 350\n)\n\n\n\n\n\n\n\n\n\n \nThe function has some additional arguments for further filtering detections (peak.amplitude) and speeding up analysis (thinning and parallel).\n \n\n\n3.1.2 Optimizing energy-based detection\nThis last example using smooth can be used to showcase how the tunning parameters can be optimized. As explained above, to do this we need a reference table that contains the time position of the target sound events. The function optimize_energy_detector() can be used finding the optimal parameter values. We must provide the range of parameter values that will be evaluated:\n\n\nCode\noptim_detection <-\n  optimize_energy_detector(\n    reference = sim2_sel_table,\n    files = \"simulated_2.wav\",\n    threshold = 50,\n    min.duration = 1,\n    path = tempdir(),\n    smooth = c(100, 250, 350)\n  )\n\n\n3 combinations will be evaluated:\n\n\nCode\noptim_detection[, c(1, 2:5, 7:12, 17:18)]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthreshold\npeak.amplitude\nsmooth\nhold.time\nmin.duration\nthinning\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmean.duration.false.negatives\nproportional.duration.true.positives\n\n\n\n\n50\n0\n100\n0\n1\n1\n20\n20\n0\n0\n10\nNA\n1.000000\n\n\n50\n0\n250\n0\n1\n1\n15\n15\n0\n0\n5\nNA\n1.179487\n\n\n50\n0\n350\n0\n1\n1\n10\n10\n0\n0\n0\nNA\n1.000000\n\n\n\n\n\n\n \nThe output contains the combination of parameters used at each iteration as well as the corresponding diagnose indices. In this case all combinations generate a good detection (recall & precision = 1). However, only the routine with the highest smooth (last row) has no split sound events (‘split.positive’ column). It also shows a better overlap to the reference sound events (‘overlap.to.true.positives’ closer to 1).\nIn addition, there are two complementary functions for optimizing energy-based detection routines: feature_reference() and merge_overlaps(). feature_reference() allow user to get a sense of the time and frequency characteristics of a reference table. This information can be used to determine the range of tuning parameter values during optimization. This is the output of the function applied to lbh_reference:\n\n\nCode\nfeature_reference(reference = lbh_reference, path = tempdir())\n\n\n                  min   mean    max\nsel.duration   117.96 142.60 163.73\ngap.duration   624.97 680.92 811.61\nannotations      9.00   9.50  10.00\nduty.cycle       0.24   0.27   0.31\npeak.amplitude  73.76  81.58  88.03\nbottom.freq      1.81   2.11   2.37\ntop.freq         8.49   8.82   9.53\n\n\n \nFeatures related to selection duration can be used to set the ‘max.duration’ and ‘min.duration’ values, frequency related features can inform banpass values, gap related features inform hold time values and duty cycle can be used to evaluate performance. Peak amplitude can be used to keep only those sound events with the highest intensity, mostly useful for routines in which only a subset of the target sound events present in the recordings is needed.\nmerge_overlaps() finds time-overlapping selections in reference tables and collapses them into a single selection. Overlapping selections would more likely appear as a single amplitude ‘hill’ and thus would be detected as a single sound event. So merge_overlaps() can be useful to prepare references in a format representing a more realistic expectation of how a pefect energy detection routine would look like."
  },
  {
    "objectID": "ohun.html#template-based-detection",
    "href": "ohun.html#template-based-detection",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "3.2 Template-based detection",
    "text": "3.2 Template-based detection\nThis detection method is better suited for highly stereotyped sound events. As it doesn’t depend on the signal-to-noise ratio it’s more robust to higher levels of background noise. The procedure is divided in three steps:\n\nChoosing the right template (get_templates())\nEstimating the cross-correlation scores of templates along sound files (template_correlator())\n\nDetecting sound events by applying a correlation threshold (template_detector())\n\nThe function get_templates() can help you find a template closer to the average acoustic structure of the sound events in a reference table. This is done by finding the sound events closer to the centroid of the acoustic space. When the acoustic space is not supplied (‘acoustic.space’ argument) the function estimates it by measuring several acoustic parameters using the function spectro_analysis() from warbleR) and summarizing it with Principal Component Analysis (after z-transforming parameters). If only 1 template is required the function returns the sound event closest to the acoustic space centroid. The rationale here is that a sound event closest to the average sound event structure is more likely to share structural features with most sounds across the acoustic space than a sound event in the periphery of the space. These ‘mean structure’ templates can be obtained as follows:\n\n\nCode\n# get mean structure template\ntemplate <-\n  get_templates(reference = lbh1_reference, path = tempdir())\n\n\n\n\n\n\n\n\n\n\n\n \nThe graph above shows the overall acoustic spaces, in which the sound closest to the space centroid is highlighted. The highlighted sound is selected as the template and can be used to detect similar sound events. The function get_templates() can also select several templates. This can be helpful when working with sounds that are just moderately stereotyped. This is done by dividing the acoustic space into sub-spaces defined as equal-size slices of a circle centered at the centroid of the acoustic space:\n\n\nCode\n# get 3 templates\nget_templates(reference = lbh_reference, \n                          n.sub.spaces = 3, path = tempdir())\n\n\n\n\n\n\n\n\n\n\n\nWe will use the single template object (‘template’) to run a detection on the example ‘lbh1’ data:\n\n\nCode\n# get correlations\ncorrelations <-\n  template_correlator(templates = template,\n                      files = \"lbh1.wav\",\n                      path = tempdir())\n\n\n \nThe output is an object of class ‘template_correlations’, with its own printing method:\n\n\nCode\n# print\ncorrelations\n\n\n \nThis object can then be used to detect sound events using template_detector():\n\n\nCode\n# run detection\ndetection <-\n  template_detector(template.correlations = correlations, threshold = 0.4)\n\ndetection\n\n\n\n\n\n\nsound.files\nselec\nstart\nend\ntemplate\nscores\n\n\n\n\nlbh1.wav\n1\n0.0815573\n0.2347256\nlbh1.wav-16\n0.7158107\n\n\nlbh1.wav\n2\n0.5709008\n0.7240692\nlbh1.wav-16\n0.7245840\n\n\nlbh1.wav\n3\n1.0602444\n1.2134127\nlbh1.wav-16\n0.6442318\n\n\nlbh1.wav\n4\n1.1301507\n1.2833190\nlbh1.wav-16\n0.4265326\n\n\nlbh1.wav\n5\n1.3398693\n1.4930377\nlbh1.wav-16\n0.4010336\n\n\nlbh1.wav\n6\n1.7127025\n1.8658709\nlbh1.wav-16\n0.7723560\n\n\nlbh1.wav\n7\n2.1903951\n2.3435634\nlbh1.wav-16\n0.6275264\n\n\nlbh1.wav\n8\n2.2253482\n2.3785165\nlbh1.wav-16\n0.4237697\n\n\nlbh1.wav\n9\n2.7030407\n2.8562091\nlbh1.wav-16\n0.8026335\n\n\nlbh1.wav\n10\n3.1923843\n3.3455526\nlbh1.wav-16\n0.9976684\n\n\nlbh1.wav\n11\n3.2273374\n3.3805058\nlbh1.wav-16\n0.4264247\n\n\nlbh1.wav\n12\n3.6817279\n3.8348962\nlbh1.wav-16\n0.7645678\n\n\nlbh1.wav\n13\n3.7166810\n3.8698493\nlbh1.wav-16\n0.4474148\n\n\nlbh1.wav\n14\n4.1477694\n4.3009377\nlbh1.wav-16\n0.6407355\n\n\nlbh1.wav\n15\n4.6371130\n4.7902813\nlbh1.wav-16\n0.7392135\n\n\nlbh1.wav\n16\n4.6720661\n4.8252344\nlbh1.wav-16\n0.4108326\n\n\n\n\n\n\n \nThe output can be explored by plotting the spectrogram along with the detection and correlation scores:\n\n\nCode\n# plot spectrogram\nlabel_spectro(\n  wave = lbh1,\n  detection = detection,\n  template.correlation = correlations[[1]],\n  flim = c(0, 10),\n  threshold = 0.4,\n  hop.size = 10, ovlp = 50)\n\n\n\n\n\n\n\n\n\n \nThe performance can be evaluated using diagnose_detection():\n\n\nCode\n#diagnose\ndiagnose_detection(reference = lbh1_reference, detection = detection)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmerged.positives\noverlap.to.true.positives\nrecall\nprecision\nf1.score\n\n\n\n\n15\n15\n1\n0\n5\n0\n0.8613333\n1\n0.9375\n0.9677419\n\n\n\n\n\n\n \n\n3.2.1 Optimizing template-based detection\nThe function optimize_template_detector() allows to evaluate the performance under different correlation thresholds:\n\n\nCode\n# run optimization\noptimization <-\n  optimize_template_detector(\n    template.correlations = correlations,\n    reference = lbh1_reference,\n    threshold = seq(0.1, 0.5, 0.1)\n  )\n\n\n5 thresholds will be evaluated:\n\n\nCode\n# print output\noptimization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthreshold\ntemplates\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmerged.positives\noverlap.to.true.positives\nrecall\nprecision\nf1.score\n\n\n\n\n0.1\nlbh1.wav-16\n54\n54\n43\n0\n10\n0\n0.5105556\n1\n0.5567010\n0.7152318\n\n\n0.2\nlbh1.wav-16\n40\n40\n32\n0\n10\n0\n0.5827500\n1\n0.5555556\n0.7142857\n\n\n0.3\nlbh1.wav-16\n32\n32\n3\n0\n10\n0\n0.6709375\n1\n0.9142857\n0.9552239\n\n\n0.4\nlbh1.wav-16\n15\n15\n1\n0\n5\n0\n0.8613333\n1\n0.9375000\n0.9677419\n\n\n0.5\nlbh1.wav-16\n10\n10\n0\n0\n0\n0\n0.9610000\n1\n1.0000000\n1.0000000\n\n\n\n\n\n\n \nAdditional threshold values can be evaluated without having to run it all over again. We just need to supplied the output from the previous run with the argument previous.output (the same trick can be done when optimizing an energy-based detection):\n\n\nCode\n# run optimization\noptimize_template_detector(\n  template.correlations = correlations,\n  reference = lbh1_reference,\n  threshold = c(0.6, 0.7),\n  previous.output = optimization\n)\n\n\n2 thresholds will be evaluated:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthreshold\ntemplates\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmerged.positives\noverlap.to.true.positives\nrecall\nprecision\nf1.score\n\n\n\n\n0.1\nlbh1.wav-16\n54\n54\n43\n0\n10\n0\n0.5105556\n1.0\n0.5567010\n0.7152318\n\n\n0.2\nlbh1.wav-16\n40\n40\n32\n0\n10\n0\n0.5827500\n1.0\n0.5555556\n0.7142857\n\n\n0.3\nlbh1.wav-16\n32\n32\n3\n0\n10\n0\n0.6709375\n1.0\n0.9142857\n0.9552239\n\n\n0.4\nlbh1.wav-16\n15\n15\n1\n0\n5\n0\n0.8613333\n1.0\n0.9375000\n0.9677419\n\n\n0.5\nlbh1.wav-16\n10\n10\n0\n0\n0\n0\n0.9610000\n1.0\n1.0000000\n1.0000000\n\n\n0.6\nlbh1.wav-16\n10\n10\n0\n0\n0\n0\n0.9610000\n1.0\n1.0000000\n1.0000000\n\n\n0.7\nlbh1.wav-16\n7\n7\n0\n3\n0\n0\n0.9542857\n0.7\n1.0000000\n0.8235294\n\n\n\n\n\n\n \nIn this case several threshold values can achieved an optimal detection.\n \n\n\n3.2.2 Detecting several templates\nSeveral templates can be used within the same call. Here we correlate two templates on the two example sound files, taking one template from each sound file:\n\n\nCode\n# get correlations\ncorrelations <-\n  template_correlator(\n    templates = lbh_reference[c(1, 10),],\n    files = c(\"lbh1.wav\", \"lbh2.wav\"),\n    path = tempdir()\n  )\n\n# run detection\ndetection <-\n  template_detector(template.correlations = correlations, threshold = 0.5)\n\ncorrelations <-\n  template_correlator(\n    templates = lbh_reference[c(1, 10),],\n    files = c(\"lbh1.wav\", \"lbh2.wav\"),\n    path = tempdir()\n  )\n\n\n \nNote that in these cases we can get the same sound event detected several times (duplicates), one by each template. We can check if that is the case just by diagnosing the detection:\n\n\nCode\n#diagnose\ndiagnose_detection(reference = lbh_reference, detection = detection)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmerged.positives\noverlap.to.true.positives\nrecall\nprecision\nf1.score\n\n\n\n\n23\n23\n0\n0\n4\n0\n0.9573913\n1\n1\n1\n\n\n\n\n\n\n \nDuplicates are shown as split positives. Fortunately, we can leave a single detected sound event by leaving only those with the highest correlation. To do this we first need to label each row in the detection using label_detection() and then remove duplicates using filter_detection():\n\n\nCode\n# labeling detection\nlabeled <-\n  label_detection(reference = lbh_reference, detection = detection)\n\n\nThis function adds a column (‘detection.class’) with the class label for each row:\n\n\nCode\ntable(labeled$detection.class)\n\n\n\n        true.positive true.positive (split) \n                   15                     8 \n\n\n \nNow we can filter out duplicates and diagnose the detection again, telling the function to select a single row per duplicate using the correlation score as a criterium (by = \"scores\", this column is part of the template_detector() output):\n\n\nCode\n# filter\nfiltered <- filter_detection(detection = labeled, by = \"scores\")\n\n# diagnose\ndiagnose_detection(reference = lbh_reference, detection = filtered)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntotal.detections\ntrue.positives\nfalse.positives\nfalse.negatives\nsplit.positives\nmerged.positives\noverlap.to.true.positives\nrecall\nprecision\nf1.score\n\n\n\n\n19\n19\n0\n0\n0\n0\n0.95\n1\n1\n1\n\n\n\n\n\n\n \nWe successfully get rid of duplicates and detected every single target sound event."
  },
  {
    "objectID": "ohun.html#improving-detection-speed",
    "href": "ohun.html#improving-detection-speed",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "3.3 Improving detection speed",
    "text": "3.3 Improving detection speed\nDetection routines can take a long time when working with large amounts of acoustic data (e.g. large sound files and/or many sound files). These are some useful points to keep in mine when trying to make a routine more time-efficient:\n\nAlways test procedures on small data subsets\ntemplate_detector() is faster than energy_detector()\nParallelization (see parallel argument in most functions) can significantly speed-up routines, but works better on Unix-based operating systems (linux and mac OS)\nSampling rate matters: detecting sound events on low sampling rate files goes faster, so we should avoid having nyquist frequencies (sampling rate / 2) way higher than the highest frequency of the target sound events (sound files can be downsampled using warbleR’s fix_sound_files())\nLarge sound files can make the routine crash, use split_acoustic_data() to split both reference tables and files into shorter clips.\nThink about using a computer with lots of RAM memory or a computer cluster for working on large amounts of data\nthinning argument (which reduces the size of the amplitude envelope) can also speed-up energy_detector()"
  },
  {
    "objectID": "ohun.html#additional-tips",
    "href": "ohun.html#additional-tips",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "3.4 Additional tips",
    "text": "3.4 Additional tips\n\nUse your knowledge about the sound event structure to determine the initial range for the tuning parameters in a detection optimization routine\nIf people have a hard time figuring out where a target sound event occurs in a recording, detection algorithms will also have a hard time\nSeveral templates representing the range of variation in sound event structure can be used to detect semi-stereotyped sound events\nMake sure reference tables contain all target sound events and only the target sound events. The performance of the detection cannot be better than the reference itself.\nAvoid having overlapping sound events or several sound events as a single one (like a multi-syllable vocalization) in the reference table when running an energy-based detector\nLow-precision can be improved by training a classification model (e.g. random forest) to tell sound events from noise\n\n\n\nPlease cite ohun like this:\nAraya-Salas, M. (2021), ohun: diagnosing and optimizing automated sound event detection. R package version 0.1.0."
  },
  {
    "objectID": "ohun.html#references",
    "href": "ohun.html#references",
    "title": "ohun: optimizing acoustic signal detection",
    "section": "3.5 References",
    "text": "3.5 References\n\nAraya-Salas, M. (2021), ohun: diagnosing and optimizing automated sound event detection. R package version 0.1.0.\nAraya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to streamline analysis of animal sound events. Methods Ecol Evol 8:184-191.\nKhanna H., Gaunt S.L.L. & McCallum D.A. (1997). Digital spectrographic cross-correlation: tests of sensitivity. Bioacoustics 7(3): 209-234.\nKnight, E.C., Hannah, K.C., Foley, G.J., Scott, C.D., Brigham, R.M. & Bayne, E. (2017). Recommendations for acoustic recognizer performance assessment with application to five common automated signal recognition programs. Avian Conservation and Ecology,\nMacmillan, N. A., & Creelman, C.D. (2004). Detection theory: A user’s guide. Psychology press.\n\n \n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C               LC_TIME=es_CR.UTF-8       \n [4] LC_COLLATE=es_ES.UTF-8     LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                  LC_ADDRESS=C              \n[10] LC_TELEPHONE=C             LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ohun_0.1.1         warbleR_1.1.28     NatureSounds_1.0.4 knitr_1.42        \n[5] seewave_2.2.0      tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10        class_7.3-21       fftw_1.0-7         digest_0.6.31     \n [5] foreach_1.5.2      utf8_1.2.3         R6_2.5.1           Sim.DiffProc_4.8  \n [9] signal_0.7-7       evaluate_0.21      e1071_1.7-12       ggplot2_3.4.0     \n[13] pillar_1.9.0       rlang_1.1.1        rstudioapi_0.14    rmarkdown_2.21    \n[17] htmlwidgets_1.5.4  igraph_1.3.5       RCurl_1.98-1.12    munsell_0.5.0     \n[21] proxy_0.4-27       compiler_4.2.2     Deriv_4.1.3        xfun_0.39         \n[25] pkgconfig_2.0.3    htmltools_0.5.5    tidyselect_1.2.0   tibble_3.2.1      \n[29] gridExtra_2.3      codetools_0.2-19   dtw_1.23-1         fansi_1.0.4       \n[33] viridisLite_0.4.1  dplyr_1.1.0        sf_1.0-9           shinyBS_0.61.1    \n[37] MASS_7.3-58.2      bitops_1.0-7       brio_1.1.3         grid_4.2.2        \n[41] jsonlite_1.8.4     gtable_0.3.1       lifecycle_1.0.3    DBI_1.1.3         \n[45] magrittr_2.0.3     units_0.8-1        scales_1.2.1       KernSmooth_2.23-20\n[49] cli_3.6.1          pbapply_1.7-0      viridis_0.6.2      testthat_3.1.8    \n[53] generics_0.1.3     vctrs_0.6.2        rjson_0.2.21       iterators_1.0.14  \n[57] tools_4.2.2        glue_1.6.2         parallel_4.2.2     fastmap_1.1.1     \n[61] yaml_2.3.7         colorspace_2.1-0   soundgen_2.5.3     classInt_0.4-8"
  },
  {
    "objectID": "seewave.html",
    "href": "seewave.html",
    "title": "Seewave",
    "section": "",
    "text": "seewave provides a wide variety of tools to accurately assess sound properties in the R environment. It is an extensive package with lots of features. The package allows to visualize and measure characteristics of time, frequency and amplitude of sounds. The tools are arranged in a modular way (each analysis in its own function) which allows combining them to generate more elaborate analyzes.\nThe majority of the functions of seewave work on wave objects (but not on audio files in folders). Here we will see examples of some of these tools, focusing on those that are potentially more useful for the study of vocal behavior in animals.\nFirst we must load the package:\nWe can see the description of the package seewave in this way:"
  },
  {
    "objectID": "seewave.html#oscillograms",
    "href": "seewave.html#oscillograms",
    "title": "Seewave",
    "section": "1 Oscillograms",
    "text": "1 Oscillograms\nYou can create the oscillogram of the entire “wave” object like this:\n\n\nCode\noscillo(tico) \n\n\n\n\n\nWe can also generate it for a segment:\n\n\nCode\noscillo(tico, from = 0, to = 1)\n\n\n\n\n\nThe visualizations in seewave allow a high degree of customization. For example change the color:\n\n\nCode\noscillo(tico, from = 0, to = 1, colwave = \"#8fcc78\")\n\n\n\n\n\nAs with most seewave functions many other components of the chart can be modified, for example:\n\n\nCode\n# grey background\nop <- par(bg = \"grey\")\n\noscillo(tico, f = 22050, k = 4 , j = 1,\n        title = TRUE,\n        colwave = \"black\", \n        coltitle = \"yellow\",\n        collab = \"red\",\n        colline = \"white\",\n        colaxis = \"blue\",\n        coly0 = \"grey50\")\n\n\n\n\n\n \nWe can also generate other representations of “amplitude vs. time”, such as “amplitude envelopes”:\n\n\nCode\nenv(tico, f = 22050, colwave = \"#8fcc78\")\n\n\n\n\n\nWe can superimpose it on the oscillogram to facilitate comparison:\n\n\nCode\noscillo(tico, f = 22050)\n\npar(new=TRUE)\n\nenv(tico, f = 22050, colwave = \"#8fcc78\")\n\n\n\n\n\n\n\n\n \n\nSliding window for time series\n \nSliding windows allow you to smooth out the contours of a time series by calculating an average value around the “neighborhood” of values for a given value. In the case of amplitude envelope the size of the “neighborhood” is given by the length of the window (“wl”). The larger the window length, the greater the smoothing of the curve:\n \n\n \nThis animation shows how the amplitude envelope of the “tico” object is smoothed with a 512-point window:\n \n\n \n… or a 1024 point window:\n \n\n \n\n \nWe can use these amplitude “hills” to define segments in the “wave” object using the timer() function. The “ssmooth” argument allows us to use a sliding window:\n\n\nCode\ntmr <- timer(orni, f = 22050, threshold = 5, ssmooth = 40, \n             bty = \"l\", colval = \"#51c724\")\n\n\n\n\n\nCode\ntmr\n\n\n$s\n[1] 6.013985e-02 5.918741e-02 5.134111e-02 4.535434e-05 5.728253e-02\n[6] 4.535434e-05 6.667088e-03 4.535434e-05 4.966300e-02\n\n$p\n [1] 2.208756e-02 1.004599e-01 8.272631e-02 2.267717e-04 8.594647e-02\n [6] 4.535434e-05 8.132033e-02 4.988977e-04 4.535434e-05 6.068410e-02\n\n$r\n[1] 0.6552769\n\n$s.start\n[1] 0.02208756 0.18268727 0.32460099 0.37616887 0.46216069 0.51948857 0.60085425\n[8] 0.60802024 0.60811095\n\n$s.end\n[1] 0.08222741 0.24187468 0.37594210 0.37621422 0.51944322 0.51953393 0.60752134\n[8] 0.60806559 0.65777395\n\n$first\n[1] \"pause\"\n\n\n \nThe output is a list with the following elements:\n\ns: duration of detected signals (in s)\np: duration of pauses (i.e. gaps) between signals\nr: ratio of s to r\ns.start: start of signals\nend: end of signals\n\n \n\nExercise\n\nIn the previous example using timer() the last pulse is divided into 2 detections, one very small at the beginning and another containing the rest of the pulse. Change the “ssmooth” argument until this section is detected as a single pulse."
  },
  {
    "objectID": "seewave.html#power-spectra",
    "href": "seewave.html#power-spectra",
    "title": "Seewave",
    "section": "2 Power Spectra",
    "text": "2 Power Spectra\nWe can visualize the amplitude in the frequency domain using power spectra. The meanspec() function calculates the average distribution of energy in the frequency range (the average power spectrum):\n\n\nCode\nmspc <- meanspec(orni, f = 22050, wl = 512, col = \"#daeace\")\n\npolygon(rbind(c(0, 0), mspc), col = \"#daeace\")\n\n\n\n\n\nCode\nnrow(mspc)\n\n\n[1] 256\n\n\nThe spec() function, on the other hand, calculates the spectrum for the entire signal:\n\n\nCode\nspc <- spec(orni, f=22050, wl=512, col = \"#8fcc78\")\n\n\n\n\n\nCode\nnrow(spc)\n\n\n[1] 7921\n\n\nThe result of spec() or meanspec() can be input into the fpeaks() function to calculate amplitude peaks:\n\n\nCode\npks <- fpeaks(spc, nmax = 1)\n\n\n\n\n\nCode\npks\n\n\n         [,1] [,2]\n[1,] 4.860409    1"
  },
  {
    "objectID": "seewave.html#wave-manipulation",
    "href": "seewave.html#wave-manipulation",
    "title": "Seewave",
    "section": "3 Wave manipulation",
    "text": "3 Wave manipulation\nWe can cut segments of a “wave” object:\n\n\nCode\ntico2 <- cutw(tico, to = 1, output = \"Wave\")\n\noscillo(tico2)\n\n\n\n\n\nAdd segments:\n\n\nCode\ntico3 <- pastew(tico, tico2, output = \"Wave\")\n\noscillo(tico3)\n\n\n\n\n\nRemove segments:\n\n\nCode\ntico4 <- deletew(tico3, output = \"Wave\", from = duration(tico), to = duration(tico3))\n\noscillo(tico4)\n\n\n\n\n\nAdd segments of silence:\n\n\nCode\ntico5 <- addsilw(tico, at = \"end\", d = 1, output = \"Wave\")\n\nduration(tico)\n\n\n[1] 1.794921\n\n\nCode\nduration(tico5)\n\n\n[1] 2.794921\n\n\n \n\nExercise\n\nThe function rev() can reverse te order of a vector:\n\n\n\nCode\nv1 <- c(1, 2, 3)\n\nrev(v1)\n\n\n[1] 3 2 1\n\n\n\nReverse the amplitude vector of ‘tico’ and generate a spectrogram of the reversed wave object\n\n\n \nFilter out frequency bands:\n\n\nCode\n# original\nspectro(tico, scale = FALSE, grid = FALSE, flim = c(2, 6))\n\n\n\n\n\nCode\n# filtered\nspectro(ffilter(tico, from = 4000, to = 6500, output = \"Wave\"), scale = FALSE, grid = FALSE, flim = c(2, 6))\n\n\n\n\n\nChange frequency (pitch):\n\n\nCode\n# cut the first\ntico6 <- cutw(tico, from = 0, to = 0.5, output = \"Wave\")\n\n# increase frec\ntico.lfs <- lfs(tico6, shift = 1000, output = \"Wave\")\n\n# decrease frec\ntico.lfs.neg <- lfs(tico6, shift = -1000, output = \"Wave\")\n\n# 3 column graph\nopar <- par()\npar(mfrow = c(1, 3))\n\n# original\nspectro(tico6, scale = FALSE, grid = FALSE, flim = c(1, 8), main = \"original\")\n\n# modified\nspectro(tico.lfs, scale = FALSE, grid = FALSE, flim = c(1, 8), main = \"1 kHz up\")\n\nspectro(tico.lfs.neg, scale = FALSE, grid = FALSE, flim = c(1, 8), main = \"1 kHz down\")\n\n\n\n\n\nCode\npar(opar)"
  },
  {
    "objectID": "seewave.html#measurements",
    "href": "seewave.html#measurements",
    "title": "Seewave",
    "section": "4 Measurements",
    "text": "4 Measurements\n \nApart from the measurements of peak frequency (fpeaks()) and duration (timer()), we can measure many other aspects of the acoustic signals using seewave. For example, we can estimate the fundamental frequency (which refers to the lowest frequency harmonic in the harmonic stack), with the fund() function:\n\n\nCode\nspectro(sheep, scale = FALSE, grid = FALSE)\n\npar(new=TRUE)\n\nff <- fund(sheep, fmax = 300, ann = FALSE, threshold=6, col = \"green\")\n\n\n\n\n\nCode\nhead(ff)\n\n\n              x          y\n[1,] 0.00000000         NA\n[2,] 0.06677027         NA\n[3,] 0.13354054         NA\n[4,] 0.20031081         NA\n[5,] 0.26708108 0.10000000\n[6,] 0.33385135 0.07142857\n\n\n \nThis function uses cepstral transformation to detect the dominant frequency. The autoc() function also measures the fundamental frequency, only using autocorrelation.\nSimilarly we can measure the dominant frequency (the harmonic with the highest energy):\n\n\nCode\npar(new=TRUE)\n\ndf <- dfreq(sheep, f = 8000, fmax = 300, type = \"p\", pch = 24, ann = FALSE, threshold = 6, col = \"red\")\n\nhead(df)\n\n\n\n\n\n\n\n              x        y\n[1,] 0.00000000       NA\n[2,] 0.06677027       NA\n[3,] 0.13354054       NA\n[4,] 0.20031081       NA\n[5,] 0.26708108 0.484375\n[6,] 0.33385135 0.625000\n\n\n \nMeasure statistical descriptors of the amplitude distribution in frequency and time:\n\n\nCode\n# cut\nnote2 <- cutw(tico, from=0.6, to=0.9, output=\"Wave\")\n\nn2.as <- acoustat(note2)\n\n\n\n\n\nCode\nas.data.frame(n2.as[3:8])\n\n\n\n\n\n\ntime.P1\ntime.M\ntime.P2\ntime.IPR\nfreq.P1\nfreq.M\n\n\n\n\n0.0272727\n0.1090909\n0.2181818\n0.1909091\n3.445312\n4.263574\n\n\n\n\n\n\n \nMeasure statistical descriptors of frequency spectra:\n\n\nCode\n# measure power spectrum\nn2.sp <- meanspec(note2, plot = FALSE)\n\nn2.spcp <- specprop(n2.sp, f = note2@samp.rate)\n\nas.data.frame(n2.spcp)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\nsd\nmedian\nsem\nmode\nQ25\nQ75\nIQR\ncent\nskewness\nkurtosis\nsfm\nsh\nprec\n\n\n\n\n4346.889\n694.2615\n4306.641\n43.39134\n4349.707\n3789.844\n4780.371\n990.5273\n4346.889\n2.224789\n6.645413\n0.023993\n0.6968186\n43.06641\n\n\n\n\n\n\n \n\nExercise\n\nMeasure the statistical descriptors of the frequency spectra (function specprop()) on the 3 notes (hint: you must cut each note first)\n\n\n \n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] seewave_2.2.0\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     MASS_7.3-58.2     jsonlite_1.8.4    signal_0.7-7     \n [5] evaluate_0.21     rlang_1.1.1       cli_3.6.1         rstudioapi_0.14  \n [9] rmarkdown_2.21    tools_4.2.2       tuneR_1.4.4       htmlwidgets_1.5.4\n[13] xfun_0.39         yaml_2.3.7        fastmap_1.1.1     compiler_4.2.2   \n[17] htmltools_0.5.5   knitr_1.42"
  },
  {
    "objectID": "program.html#day-1-video",
    "href": "program.html#day-1-video",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "1 Day 1 (video)",
    "text": "1 Day 1 (video)\n\n\n\n1.1 Readings\n\n1.1.1 Intro to basic bioacoustics concepts\n\nKöhler, J., Jansen, M., Rodríguez, A., Kok, P. J. R., Toledo, L. F., Emmrich, M., … & Vences, M. (2017). The use of bioacoustics in anuran taxonomy: theory, terminology, methods and recommendations for best practice. Zootaxa, 4251(1), 1-124. (at least the first 28 pages)\n\n\n\n\n1.2 Videos\n\nIntroduction to digital audio\nDigital audio artifacts: (Video 1, Video 2)\n\n \n\n\n1.3 Optional readings\n\n1.3.1 Reproducibility\n\nAlston, J. M., & Rick, J. A. (2021). A beginner’s guide to conducting reproducible research. Bulletin of the Ecological Society of America, 102(2), 1-14.\nCulina, A., van den Berg, I., Evans, S., & Sánchez-Tójar, A. (2020). Low availability of code in ecology: A call for urgent action. PLoS Biology, 18(7), e3000763.\n\n\n\n\n \nIntroduction Introduction\n\nHow animal acoustic signals look like?\nAnalytical workflow in bioacoustics research\nAdvantages of programming\nCourse outline\n\n \nWhat is sound? Sound\n\n\nCreate a Rstudio project for the course\nDownload this folder into the course project directory\n\n\n\nSound as a time series\nSound as a digital object\nAcoustic data in R\n‘wave’ object structure\n‘wave’ object manipulations\nadditional formats\n\n \n\n1.4 Homework\n\nUse the function query_xc() to check the availability of recordings for any bird species (do not download at this step) (check this brief tutorial on how to do that)\nSubset the data frame returned by the function to get a subset of subspecies/populations or recordings from a specific country and for certain vocalization type (using base R subsetting tools)\nDownload the associated recordings using query_xc() again\nExplore the recordings with any spectrogram creating GUI program"
  },
  {
    "objectID": "program.html#day-2-video",
    "href": "program.html#day-2-video",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "2 Day 2 (video)",
    "text": "2 Day 2 (video)\n\n\n2.1 Videos\n\n2.1.1 Raven tutorials\n\nIntroduction to the Raven Pro Interface\nIntroduction to selections and measurements\nSaving, retrieving, and exporting selection tables\nUsing annotations\n\n\n\nBuilding spectrograms Building spectrograms\n\nFourier transform\nBuilding a spectrogram\nCharacteristics and limitations\nSpectrograms in R\n\nPackage seewave seewave\n\nExplore, modify and measure ‘wave’ objects\nSpectrograms and oscillograms\nFiltering and re-sampling\nAcoustic measurements\n\n \n\n2.2 Homework\n\nUse Raven Pro to annotate some of the signals found in the xeno-canto recordings you downloaded previously"
  },
  {
    "objectID": "program.html#day-3-video",
    "href": "program.html#day-3-video",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "3 Day 3 (video)",
    "text": "3 Day 3 (video)\n\n\n3.1 Readings\n\nArasco, A. G., Manser, M., Watson, S. K., Kyabulima, S., Radford, A. N., Cant, M. A., & Garcia, M. (2023). Testing the acoustic adaptation hypothesis with vocalizations from three mongoose species. Animal Behaviour, 187, 71-95.\n\n\n \nAnnotation software annotations\n\nRaven / audacity\nOpen and explore recordings\nModify-optimize visualization parameters\nAnnotate signals\n\nQuantifying acoustic signal structure Quantify structure\n\nSpectro-temporal measurements (spectro_analysis())\nParameter description\nHarmonic content\nCepstral coefficients (mfcc_stats())\nCross-correlation (cross_correlation())\nDynamic time warping (freq_DTW())\nSignal-to-noise ratio (sig2noise())\nInflections (inflections())\nParameters at other levels (song_analysis())\n\n \n\n3.2 Homework\n\nDouble-check annotations using warbleR’s dedicated functions\n\n\nCreate single spectrograms of each annotation\nCreate full spectrograms of all sound files along with annotations\nCreate catalogs\n\n \n\nDouble-check annotations using Raven (export data from R to Raven)"
  },
  {
    "objectID": "program.html#day-4-video",
    "href": "program.html#day-4-video",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "4 Day 4 (video)",
    "text": "4 Day 4 (video)\n\n\n4.1 Readings\n\n4.1.1 \n\nOdom, K. J., Cain, K. E., Hall, M. L., Langmore, N. E., Mulder, R. A., Kleindorfer, S., … & Webster, M. S. (2021). Sex role similarity and sexual selection predict male and female song elaboration and dimorphism in fairy‐wrens. Ecology and evolution, 11(24), 17901-17919.\n\n\n\n \nQuality control in recordings and annotation Quality checks\n\nCheck and modify sound file format (check_wavs(), info_wavs(), duration_wavs(), mp32wav() y fix_wavs())\nTuning spectrogram parameters (tweak_spectro())\nDouble-checking selection tables (check_sels(), spectrograms(), full_spectrograms() & catalog())\nRe-adjusting selections (tailor_sels())\n\nCharacterizing hierarchical levels in acoustic signals\n\nCreating ‘song’ spectrograms (full_spectrograms(), spectrograms())\n‘Song’ parameters (song_analysis())\n\n \n\n4.2 Homework\n\nSelect best quality signals for analysis\nMeasure acoustic parameters\nSummarize variation at higher hierachical levels (if necessary)"
  },
  {
    "objectID": "program.html#day-5-video",
    "href": "program.html#day-5-video",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "5 Day 5 (video)",
    "text": "5 Day 5 (video)\n\n\n5.1 Readings\n\nBlog post: Potential issues of the ‘spectral parameters/PCA’ approach\nBlog post: Choosing the right method for measuring acoustic signal structure\n\n\n \nChoosing the right method for quantifying structure Comparing methods\n\nCompare different methods for quantifying structure (compare_methods())\n\nQuantifying acoustic spaces Acoustic space\n\nIntro to PhenotypeSpace\nQuanitfying space size\nComparing sub-spaces"
  },
  {
    "objectID": "quality_checks.html",
    "href": "quality_checks.html",
    "title": "Quality checks for recordings and annotations",
    "section": "",
    "text": "When working with sound files obtained from various sources it is common to have variation in recording formats and parameters or even find corrupt files. Similarly, when a large number of annotations are used, it is normal to find errors in some of them. These problems may prevent the use of acoustic analysis in warbleR. Luckily, the package also offers functions to facilitate the detection and correction of errors in sound files and annotations."
  },
  {
    "objectID": "quality_checks.html#convert-.mp3-to-.wav",
    "href": "quality_checks.html#convert-.mp3-to-.wav",
    "title": "Quality checks for recordings and annotations",
    "section": "1 Convert .mp3 to .wav",
    "text": "1 Convert .mp3 to .wav\nThe mp32wav() function allows you to convert files in ‘.mp3’ format to ‘.wav’ format. This function converts all the ‘mp3’ files in the working directory. Let’s use the files in the ‘./examples/mp3’ folder as an example:\n\n\n\n\n\nCode\nwarbleR_options(wav.path = \"./examples\", ovlp = 90)\n\nlist.files(path = \"./examples/mp3\", pattern = \"mp3$\")\n\nmp32wav(path = \"./examples/mp3\", dest.path = \"./examples/mp3\")\n\nlist.files(path = \"./examples/mp3\", pattern = \"mp3$|wav$\")\n\n\n\n\n[1] \"BlackCappedVireo.mp3\" \"BowheadWhaleSong.mp3\" \"CanyonWren.mp3\"      \n\n\n[1] \"BlackCappedVireo.mp3\" \"BlackCappedVireo.wav\" \"BowheadWhaleSong.mp3\"\n[4] \"BowheadWhaleSong.wav\" \"CanyonWren.mp3\"       \"CanyonWren.wav\"      \n\n\n \nWe can also modify the sampling rate and/or dynamic range with mp32wav():\n\n\nCode\nmp32wav(path = \"./examples/mp3\", samp.rate = 48, bit.depth = 24, overwrite = TRUE,\n    dest.path = \"./examples/mp3\")\n\nlist.files(path = \"./examples/mp3\")\n\n\n \nWe can check the properties of the ‘.wav’ sound files using the info_sound_files() function:\n\n\nCode\ninfo_sound_files(path = \"./examples/mp3\")\n\n\n\n\n\n\n \n  \n    sound.files \n    duration \n    sample.rate \n    channels \n    bits \n    wav.size \n    samples \n  \n \n\n  \n    BlackCappedVireo.mp3 \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.087770 \n    120384 \n  \n  \n    BlackCappedVireo.wav \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.240812 \n    120384 \n  \n  \n    BowheadWhaleSong.mp3 \n    86.648163 \n    22.05 \n    1 \n    16 \n    1.386787 \n    1910592 \n  \n  \n    BowheadWhaleSong.wav \n    86.648163 \n    22.05 \n    1 \n    16 \n    3.821228 \n    1910592 \n  \n  \n    CanyonWren.mp3 \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.087352 \n    239616 \n  \n  \n    CanyonWren.wav \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.479276 \n    239616"
  },
  {
    "objectID": "quality_checks.html#homogenize-recordings",
    "href": "quality_checks.html#homogenize-recordings",
    "title": "Quality checks for recordings and annotations",
    "section": "2 Homogenize recordings",
    "text": "2 Homogenize recordings\nAlternatively, we can use the fix_wavs() function to homogenize the sampling rate, the dynamic interval and the number of channels. It is adviced that all sound files should have the same recording parameters before any acoustic analysis. In the example ‘.mp3’ files, not all of them have been recorded with the same parameters. We can see this if we convert them back to ‘.wav’ and see their properties:\n\n\nCode\nmp32wav(path = \"./examples/mp3\", overwrite = TRUE, dest.path = \"./examples/mp3\"\n\ninfo_sound_files(path = \"./examples/mp3\")\n\n\n\n\n\n\n \n  \n    sound.files \n    duration \n    sample.rate \n    channels \n    bits \n    wav.size \n    samples \n  \n \n\n  \n    BlackCappedVireo.mp3 \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.087770 \n    120384 \n  \n  \n    BlackCappedVireo.wav \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.240812 \n    120384 \n  \n  \n    BowheadWhaleSong.mp3 \n    86.648163 \n    22.05 \n    1 \n    16 \n    1.386787 \n    1910592 \n  \n  \n    BowheadWhaleSong.wav \n    86.648163 \n    22.05 \n    1 \n    16 \n    3.821228 \n    1910592 \n  \n  \n    CanyonWren.mp3 \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.087352 \n    239616 \n  \n  \n    CanyonWren.wav \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.479276 \n    239616 \n  \n\n\n\n\n\n \nThe fix_wavs() function will convert all files to the same sampling rate and dynamic range:\n\n\nCode\nfix_wavs(path = mp3.pth, samp.rate = 44.1, bit.depth = 24)\n\ninfo_sound_files(path = \"./examples/mp3/converted_sound_files\")\n\n\n\n\n\n\n\n\n\n \n  \n    sound.files \n    duration \n    sample.rate \n    channels \n    bits \n    wav.size \n    samples \n  \n \n\n  \n    BlackCappedVireo.mp3 \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.087770 \n    120384 \n  \n  \n    BlackCappedVireo.wav \n    5.459592 \n    22.05 \n    1 \n    16 \n    0.240812 \n    120384 \n  \n  \n    BowheadWhaleSong.mp3 \n    86.648163 \n    22.05 \n    1 \n    16 \n    1.386787 \n    1910592 \n  \n  \n    BowheadWhaleSong.wav \n    86.648163 \n    22.05 \n    1 \n    16 \n    3.821228 \n    1910592 \n  \n  \n    CanyonWren.mp3 \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.087352 \n    239616 \n  \n  \n    CanyonWren.wav \n    5.433469 \n    44.10 \n    1 \n    16 \n    0.479276 \n    239616 \n  \n\n\n\n\n\nAnother useful function to check file properties is wav_dur(). This function returns the duration in seconds of each ‘.wav’ file."
  },
  {
    "objectID": "quality_checks.html#check-recordings",
    "href": "quality_checks.html#check-recordings",
    "title": "Quality checks for recordings and annotations",
    "section": "3 Check recordings",
    "text": "3 Check recordings\ncheck_sound_files() should be the first function that should be used before running any warbleR analysis. The function simply checks if the sound files in ‘.wav’ format in the working directory can be read in R. For example, the following code checks all the files in the ‘examples’ folder, which should detect the ‘corrupted_file.wav’:\n\n\nCode\ncheck_sound_files()\n\n\n\n\n\nIf we remove that file from the folder, the function returns the following message:\n\n\nCode\ncheck_sound_files()"
  },
  {
    "objectID": "quality_checks.html#spectrograph-settings",
    "href": "quality_checks.html#spectrograph-settings",
    "title": "Quality checks for recordings and annotations",
    "section": "4 Spectrograph settings",
    "text": "4 Spectrograph settings\nThe parameters that determine the appearance of spectrograms (and power spectra and periodgrams) also have an effect on the measurements taken on them. Therefore it is necessary to use the same parameters to analyze all the signals in a project (except with some exceptions) so that the measurements are comparable. The visualization of spectrograms generated with different spectrographic parameters is a useful way of defining the combination of parameters with which the structure of the signals is distinguished in more detail. The function tweak_spectro() aims to simplify the selection of parameters through the display of spectrograms. The function plots, for a single selection, a mosaic of spectrograms with different display parameters. For numerical arguments, the upper and lower limits of a range can be provided. The following parameters may have variable values:\n\nwl: window length (numerical range)\novlp: overlap (numerical range)\ncollev.min: minimum amplitude value for color levels (numerical range)\nwn: window function name (character)\npal: palette (character)\n\nThe following code generates an image with spectrograms that vary in window size and window function (the rest of the parameters are passed to the catalog () function internally to create the mosaic):\n\n\nCode\ntweak_spectro(X = lbh_selec_table, wl = c(100, 1000), wn = c(\"hanning\",\n    \"hamming\", \"rectangle\"), length.out = 16, nrow = 8, ncol = 6,\n    width = 15, height = 20, rm.axes = TRUE, cex = 1, box = F)\n\n\n\n \nNote that the length.out argument defines the number of values to interpolate within the numerical ranges. wl = 220 seems to produce clearer spectrograms.\nWe can add a color palette to differentiate the levels of one of the parameters, for example ‘wn’:\n\n\nCode\n# install.packages('RColorBrewer')\n\nlibrary(RColorBrewer)\n\n# crear paleta\ncmc <- function(n) if (n > 5) rep(adjustcolor(brewer.pal(5, \"Spectral\"),\n    alpha.f = 0.6), ceiling(n/4))[1:n] else adjustcolor(brewer.pal(n,\n    \"Spectral\"), alpha.f = 0.6)\n\ntweak_spectro(X = lbh_selec_table, wl = c(100, 1000), wn = c(\"hanning\",\n    \"hamming\", \"rectangle\"), length.out = 16, nrow = 8, ncol = 6,\n    width = 15, height = 20, rm.axes = TRUE, cex = 1, box = F, group.tag = \"wn\",\n    tag.pal = list(cmc))\n\n\n\n \nWe can also use it to choose the color palette and the minimum amplitude for plotting (‘collev.min’):\n\n\nCode\ntweak_spectro(X = lbh_selec_table, wl = 220, collev.min = c(-20, -100),\n    pal = c(\"reverse.gray.colors.2\", \"reverse.topo.colors\", \"reverse.terrain.colors\"),\n    length.out = 16, nrow = 8, ncol = 6, width = 15, height = 20,\n    rm.axes = TRUE, cex = 1, box = F, group.tag = \"pal\", tag.pal = list(cmc))"
  },
  {
    "objectID": "quality_checks.html#double-check-selections",
    "href": "quality_checks.html#double-check-selections",
    "title": "Quality checks for recordings and annotations",
    "section": "5 Double-check selections",
    "text": "5 Double-check selections\nThe main function to double-check selection tables is check_sels(). This function checks a large number of possible errors in the selection information:\n\n‘X’ is an object of the class ‘data.frame’ or ‘selection_table’ (see selection_table) and contains the columns required to be used in any warbleR function (‘sound.files’, ‘selec’, ‘start’ , ‘end’, if it does not return an error)\n‘sound.files’ in ‘X’ corresponds to the .wav files in the working directory or in the provided ‘path’ (if no file is found it returns an error, if some files are not found it returns error information in the output data frame)\nthe time limit parameters (‘start’, ‘end’) and frequency (‘bottom.freq’, ‘top.freq’, if provided) are numeric and do not contain NA (if they do not return an error)\nThere are no duplicate selection tags (‘selec’) within a sound file (if it does not return an error)\nsound files can be read (error information in the output data frame)\nThe start and end time of the selections is within the duration of the sound files (error information in the output data frame)\nSound files can be read (error information in the output data frame)\nThe header (header) of the sound files is not damaged (only if the header = TRUE, error information in the selection table with results)\n‘top.freq’ is less than half of the sampling frequency (nyquist frequency, error information in the data table with results)\nNegative values are not found in the time or frequency limit parameters (error information in the data table with results)\n‘start’ higher than ‘end’ or ‘bottom.freq’ higher than ‘top.freq’ (error information in the output data frame)\nThe value of ‘channel’ is not greater than the number of channels in the sound files (error information in the output data frame)\n\n\n\nCode\ncs <- check_sels(lbh_selec_table)\n\n\n \nThe function returns a data frame that includes the information in ‘X’ plus additional columns about the format of the sound files, as well as the result of the checks (column ‘check.res’):\n\n\nCode\ncs\n\n\n\n\n\n\n \n  \n    sound.files \n    channel \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n    check.res \n    duration \n    min.n.samples \n    sample.rate \n    channels \n    bits \n    sound.file.samples \n  \n \n\n  \n    Phae.long1.wav \n    1 \n    1 \n    1.1693549 \n    1.3423884 \n    2.220105 \n    8.604378 \n    OK \n    0.1730334 \n    3893 \n    22.5 \n    1 \n    16 \n    56251 \n  \n  \n    Phae.long1.wav \n    1 \n    2 \n    2.1584085 \n    2.3214565 \n    2.169437 \n    8.807053 \n    OK \n    0.1630480 \n    3668 \n    22.5 \n    1 \n    16 \n    56251 \n  \n  \n    Phae.long1.wav \n    1 \n    3 \n    0.3433366 \n    0.5182553 \n    2.218294 \n    8.756604 \n    OK \n    0.1749187 \n    3935 \n    22.5 \n    1 \n    16 \n    56251 \n  \n  \n    Phae.long2.wav \n    1 \n    1 \n    0.1595983 \n    0.2921692 \n    2.316862 \n    8.822316 \n    OK \n    0.1325709 \n    2982 \n    22.5 \n    1 \n    16 \n    38251 \n  \n  \n    Phae.long2.wav \n    1 \n    2 \n    1.4570585 \n    1.5832087 \n    2.284006 \n    8.888027 \n    OK \n    0.1261502 \n    2838 \n    22.5 \n    1 \n    16 \n    38251 \n  \n  \n    Phae.long3.wav \n    1 \n    1 \n    0.6265520 \n    0.7577715 \n    3.006834 \n    8.822316 \n    OK \n    0.1312195 \n    2952 \n    22.5 \n    1 \n    16 \n    49500 \n  \n  \n    Phae.long3.wav \n    1 \n    2 \n    1.9742132 \n    2.1043921 \n    2.776843 \n    8.888027 \n    OK \n    0.1301789 \n    2929 \n    22.5 \n    1 \n    16 \n    49500 \n  \n  \n    Phae.long3.wav \n    1 \n    3 \n    0.1233643 \n    0.2545812 \n    2.316862 \n    9.315153 \n    OK \n    0.1312170 \n    2952 \n    22.5 \n    1 \n    16 \n    49500 \n  \n  \n    Phae.long4.wav \n    1 \n    1 \n    1.5168116 \n    1.6622365 \n    2.513997 \n    9.216586 \n    OK \n    0.1454249 \n    3272 \n    22.5 \n    1 \n    16 \n    72000 \n  \n  \n    Phae.long4.wav \n    1 \n    2 \n    2.9326920 \n    3.0768784 \n    2.579708 \n    10.235116 \n    OK \n    0.1441864 \n    3244 \n    22.5 \n    1 \n    16 \n    72000 \n  \n  \n    Phae.long4.wav \n    1 \n    3 \n    0.1453977 \n    0.2904966 \n    2.579708 \n    9.742279 \n    OK \n    0.1450989 \n    3264 \n    22.5 \n    1 \n    16 \n    72000 \n  \n\n\n\n\n\n \nLet’s modified a selection table to see how the function works:\n\n\nCode\n# copiar las primeras 6 filas\nst2 <- lbh_selec_table[1:6, ]\n\n# hacer caracter\nst2$sound.files <- as.character(st2$sound.files)\n\n# cambiar nombre de archivo de sonido en sel 1\nst2$sound.files[1] <- \"aaa.wav\"\n\n# modificar fin en sel 3\nst2$end[3] <- 100\n\n# hacer top.freq igual q bottom freq en sel 3\nst2$top.freq[3] <- st2$bottom.freq[3]\n\n# modificar top freq en sel 5\nst2$top.freq[5] <- 200\n\n# modificar channes en sel 6\nst2$channel[6] <- 3\n\n# revisar\ncs <- check_sels(st2)\n\ncs[, c(1:7, 10)]\n\n\n\n\n\n\n\n\n\n \n  \n    sound.files \n    channel \n    selec \n    start \n    end \n    bottom.freq \n    top.freq \n    min.n.samples \n  \n \n\n  \n    aaa.wav \n    1 \n    1 \n    1.1693549 \n    1.3423884 \n    2.220105 \n    8.604378 \n    NA \n  \n  \n    Phae.long1.wav \n    1 \n    2 \n    2.1584085 \n    2.3214565 \n    2.169437 \n    8.807053 \n    3668 \n  \n  \n    Phae.long1.wav \n    1 \n    3 \n    0.3433366 \n    100.0000000 \n    2.218294 \n    2.218294 \n    2242274 \n  \n  \n    Phae.long2.wav \n    1 \n    1 \n    0.1595983 \n    0.2921692 \n    2.316862 \n    8.822316 \n    2982 \n  \n  \n    Phae.long2.wav \n    1 \n    2 \n    1.4570585 \n    1.5832087 \n    2.284006 \n    200.000000 \n    2838 \n  \n  \n    Phae.long3.wav \n    1 \n    1 \n    0.6265520 \n    0.7577715 \n    3.006834 \n    8.822316 \n    2952 \n  \n\n\n\n\n\n \ncheck_sels() is used internally when creating selection tables and extended selection tables.\n \n\n5.1 Visual inspection of spectrograms\nOnce the information in the selections has been verified, the next step is to ensure that the selections contain accurate information about the location of the signals of interest. This can be done by creating spectrograms of all selections. For this we have several options. The first is spectrograms() (previously called specreator()) which generates (by default) a spectrogram for each selection. We can run it on the sample data like this:\n\n\nCode\n# using default parameters tweak_spectro()\nwarbleR_options(wav.path = \"./examples\", wl = 220, wn = \"hanning\",\n    ovlp = 90, pal = reverse.topo.colors)\n\nspectrograms(lbh_selec_table, collevels = seq(-100, 0, 5))\n\n\n\n\n\n \nThe images it produces are saved in the working directory and look like this:\n\n \n\nExercise\n \n\nHave the label shown on the selection display the data in the ‘sel.comment’ column of the sample selection box using the sel.labels argument\n\n\n \n\n\n5.2 Full spectrograms\nWe can create spectrograms for the whole sound files using full_spectrograms(). If the X argument is not given, the function will create the spectrograms for all the files in the working directory. Otherwise, the function generates spectrograms for sound files in X and highlights selections with transparent rectangles similar to those ofspectrograms(). In this example we download a recording from a striped-throated hermit (Phaethornis striigularis) from Xeno-Canto:\n\n\nCode\n# load package with color palettes\nlibrary(viridis)\n\n# create directory\ndir.create(\"./examples/hermit\")\n\n# download sound file\nphae.stri <- query_xc(qword = \"nr:154074\", download = TRUE, path = \"./examples/hermit\")\n\n# Convert mp3 to wav format\nmp32wav(path = \"./examples/hermit/\", pb = FALSE)\n\n# plot full spec\nfull_spectrograms(sxrow = 1, rows = 10, pal = magma, wl = 200, flim = c(3,\n    10), collevels = seq(-140, 0, 5), path = \"./examples/hermit/\")"
  },
  {
    "objectID": "quality_checks.html#catalogs",
    "href": "quality_checks.html#catalogs",
    "title": "Quality checks for recordings and annotations",
    "section": "6 Catalogs",
    "text": "6 Catalogs\nCatalogs allow you to inspect selections of many recordings in the same image and group them by categories. This makes it easier to verify the consistency of the categories. Many of the arguments are shared with tweak_spectro() (catalog() is used internally in tweak_spectro()). We can generate a catalog with color tags to identify selections from the same sound file as follows:\n\n\nCode\n# read bat inquiry data\ninq <- readRDS(file = \"ext_sel_tab_inquiry.RDS\")\n\ncatalog(X = inq[1:100, ], flim = c(10, 50), nrow = 10, ncol = 10,\n    same.time.scale = T, mar = 0.01, gr = FALSE, img.suffix = \"inquiry\",\n    labels = c(\"sound.files\", \"selec\"), legend = 0, rm.axes = TRUE,\n    box = F, group.tag = \"sound.files\", tag.pal = list(magma), width = 20,\n    height = 20, pal = viridis, collevels = seq(-100, 0, 5))\n\n\n\n \n\nExercise\n \n\nUsing the ‘lbh_selec_table’ data, create a catalog with selections color-tagged by song type"
  },
  {
    "objectID": "quality_checks.html#tailoring-selections",
    "href": "quality_checks.html#tailoring-selections",
    "title": "Quality checks for recordings and annotations",
    "section": "7 Tailoring selections",
    "text": "7 Tailoring selections\nThe position of the selections in the sound file (i.e. its ‘coordinates’ of time and frequency) can be modified interactively from R using the sel_tailor() function. This function produces a graphic window showing spectrograms and a series of ‘buttons’ that allow you to modify the view and move forward in the selection table:\n\n\nCode\ntailor_sels(X = lbh_selec_table[1:4, ], auto.next = TRUE)\n\n\n\n \nThe function returns the corrected data as a data frame in R and also saves a ‘.csv’ file in the directory where the sound files are located.\nsel_tailor() can also be used to modify frequency contours such as those produced by the dfDTW() or ffDTW() function:\n\n\nCode\ncntours <- freq_ts(X = lbh_selec_table[1:5, ])\n\ntail.cntours <- tailor_sels(X = lbh_selec_table[1:5, ], ts.df = cntours,\n    auto.contour = TRUE)"
  },
  {
    "objectID": "quality_checks.html#references",
    "href": "quality_checks.html#references",
    "title": "Quality checks for recordings and annotations",
    "section": "8 References",
    "text": "8 References\n\nAraya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to streamline analysis of animal acoustic signals. Methods Ecol Evol 8:184–191.\n\n \n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] kableExtra_1.3.4   warbleR_1.1.28     NatureSounds_1.0.4 knitr_1.42        \n[5] seewave_2.2.0      tuneR_1.4.4       \n\nloaded via a namespace (and not attached):\n [1] xfun_0.39          pbapply_1.7-0      colorspace_2.1-0   vctrs_0.6.2       \n [5] testthat_3.1.8     htmltools_0.5.5    viridisLite_0.4.1  yaml_2.3.7        \n [9] rlang_1.1.1        glue_1.6.2         withr_2.5.0        lifecycle_1.0.3   \n[13] stringr_1.5.0      munsell_0.5.0      rvest_1.0.3        moments_0.14.1    \n[17] htmlwidgets_1.5.4  evaluate_0.21      fastmap_1.1.1      fftw_1.0-7        \n[21] parallel_4.2.2     Rcpp_1.0.10        scales_1.2.1       formatR_1.12      \n[25] webshot_0.5.4      jsonlite_1.8.4     systemfonts_1.0.4  brio_1.1.3        \n[29] rjson_0.2.21       digest_0.6.31      stringi_1.7.12     bioacoustics_0.2.8\n[33] dtw_1.23-1         cli_3.6.1          tools_4.2.2        bitops_1.0-7      \n[37] magrittr_2.0.3     RCurl_1.98-1.12    proxy_0.4-27       MASS_7.3-58.2     \n[41] xml2_1.3.4         rmarkdown_2.21     svglite_2.1.0      httr_1.4.6        \n[45] rstudioapi_0.14    R6_2.5.1           signal_0.7-7       compiler_4.2.2"
  },
  {
    "objectID": "comparing_methods.html",
    "href": "comparing_methods.html",
    "title": "Comparing the performance of methods for measuring acoustic structure",
    "section": "",
    "text": "Bioacoustic research is based on quantifying the structure of acoustic signals and comparing that structure between different behavioral / social / ecological contexts, groups or species. However, measuring the signal structure in a way that takes into account the most relevant variation in signal structure could be a difficult task. Some of the differences that are evident by visual inspection of spectrograms may not be detected by some analyzes. Therefore, choosing the most appropriate analytical approach is a critical step.\nThe compare_methods() function from warbleR attempts to facilitate the selection of the method. This function produces graphics (such as image files in the working directory) with spectrograms of 4 signals at a time, which allow visual inspection of the performance of acoustic analysis methods when comparing those signals. The signals are chosen randomly from the data frame or selection table provided (argument ‘X’). The function compares 2 methods at a time. The available methods are:\nThe graphs also contain 2 scatter plots (1 for each method) of the acoustic space of all the signals in the input data frame ‘X’. The position of the 4 signals in the spectrograms is highlighted in the acoustic space plots. In this way, users can directly assess whether the distances between the signals in the acoustic space accurately represent the spectrographic similarity (i.e. how similar its structure looks on the spectrograms)."
  },
  {
    "objectID": "comparing_methods.html#compare-methods-in-warbler",
    "href": "comparing_methods.html#compare-methods-in-warbler",
    "title": "Comparing the performance of methods for measuring acoustic structure",
    "section": "1 Compare methods in warbleR",
    "text": "1 Compare methods in warbleR\nThis is a brief example of how to use the function using the data files included in the package (and in the examples folder). Simply execute the function by selecting the 2 methods you want to compare. The following code compares spectrographic cross correlation (XCORR) and dynamic time warping in the dominant frequency contours (freq_DTW). The compared selections are randomly selected from the set of selections in the input data frame. The argument ‘n’ defines the number of comparisons (that is, graphs) that must be created:\n\n\n\n\n\nCode\nlibrary(warbleR)\n\ndata(\"lbh_selec_table\")\n\n# global parameters\nwarbleR_options(wav.path = \"./examples\", flim = c(0, 10), bp = c(0, 10), wl = 300, n = 12)\n\ncompare_methods(X = lbh_selec_table, methods = c(\"XCORR\", \"dfDTW\"))\n\n\n \nIt must produce 12 image files (in the working directory) that look like this one:\n\n \nLooking at several iterations of the comparison, you can have a better idea of which method works best for the signals being analyzed:\n \n\n \nThe distance of the acoustic pair between the signals is shown next to the arrows that link them. The font color of a distance value corresponds to the font color of the method that generated it, as shown in the scatter diagrams (in this case, the black font represents the XCORR distances). The distances are standardized, being 0 the distance of a signal to itself and 1 the distance in pairs farthest in the set of signals. The principal component analysis (function prcomp()) is applied to calculate distances when spectral parameters (SP) are used. In that case the first 2 components are used. Classic multidimensional scaling, also known as principal coordinate analysis, function cmdscale()) is used for all other methods. The file name contains the methods that are compared and the row number of the selections. This function internally uses a modified version of the spectro() function of the seewave package to create spectrograms. Note that all spectrograms are plotted with the same frequency and time scale.\n\n\nCode\ncompare_methods(X = lbh_selec_table, methods = c(\"XCORR\", \"SP\"))\n\n\n\n \n\nExercise\n \n\nUse the compare_methods() function to compare the following methods:\n\ndescriptors of cepstral coefficients (“MFCC”) vs cross-correlation (“XCORR”)\ndynamic time warping on dominant frequency contours (“dfDTW”), spectrographic parameters (“SP”)\n\n\n \n\nWhich method better represents the variation in signal structure for each comparison?\nCompare the best methods from the two comparison above"
  },
  {
    "objectID": "comparing_methods.html#compare-custom-measurements",
    "href": "comparing_methods.html#compare-custom-measurements",
    "title": "Comparing the performance of methods for measuring acoustic structure",
    "section": "2 Compare custom measurements",
    "text": "2 Compare custom measurements\nAlternatively, you can provide your own data. This could be useful to eliminate unwanted parameters or to enter parameters obtained with other programs (for example, from Raven). To do this, enter your data with the argument custom1. The following example 1) calculate the spectral parameters with the spectro_analysis() function, 2) select only the first 7 columns of the output, and 3) enter this data in compare_methods():\n\n\nCode\n# measure parameters\nY <- spectro_analysis(lbh_selec_table)\n\n# selec a subset\nY <- Y[, 1:7]\n\n# PCA\nY <- prcomp(Y[, 3:ncol(Y)])$x\n\n# add sound files and selec columns\nY <- data.frame(lbh_selec_table[, c(1, 3)], Y[, 1:2])\n\ncompare_methods(X = lbh_selec_table, methods = c(\"dfDTW\"), custom1 = Y)\n\n\n\n \nNote that there is also a custom2 argument for entering another custom data. The function has many other arguments for specifying methods (for example bandpass, overlap) and spectrogram settings (margin, grid, frequency limits, etc).\n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10        rstudioapi_0.14    magrittr_2.0.3     knitr_1.42        \n [5] NatureSounds_1.0.4 MASS_7.3-58.2      R6_2.5.1           rjson_0.2.21      \n [9] rlang_1.1.1        fastmap_1.1.1      pbapply_1.7-0      warbleR_1.1.28    \n[13] tools_4.2.2        parallel_4.2.2     xfun_0.39          dtw_1.23-1        \n[17] cli_3.6.1          htmltools_0.5.5    yaml_2.3.7         digest_0.6.31     \n[21] brio_1.1.3         tuneR_1.4.4        htmlwidgets_1.5.4  bitops_1.0-7      \n[25] testthat_3.1.8     RCurl_1.98-1.12    signal_0.7-7       seewave_2.2.0     \n[29] evaluate_0.21      rmarkdown_2.21     proxy_0.4-27       compiler_4.2.2    \n[33] jsonlite_1.8.4     fftw_1.0-7"
  },
  {
    "objectID": "instructor.html",
    "href": "instructor.html",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "",
    "text": "Marcelo Araya-Salas\n\n\n\n\n\nI am just another behavioral ecologists that ended up doing a lot of coding just to get data analysis done. So now I’m deeply involved in the development of computational tools for (non-genetic) biological data analysis, mostly related to animal behavior and bioacoustics. I am the developer and maintainer of the R packages warbleR and Rraven that provide functions to streamline high-throughput acoustic analysis of animal sounds, aiming to simplify the use of R for bioacoustic research. More recently I released the R packages baRulho, to quantify acoustic signal transmission and degradation, ohun, to optimize automatic detection and PhenotypeSpace for quantifying multidimensional trait spaces. Also check out the new R package sketchy for organizing research compendiums. New functions as well as other more elaborated analyses are detailed in my blog Bioacoustics in R."
  },
  {
    "objectID": "sound.html",
    "href": "sound.html",
    "title": "Sound",
    "section": "",
    "text": "Sound waves are characterized by compression and expansion of the medium as sound energy moves through it. There is also back and forth motion of the particles making up the medium:\ntaken from https://dosits.org\nThe variation in pressure that is perceived at a fixed point in space can be represented by a graph of pressure (amplitude) by time:\nSounds waves are typically quantified by their frequency (number of cycles per second, Hz) and amplitude (relative intensity)."
  },
  {
    "objectID": "sound.html#sampling-frequency",
    "href": "sound.html#sampling-frequency",
    "title": "Sound",
    "section": "0.1 Sampling frequency",
    "text": "0.1 Sampling frequency\nDigitizing implies discretizing, which requires some sort of regular sampling. Sampling frequency refers to how many samples of the pressure level of the environment are taken per second. A 440 Hz sine wave recorded at 44100 Hz would have around 100 samples per cycle. This plot shows 2 cycles of a 440 Hz sine wave sampled (vertical dotted lines) at 44100 Hz:"
  },
  {
    "objectID": "sound.html#nyquist-frequency",
    "href": "sound.html#nyquist-frequency",
    "title": "Sound",
    "section": "0.2 Nyquist frequency",
    "text": "0.2 Nyquist frequency\nSampling should be good enough so the regularity of the sine wave can be reconstructed from the sampled data. Low sampling frequencies of a high frequency sine wave might not be able to provide enough information. For instance, the same 440 Hz sine wave sampled at 22050 Hz looks like this:\n\n\n\n\n\n \nAs you can see way less samples are taken per unit of time. The threshold at which samples cannot provide a reliable estimate of the regularity of a sine wave is called Nyquist frequency and corresponds to half of the frequency of the sine wave. This is how the 2 cycles of the 440 Hz would look like when sampled at its Nyquist frequency (sampling frequency of 880 Hz):"
  },
  {
    "objectID": "sound.html#quantization",
    "href": "sound.html#quantization",
    "title": "Sound",
    "section": "0.3 Quantization",
    "text": "0.3 Quantization\nOnce we know at which point amplitude samples will be taken we just need to measure it. This process is called quantization. The range of amplitude values is discretized in a number of intervals equals to 2 ^ bits. Hence, it involves some rounding of the actual amplitude values and some data loss. This is the same 440 Hz sine wave recorded at 44100 kHz quantized at 2 bits (2^2 = 4 intervals):\n\n\n\n\n\n \nRounding and data loss is more obvious if we bind the sampled points with lines:\n\n\n\n\n\n \nThis is the same signal quantized at 3 bits (2^3 = 8 intervals):\n\n\n\n\n\n \n4 bits (2^4 = 16 intervals):\n\n\n\n\n\n \n.. and 8 bits (2^8 = 256 intervals):\n\n\n\n\n\n \nAt this point quantization involves very little information loss. 16 bits is probably the most common dynamic range used nowadays. As you can imagine, the high number of intervals (2^16 = 65536) allows for great precision in the quantization of amplitude."
  },
  {
    "objectID": "sound.html#non-specific-classes",
    "href": "sound.html#non-specific-classes",
    "title": "Sound",
    "section": "1.1 Non-specific classes",
    "text": "1.1 Non-specific classes\n\n1.1.1 Vectors\nAny numerical vector can be treated as a sound if a sampling frequency is provided. For example, a 440 Hz sinusoidal sound sampled at 8000 Hz for one second can be generated like this:\n\n\nCode\nlibrary(seewave)\n\n# create sinewave at 440 Hz\ns1 <- sin(2 * pi * 440 * seq(0, 1, length.out = 8000))\n\nis.vector(s1)\n\n\n[1] TRUE\n\n\nCode\nmode(s1)\n\n\n[1] \"numeric\"\n\n\n \nThese sequences of values only make sense when specifying the sampling rate at which they were created:\n\n\nCode\noscillo(s1, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n \n\n\n1.1.2 Matrices\nYou can read any single column matrix:\n\n\nCode\ns2 <- as.matrix(s1)\n\nis.matrix(s2)\n\n\n[1] TRUE\n\n\nCode\ndim(s2)\n\n\n[1] 8000    1\n\n\nCode\noscillo(s2, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n \nIf the matrix has more than one column, only the first column will be considered:\n\n\nCode\nx <- rnorm(8000)\n\ns3 <- cbind(s2, x)\n\nis.matrix(s3)\n\n\n[1] TRUE\n\n\nCode\ndim(s3)\n\n\n[1] 8000    2\n\n\nCode\noscillo(s3, f = 8000, from = 0, to = 0.01)\n\n\n\n\n\n \n\n\n1.1.3 Time series\nThe class ts and related functions ts(), as.ts(), is.ts() can also be used to generate sound objects in R. Here the command to similarly generate a series of time is shown corresponding to a 440 Hz sinusoidal sound sampled at 8000 Hz for one second:\n\n\nCode\ns4 <- ts(data = s1, start = 0, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:8000] from 0 to 1: 0 0.339 0.637 0.861 0.982 ...\n\n\n \nTo generate a random noise of 0.5 seconds:\n\n\nCode\ns4 <- ts(data = runif(4000, min = -1, max = 1), start = 0, end = 0.5, frequency = 8000)\n\nstr(s4)\n\n\n Time-Series [1:4001] from 0 to 0.5: -0.225 -0.876 -0.869 0.958 0.557 ...\n\n\n \nThe frequency() and deltat() functions return the sampling frequency (\\(f\\)) and the time resolution (\\(Delta t\\)) respectively:\n\n\nCode\nfrequency(s4)\n\n\n[1] 8000\n\n\nCode\ndeltat(s4)\n\n\n[1] 0.000125\n\n\n \nAs the frequency is incorporated into the ts objects, it is not necessary to specify it when used within functions dedicated to audio:\n\n\nCode\noscillo(s4, from = 0, to = 0.01)\n\n\n\n\n\n \nIn the case of multiple time series, seewave functions will consider only the first series:\n\n\nCode\ns5 <- ts(data = s3, f = 8000)\n\nclass(s5)\n\n\n[1] \"mts\"    \"ts\"     \"matrix\"\n\n\nCode\noscillo(s5, from = 0, to = 0.01)"
  },
  {
    "objectID": "sound.html#dedicated-r-classes-for-sound",
    "href": "sound.html#dedicated-r-classes-for-sound",
    "title": "Sound",
    "section": "1.2 Dedicated R classes for sound",
    "text": "1.2 Dedicated R classes for sound\nThere are 3 kinds of objects corresponding to the wav binary format or themp3 compressed format:\n\nWave class of the package tuneR\nsound class of the package phonTools\nAudioSample class of the package audio\n\n \n\n1.2.1 Wave class (tuneR)\nThe Wave class comes with the tuneR package. This S4 class includes different “slots” with the amplitude data (left or right channel), the sampling frequency (or frequency), the number of bits (8/16/24/32) and the type of sound (mono/stereo). High sampling rates (> 44100 Hz) can be read on these types of objects.\nThe function to import .wav files from the hard drive is readWave:\n\n\nCode\n# load packages\nlibrary(tuneR)\n\ns6 <- readWave(\"./examples/Phae.long1.wav\")\n\n\n \nWe can verify the class of the object like this:\n\n\nCode\n# object class\nclass(s6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nS4 objects have a structure similar to lists but use ‘@’ to access each position (slot):\n\n\nCode\n# structure\nstr(s6)\n\n\nFormal class 'Wave' [package \"tuneR\"] with 6 slots\n  ..@ left     : int [1:56251] 162 -869 833 626 103 -2 43 19 47 227 ...\n  ..@ right    : num(0) \n  ..@ stereo   : logi FALSE\n  ..@ samp.rate: int 22500\n  ..@ bit      : int 16\n  ..@ pcm      : logi TRUE\n\n\nCode\n# extract 1 position\ns6@samp.rate\n\n\n[1] 22500\n\n\n \n\n“Pulse-code modulation (PCM) is a method used to digitally represent sampled analog signals. It is the standard form of digital audio. In a PCM stream, the amplitude of the analog signal is sampled regularly at uniform intervals, and each sample is quantized to the nearest value within a range of digital steps” (Wikipedia).\n\n \nThe samples come in the slot ‘@left’:\n\n\nCode\n# samples\ns6@left[1:40]\n\n\n [1]  162 -869  833  626  103   -2   43   19   47  227   -4  205  564  171  457\n[16]  838 -216   60   76 -623 -213  168 -746 -248  175 -512  -58  651  -85 -213\n[31]  586   40 -407  371  -51 -587  -92   94 -527   40\n\n\n \nThe number of samples is given by the duration and the sampling rate.\n \n\nExercise\n\nHow can we calculate the duration of the wave object using the information in the object?\n\n \n\nExtract the first second of audio from the object s6 using indexing (and squared brackets)\n\n\n \nAn advantage of using readWave() is the ability to read specific segments of sound files, especially useful with long files. This is done using the from andto arguments and specifying the units of time with the units arguments. The units can be converted into “samples”, “minutes” or “hours”. For example, to read only the section that begins in 1s and ends in 2s of the file “Phae.long1.wav”:\n\n\nCode\ns7 <- readWave(\"./examples/Phae.long1.wav\", from = 1, to = 2, units = \"seconds\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      22500\n    Duration (seconds):     1\n    Samplingrate (Hertz):   22500\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nThe .mp3 files can be imported to R although they are imported inWave format. This is done using the readMP3() function:\n\n\nCode\ns7 <- readMP3(\"./examples/Phae.long1.mp3\")\n\ns7\n\n\n\nWave Object\n    Number of Samples:      56448\n    Duration (seconds):     2.56\n    Samplingrate (Hertz):   22050\n    Channels (Mono/Stereo): Mono\n    PCM (integer format):   TRUE\n    Bit (8/16/24/32/64):    16 \n\n\n \nTo obtain information about the object (sampling frequency, number of bits, mono/stereo), it is necessary to use the indexing of S4 class objects:\n\n\nCode\ns7@samp.rate\n\n\n[1] 22050\n\n\nCode\ns7@bit\n\n\n[1] 16\n\n\nCode\ns7@stereo\n\n\n[1] FALSE\n\n\n \nA property that does not appear in these calls is that readWave does not normalize the sound. The values that describe the sound will be included between \\(\\pm2^{bit} - 1\\):\n\n\nCode\nrange(s7@left)\n\n\n[1] -32768  32767\n\n\n \n\nExercise\nThe function Wave can be used to create wave objects.\n \n\nRun the example code in the function documentation\nPlot the oscillogram for the first 0.01 s of ‘Wobj’\nNote that the function sine provides a shortcut that can be used to create wave object with a sine wave. Check out other similar functions described in the sine function documentation. Try 4 of these alternative functions and plot the oscillogram of the first 0.01 s for each of them.\n\n\n \nThe function read_sound_files from warbleR is a wrapper over several sound file reading functions, that can read files in ‘wav’, ‘mp3’, ‘flac’ and ‘wac’ format:\n\n\nCode\nlibrary(warbleR)\n\n# wave\nrsf1 <- read_sound_file(\"Phaethornis-eurynome-15607.wav\", path = \"./examples\")\n\nclass(rsf1)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# mp3\nrsf2 <- read_sound_file(\"Phaethornis-striigularis-154074.mp3\", path = \"./examples\")\n\nclass(rsf2)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# flac\nrsf3 <- read_sound_file(\"Phae.long1.flac\", path = \"./examples\")\n\nclass(rsf3)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\n# wac\nrsf4 <- read_sound_file(\"recording_20170716_230503.wac\", path = \"./examples\")\n\nclass(rsf4)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\n \nThe function can also read recordings hosted in an online repository:\n\n\nCode\nrsf5 <- read_sound_file(X = \"https://xeno-canto.org/35340/download\")\n\nclass(rsf5)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\"\n\n\nCode\nrsf6 <- read_sound_file(X = \"https://github.com/maRce10/OTS_BIR_2023/raw/master/examples/Phae.long1.flac\")\n\nclass(rsf6)\n\n\n[1] \"Wave\"\nattr(,\"package\")\n[1] \"tuneR\""
  },
  {
    "objectID": "sound.html#class-sound-phontools",
    "href": "sound.html#class-sound-phontools",
    "title": "Sound",
    "section": "1.3 Class sound (phonTools)",
    "text": "1.3 Class sound (phonTools)\nThe loadsound() function of phonTools also imports ‘wave’ sound files into R, in this case as objects of class sound:\n\n\nCode\nlibrary(phonTools)\n\ns8 <- loadsound(\"./examples/Phae.long1.wav\")\n\ns8\n\n\n\n      Sound Object\n\n   Read from file:         ./examples/Phae.long1.wav\n   Sampling frequency:     22500  Hz\n   Duration:               2500.044  ms\n   Number of Samples:      56251 \n\n\nCode\nstr(s8)\n\n\nList of 5\n $ filename  : chr \"./examples/Phae.long1.wav\"\n $ fs        : int 22500\n $ numSamples: num 56251\n $ duration  : num 2500\n $ sound     : Time-Series [1:56251] from 0 to 2.5: 0.00494 -0.02652 0.02542 0.0191 0.00314 ...\n - attr(*, \"class\")= chr \"sound\"\n\n\n \nThis function only imports files with a dynamic range of 8 or 16 bits."
  },
  {
    "objectID": "sound.html#class-audiosample-audio",
    "href": "sound.html#class-audiosample-audio",
    "title": "Sound",
    "section": "1.4 Class audioSample (audio)",
    "text": "1.4 Class audioSample (audio)\nThe audio package is another option to handle .wav files. The sound can be imported using the load.wave() function. The class of the resulting object is audioSample which is essentially a numerical vector (for mono) or a numerical matrix with two rows (for stereo). The sampling frequency and resolution are saved as attributes:\n\n\nCode\nlibrary(audio)\n\ns10 <- load.wave(\"./examples/Phae.long1.wav\")\n\nhead(s10)\n\n\nsample rate: 22500Hz, mono, 16-bits\n[1]  4.943848e-03 -2.652058e-02  2.542114e-02  1.910400e-02  3.143311e-03\n[6] -6.103702e-05\n\n\nCode\ns10$rate\n\n\n[1] 22500\n\n\nCode\ns10$bits\n\n\n[1] 16\n\n\n \nThe main advantage of the audio package is that the sound can be acquired directly within an R session. This is achieved first by preparing a NAs vector and then using therecord() function. For example, to obtain a mono sound of 5 seconds sampled at 16 kHz:\n\n\nCode\ns11 <- rep(NA_real_, 16000 * 5)\n\nrecord(s11, 16000, 1)\n\n\n \nA recording session can be controlled by three complementary functions: pause(), rewind(), and resume()."
  },
  {
    "objectID": "sound.html#export-sounds-from-r",
    "href": "sound.html#export-sounds-from-r",
    "title": "Sound",
    "section": "1.5 Export sounds from R",
    "text": "1.5 Export sounds from R\nFor maximum compatibility with other sound programs, it may be useful to save a sound as a simple .txt file. The following commands will write a “tico.txt” file:\n\n\nCode\ndata(tico)\n\nexport(tico, f = 22050)"
  },
  {
    "objectID": "sound.html#format-.wav",
    "href": "sound.html#format-.wav",
    "title": "Sound",
    "section": "1.6 Format ‘.wav’",
    "text": "1.6 Format ‘.wav’\ntuneR and audio have a function to write .wav files: writeWave() and save.wave() respectively. Within seewave, the savewav() function, which is based on writeWave(), can be used to save data in .wav format. By default, the object name will be used for the name of the .wav file:\n\n\nCode\nsavewav(tico)"
  },
  {
    "objectID": "sound.html#format-.flac",
    "href": "sound.html#format-.flac",
    "title": "Sound",
    "section": "1.7 Format ‘.flac’",
    "text": "1.7 Format ‘.flac’\nFree Lossless Audio Codec (FLAC) is a file format for lossless audio data compression. FLAC reduces bandwidth and storage requirements without sacrificing the integrity of the audio source. Audio sources encoded in FLAC are generally reduced in size from 40 to 50 percent. See the flac website for more details (flac.sourceforge.net).\nThe .flac format cannot be used as such with R. However, the wav2flac()function allows you to call the FLAC software directly from the console. Therefore, FLAC must be installed on your operating system. If you have a .wav file that you want to compress in .flac, call:\n\n\nCode\nwav2flac(file = \"./examples/Phae.long1.wav\", overwrite = FALSE)\n\n\n \nTo compress a .wav file to a .flac format, the argument reverse = TRUE must be used:\n\n\nCode\nwav2flac(\"Phae.long1.flac\", reverse = TRUE)\n\n\n \nThis table, taken from Sueur (2018), summarizes the functions available to import and export sound files in R. The table is incomplete since it does not mention the functions of the phonTools package:\n\n\n \n\nExercise\n\nHow does the sampling rate affect the size of an audio file? (hint: create 2 sounds files with the same data but different sampling rates; use sine())\nHow does the dynamic range affect the size of an audio file?\nUse the system.time() function to compare the performance of the different functions to import audio files in R. For this use the file “LBH.374.SUR.wav” (Long-billed hermit songs) which lasts about 2 min\n\nThe following code creates a plot similar to oscillo but using dots instead of lines:\n\n\nCode\n# generate sine wave\nwav <- sine(freq = 440, duration = 500, xunit = \"samples\", samp.rate = 44100)\n\n# plot\nplot(wav@left)\n\n\n\n\n\n\n\n \n\nUse the function downsample() to reduce the sampling rate of ‘wav’ (below 44100) and plot the output object. Decrease the sampling rate until you cannot recognize the wave pattern from the original wave object. Try several values so you get a sense at which sampling rate this happens."
  },
  {
    "objectID": "sound.html#references",
    "href": "sound.html#references",
    "title": "Sound",
    "section": "1.8 References",
    "text": "1.8 References\n\nSueur J, Aubin T, Simonis C. 2008. Equipment review: seewave, a free modular tool for sound analysis and synthesis. Bioacoustics 18(2):213–226.\nSueur, J. (2018). Sound Analysis and Synthesis with R.\nSueur J. (2018). I/O of sound with R. seewave package vignette. url: https://cran.r-project.org/web/packages/seewave/vignettes/seewave_IO.pdf\n\n\nSession information\n\n\nR version 4.2.2 Patched (2022-11-10 r83330)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=es_ES.UTF-8    \n [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=es_ES.UTF-8   \n [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] audio_0.1-10       phonTools_0.2-2.1  warbleR_1.1.28     NatureSounds_1.0.4\n[5] tuneR_1.4.4        knitr_1.42         seewave_2.2.0     \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0   xfun_0.39          pbapply_1.7-0      colorspace_2.1-0  \n [5] vctrs_0.6.2        generics_0.1.3     testthat_3.1.8     htmltools_0.5.5   \n [9] viridisLite_0.4.1  yaml_2.3.7         utf8_1.2.3         rlang_1.1.1       \n[13] pillar_1.9.0       glue_1.6.2         withr_2.5.0        lifecycle_1.0.3   \n[17] stringr_1.5.0      munsell_0.5.0      gtable_0.3.1       moments_0.14.1    \n[21] htmlwidgets_1.5.4  evaluate_0.21      fastmap_1.1.1      fftw_1.0-7        \n[25] parallel_4.2.2     fansi_1.0.4        Rcpp_1.0.10        scales_1.2.1      \n[29] formatR_1.12       jsonlite_1.8.4     brio_1.1.3         gridExtra_2.3     \n[33] rjson_0.2.21       ggplot2_3.4.0      digest_0.6.31      stringi_1.7.12    \n[37] dplyr_1.1.0        bioacoustics_0.2.8 dtw_1.23-1         grid_4.2.2        \n[41] cli_3.6.1          tools_4.2.2        bitops_1.0-7       magrittr_2.0.3    \n[45] RCurl_1.98-1.12    proxy_0.4-27       tibble_3.2.1       pkgconfig_2.0.3   \n[49] MASS_7.3-58.2      rmarkdown_2.19     rstudioapi_0.14    viridis_0.6.2     \n[53] R6_2.5.1           signal_0.7-7       compiler_4.2.2"
  },
  {
    "objectID": "r_basics.html",
    "href": "r_basics.html",
    "title": "R basics",
    "section": "",
    "text": "Code\nx <- iris[1:4, ]\n\nx\n\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa"
  },
  {
    "objectID": "annotations.html#objetive",
    "href": "annotations.html#objetive",
    "title": "Import annotations into R",
    "section": "Objetive",
    "text": "Objetive\n\nLearn various methods to import and export annotations in R\nGet familiar with the data structure used for representing annotations in R"
  },
  {
    "objectID": "annotations.html#objetives",
    "href": "annotations.html#objetives",
    "title": "Import annotations into R",
    "section": "Objetives",
    "text": "Objetives\n\nLearn various methods to import and export annotations in R\nGet familiar with the data structure used for representing annotations in R"
  },
  {
    "objectID": "comparing_methods.html#objetives",
    "href": "comparing_methods.html#objetives",
    "title": "Comparing the performance of methods for measuring acoustic structure",
    "section": "Objetives",
    "text": "Objetives\n\nLearn how to compare methods to measure acoustic structure\nGet familiar with the use of acoustic spaces to summarize results form acoustic analyses"
  },
  {
    "objectID": "intro_to_warbler.html#objetive",
    "href": "intro_to_warbler.html#objetive",
    "title": "Introduction to warbleR",
    "section": "Objetive",
    "text": "Objetive\n\nProvide and overview of the must relevant tools in the package warbleR"
  },
  {
    "objectID": "measure_acoustic_structure.html#objetives",
    "href": "measure_acoustic_structure.html#objetives",
    "title": "Measures of acoustic structure",
    "section": "Objetives",
    "text": "Objetives\n\nLearn the different methods available to quantify acoustic structure\nUnderstand their pros and cons\nLearn how to apply them in R"
  },
  {
    "objectID": "get_xc_recordings.html#objetive",
    "href": "get_xc_recordings.html#objetive",
    "title": "OTS Bioacoustic Analysis in R 2023",
    "section": "Objetive",
    "text": "Objetive\n\nDemonstrate how to obtain acoustic data from online repositories"
  },
  {
    "objectID": "measure_structure_green_hermit.html",
    "href": "measure_structure_green_hermit.html",
    "title": "Case study",
    "section": "",
    "text": "Demonstrate how to articulate functions used during the course to obtain, explore and quantify acoustic data"
  },
  {
    "objectID": "quality_checks.html#objetive",
    "href": "quality_checks.html#objetive",
    "title": "Quality checks for recordings and annotations",
    "section": "Objetive",
    "text": "Objetive\n\nProvide tools for double-checking the quality of the acoustic data and derived analyses along the acoustic analysis workflow"
  },
  {
    "objectID": "r_basics.html#objetive",
    "href": "r_basics.html#objetive",
    "title": "R basics",
    "section": "Objetive",
    "text": "Objetive\n\nRevisit the basic syntax and data structures in R"
  },
  {
    "objectID": "seewave.html#objetives",
    "href": "seewave.html#objetives",
    "title": "Seewave",
    "section": "Objetives",
    "text": "Objetives\n\nUnderstand the most common metrics of acoustic structure\nGet familiar with manipulating and formatting sound in the R environment"
  },
  {
    "objectID": "sound.html#objetives",
    "href": "sound.html#objetives",
    "title": "Sound",
    "section": "Objetives",
    "text": "Objetives\n\nLearn the basic aspects of sound as a physical phenomenom\nGet familiar with how sound is represented as a digital object in R"
  },
  {
    "objectID": "spectrograms.html#objetives",
    "href": "spectrograms.html#objetives",
    "title": "Building spectrograms",
    "section": "Objetives",
    "text": "Objetives\n\nUnderstand how spectrograms are created\nLearn to create and customize spectrograms in R"
  },
  {
    "objectID": "r_basics.html#objetives",
    "href": "r_basics.html#objetives",
    "title": "R basics",
    "section": "Objetives",
    "text": "Objetives\n\nRevisit the basic syntax and data structures in R\nGet familiar with documentation and help resources"
  }
]