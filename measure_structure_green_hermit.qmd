---
title: <font size="6"><b>Case study</b></font>
toc: true
toc-depth: 2
toc-location: left
number-sections: true
highlight-style: pygments
format:
  html:
    df-print: kable
    code-fold: show
    code-tools: true
    css: styles.css
---

::: {.alert .alert-info}
## **Objetive** {.unnumbered .unlisted}

-   Demonstrate how to articulate functions used during the course to obtain, explore and quantify acoustic data
:::

 

## Download Xeno-Canto data

The warbleR function [`query_xc()`](https://marce10.github.io/warbleR/reference/query_xc.html) queries for avian vocalization recordings in the open-access online repository [Xeno-Canto](https://xeno-canto.org). It can return recordings metadata or download the associated sound files.

Get recording metadata for green hermits (*Phaethornis guy*):

```{r, echo=FALSE,message=FALSE,  warning=FALSE}
library(warbleR)
```

```{r, message=FALSE,  warning=FALSE, eval = FALSE}

library(warbleR)

pg <- query_xc(qword = 'Phaethornis guy', download = FALSE)

```

 

Keep only song vocalizations of high quality:

```{r, eval = FALSE}

song_pg <- pg[grepl("song", ignore.case = TRUE, pg$Vocalization_type) & pg$Quality == "A", ]

# remove 1 site from Colombia to have a few samples per country
song_pg <- song_pg[song_pg$Locality != "Suaita, Santander", ]

```

 

```{r, echo=FALSE}
song_pg <- read.csv("./examples/p_guy/metadata_p_guy_XC.csv")
```

Map locations using [`map_xc()`](https://marce10.github.io/warbleR/reference/map_xc.html):

```{r, results = 'asis', fig.width=9}

map_xc(song_pg, leaflet.map = TRUE)

```

 

Once you feel fine with the subset of data you can go ahead and download the sound files and save the metadata as a .csv file:

```{r, eval = FALSE, fig.width=10}

query_xc(X = song_pg, path = "./examples/p_guy", parallel = 3)

write.csv(song_pg, file = "./examples/p_guy/metadata_p_guy_XC.csv", row.names = FALSE)

```

 

## Preparing sound files for analysis (optional)

Now convert all to .wav format (`mp3_2_wav`) and homogenizing sampling rate and bit depth (`fix_wavs`):

```{r, eval = FALSE}

mp3_2_wav(samp.rate = 22.05, path =  "./examples/p_guy")

fix_wavs(path =  "./examples/p_guy", samp.rate = 44.1, bit.depth = 16)

```

 

## Annotating sound files in Raven

Now songs should be manually annotated and all the selection in the .txt files should be pooled together in a single spreadsheet.

 

## Importing annotations into R

Once that is done we can read the spreadsheet with the package 'readxl' as follows:

```{r, eval = FALSE, echo = FALSE}

library(Rraven)

ann_p_guy <- imp_raven(path = "./examples/p_guy", warbler.format = TRUE)

check_sels(ann_p_guy, path = "./examples/p_guy/converted_sound_files/")

write.csv(ann_p_guy, file = "./examples/p_guy/annotations_p_guy.csv", row.names = FALSE)

```

```{r, eval = FALSE}
# install.packages("readxl") # install if needed

# load package
library(readxl)

# read data
annotations <- read_excel(path = "./examples/p_guy/annotations_p_guy.xlsx")

# check data
head(annotations)
```

```{r, echo=FALSE}

# load package
library(readxl)

# read data
annotations <- read_excel(path = "./examples/p_guy/annotations_p_guy.xlsx")

kable(annotations[1:6, -7])

```

Note that the column names should be: "start", "end", "bottom.freq", "top.freq" and "sound.files". In addition frequency columns ("bottom.freq" and "top.freq") must be in kHz, not in Hz. We can check if the annotations are in the right format using warbleR's `check_sels()`:

```{r}

sound_file_path <- "./examples/p_guy/converted_sound_files/"

cs <- check_sels(annotations, path = sound_file_path)

```

 

## Measure acoustic structure

We can measured several parameters of acoustic structure with the warbleR function `spectro_analysis()`:

```{r, warning=FALSE, message=FALSE}

sp <- spectro_analysis(X = annotations, path = sound_file_path)

```

 

Then we summarize those parameters with a Principal Component Analysis (PCA):

```{r}

# run excluding sound file and selec columns
pca <- prcomp(sp[, -c(1, 2)])


# add first 2 PCs to sound file and selec columns
pca_data <- cbind(sp[, c(1, 2)], pca$x[, 1:2])

```

 

At this point should should get someting like this:

```{r, eval = FALSE}
head(pca_data)
```

```{r, echo = FALSE}
kable(pca_data[1:6, ])

```

 

'PC1' and 'PC2' are the 2 new dimensions that will be used to represent the acoustic space.

 

## Adding metadata

Now we just need to add any metadata we considered important to try to explain acoustic similarities shown in the acoustic space scatterplot:

```{r}

# read XC metadata
song_pg <- read.csv("./examples/p_guy/metadata_p_guy_XC.csv")

# create a column with the file name in the metadata
song_pg$sound.files <- paste0(song_pg$Genus, "-", song_pg$Specific_epithet, "-", song_pg$Recording_ID, ".wav")

# and merge based on sound files and any metadata column we need
pca_data_md <- merge(pca_data, song_pg[, c("sound.files", "Country", "Latitude", "Longitude")])

```

 

## Assessing geographic patterns of variation

We are ready to plot the acoustic space scatterplot. For this we will use the package 'ggplot2':

```{r}

# install.packages("ggplot2")
library(ggplot2)

# install.packages("viridis")
library(viridis)

# plot
ggplot(data = pca_data_md, aes(x = PC1, y = PC2, color = Country, shape = Country)) +
  geom_point(size = 3) + 
  scale_color_viridis_d()

```

 

You can also add information about their geographic location (in this case longitude) to the plot as follows:

```{r}

# plot
ggplot(data = pca_data_md, aes(x = PC1, y = PC2, color = Longitude, shape = Country)) +
  geom_point(size = 3) +
  scale_color_viridis_c()

```

 

We can even test if geographic distance is associated to acoustic distance (i.e. if individuals geographically closer produce more similar songs) using a [mantel test](https://en.wikipedia.org/wiki/Mantel_test) (`mantel` function from the package vegan):

```{r, warning=FALSE, message=FALSE}

# create geographic and acoustic distance matrices
geo_dist <- dist(pca_data_md[, c("Latitude", "Longitude")])
acoust_dist <- dist(pca_data_md[, c("PC1", "PC2")])

# install.packages("vegan")
library(vegan)

# run test
mantel(geo_dist, acoust_dist)

```

 

In this example no association between geographic and acoustic distance was detected (p value \> 0.05).

------------------------------------------------------------------------

<font size="4">Session information</font>

```{r session info, echo=F}

sessionInfo()

```
